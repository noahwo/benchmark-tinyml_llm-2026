{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2ababb9",
   "metadata": {},
   "source": [
    "# CodeBERT Similarity Calculations\n",
    "A consolidated notebook to run PSG, SG, and TPU-SG similarity scoring and persist results.\n",
    "\n",
    "**Sections**\n",
    "1. Configure Paths and Environment\n",
    "2. Import Dependencies and Utilities\n",
    "3. Load Reference File and Discover Candidates\n",
    "4. Run Similarity Scoring Loop (All Three Scripts)\n",
    "5. Append and Merge CSV Outputs\n",
    "6. Quick Summary and Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62f0beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configure Paths and Environment\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "if \"__file__\" in globals():\n",
    "    SCRIPT_DIR = Path(__file__).resolve().parent\n",
    "else:\n",
    "    # Notebook execution: assume cwd is the repo root\n",
    "    SCRIPT_DIR = Path.cwd() / \"codebertscore-similarity/analyser-results\"\n",
    "    if not SCRIPT_DIR.exists():\n",
    "        # Fallback to cwd if running from inside analyser-results already\n",
    "        SCRIPT_DIR = Path.cwd()\n",
    "\n",
    "# Derive project root based on known layout\n",
    "if SCRIPT_DIR.name == \"analyser-results\" and SCRIPT_DIR.parent.name == \"codebertscore-similarity\":\n",
    "    PROJECT_ROOT = SCRIPT_DIR.parent.parent\n",
    "else:\n",
    "    PROJECT_ROOT = SCRIPT_DIR\n",
    "\n",
    "CODE_BERT_PACKAGE = PROJECT_ROOT / \"codebertscore-similarity\"\n",
    "sys.path.insert(0, str(CODE_BERT_PACKAGE))\n",
    "\n",
    "# Per-script configuration matching the original files\n",
    "CONFIGS = {\n",
    "    \"psg\": {\n",
    "        \"reference\": PROJECT_ROOT / \"codebertscore-similarity/references/TFLite_detection_video.py\",\n",
    "        \"candidate_glob\": \"*/exported_valid_code/psg/*.py\",\n",
    "        \"output_csv\": PROJECT_ROOT / \"codebertscore-similarity/analyser-results/similarity_results_psg.csv\",\n",
    "        \"lang\": \"python\",\n",
    "    },\n",
    "    \"sg\": {\n",
    "        \"reference\": PROJECT_ROOT / \"codebertscore-similarity/references/object_color_classify.ino\",\n",
    "        \"candidate_glob\": \"*/exported_valid_code/sg/*.ino\",\n",
    "        \"output_csv\": PROJECT_ROOT / \"codebertscore-similarity/analyser-results/similarity_results_sg.csv\",\n",
    "        \"lang\": \"c_sharp\",\n",
    "    },\n",
    "    \"tpusg\": {\n",
    "        \"reference\": PROJECT_ROOT / \"codebertscore-similarity/references/TFLite_detection_video_TPU.py\",\n",
    "        \"candidate_glob\": \"*/exported_valid_code/tpusg/*.py\",\n",
    "        \"output_csv\": PROJECT_ROOT / \"codebertscore-similarity/analyser-results/similarity_results_tpusg.csv\",\n",
    "        \"lang\": \"python\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Include both 2025 and 2026 runs under langfuse_export\n",
    "CANDIDATE_ROOT = PROJECT_ROOT / \"langfuse_export\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a73db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Import Dependencies and Utilities\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import torch\n",
    "import code_bert_score\n",
    "\n",
    "# Enable CUDA optimizations for better performance\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.set_grad_enabled(False)  # Disable gradients for inference-only\n",
    "    \n",
    "    # Get GPU info\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    compute_cap = torch.cuda.get_device_capability()\n",
    "    total_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    \n",
    "    print(f\"✓ GPU: {gpu_name}\")\n",
    "    print(f\"✓ Compute Capability: {compute_cap[0]}.{compute_cap[1]}\")\n",
    "    print(f\"✓ Memory: {total_memory_gb:.1f} GB\")\n",
    "    \n",
    "    # Enable TF32 on Ampere+ GPUs (RTX 30xx, A100, etc.) - Pascal/GTX 1060 doesn't support this\n",
    "    if compute_cap[0] >= 8:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        print(\"✓ Enabled TF32 precision (Ampere+ GPU)\")\n",
    "    else:\n",
    "        print(f\"ℹ TF32 not available (requires Ampere+ GPU, you have compute {compute_cap[0]}.{compute_cap[1]})\")\n",
    "    \n",
    "    print(\"✓ CUDA optimizations enabled\")\n",
    "\n",
    "\n",
    "def load_file_content(file_path: Path):\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_model_name(candidate_path: Path):\n",
    "    # .../<run>/exported_valid_code/<variant>/file.ext\n",
    "    try:\n",
    "        return candidate_path.parents[2].name\n",
    "    except IndexError:\n",
    "        return candidate_path.stem\n",
    "\n",
    "\n",
    "def ensure_header(csv_path: Path, columns):\n",
    "    csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if not csv_path.exists():\n",
    "        pd.DataFrame(columns=columns).to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "def get_processed_ids(csv_path: Path):\n",
    "    if not csv_path.exists():\n",
    "        return set()\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, usecols=[\"Candidate_ID\"])\n",
    "        if \"Candidate_ID\" in df.columns:\n",
    "            return set(df[\"Candidate_ID\"].astype(str).dropna())\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading existing CSV {csv_path}: {e}\")\n",
    "    return set()\n",
    "\n",
    "\n",
    "def get_processed_paths(csv_path: Path):\n",
    "    if not csv_path.exists():\n",
    "        return set()\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, usecols=[\"Candidate_Path\"])\n",
    "        if \"Candidate_Path\" in df.columns:\n",
    "            return set(df[\"Candidate_Path\"].astype(str).dropna())\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading existing CSV {csv_path}: {e}\")\n",
    "    return set()\n",
    "\n",
    "\n",
    "def parse_model_fields(raw_model):\n",
    "    \"\"\"Extract base model (phi4|qw32|gpt5) and prompt_level (abla-l1|abla-l2|original) from raw model text.\"\"\"\n",
    "    text = str(raw_model)\n",
    "    if \"_\" in text:\n",
    "        _, text = text.split(\"_\", 1)\n",
    "        \n",
    "    levels = [\"abla-l1\", \"abla-l2\", \"abla-1p\", \"abla-2p\"]\n",
    "    prompt_level = next((lvl for lvl in levels if lvl in text), \"original\")\n",
    "    base_model = next((m for m in (\"phi4\", \"qw32\", \"gpt5\") if m in text), text.split(\"-\")[0])\n",
    "    \n",
    "    # Normalize model names\n",
    "    model_mapping = {\n",
    "        \"gpt5\": \"gpt-5\",\n",
    "        \"qw32\": \"qwen32\",\n",
    "    }\n",
    "    base_model = model_mapping.get(base_model, base_model)\n",
    "    \n",
    "    return base_model, prompt_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa9797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[psg] reference loaded; candidates: 276\n",
      "[sg] reference loaded; candidates: 54\n",
      "[tpusg] reference loaded; candidates: 306\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 3. Load Reference File and Discover Candidates\n",
    "references = {}\n",
    "candidate_sets = {}\n",
    "\n",
    "for key, cfg in CONFIGS.items():\n",
    "    ref_content = load_file_content(cfg[\"reference\"])\n",
    "    if not ref_content:\n",
    "        print(f\"Failed to load reference for {key}: {cfg['reference']}\")\n",
    "        continue\n",
    "    references[key] = ref_content\n",
    "    # search across all runs under langfuse_export (e.g., 2025, 2026, etc.)\n",
    "    candidate_files = sorted(CANDIDATE_ROOT.glob(f\"*/{cfg['candidate_glob']}\"))\n",
    "    candidate_sets[key] = candidate_files\n",
    "    print(f\"[{key}] reference loaded; candidates: {len(candidate_files)}\")\n",
    "\n",
    "# Device selection\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Batch size configuration based on GPU memory\n",
    "if DEVICE == \"cuda\":\n",
    "    total_mem_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    compute_cap = torch.cuda.get_device_capability()\n",
    "    \n",
    "    # Auto-adjust batch size based on available VRAM\n",
    "    if total_mem_gb <= 6:\n",
    "        BATCH_SIZE = 20  # GTX 1060 6GB, GTX 1650, etc.\n",
    "        print(\"⚠️  6GB GPU detected - using batch_size=20 to prevent OOM\")\n",
    "    elif total_mem_gb <= 8:\n",
    "        BATCH_SIZE = 24  # 8GB cards\n",
    "    elif total_mem_gb <= 10:\n",
    "        BATCH_SIZE = 32  # RTX 3060 Ti, RTX 3080 (10GB)\n",
    "    elif total_mem_gb <= 12:\n",
    "        BATCH_SIZE = 48  # RTX 3060 (12GB)\n",
    "    else:\n",
    "        BATCH_SIZE = 64  # 16GB+ cards\n",
    "    \n",
    "    print(f\"Using device: {DEVICE} ({total_mem_gb:.1f}GB)\")\n",
    "    print(f\"Batch size: {BATCH_SIZE}\")\n",
    "else:\n",
    "    BATCH_SIZE = 64\n",
    "    print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dd0ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[psg] wrote 276 rows to /home/han/Projects/benchmark-tinyml_llm-2026/codebertscore-similarity/analyser-results/similarity_results_psg.csv\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_0dfdffec_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_249bc995_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_2faeb813_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_30f9f1ab_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_3a5de86f_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_3b449b78_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_4627f94c_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_49199441_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_49cd8e0b_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_4e623cbc_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_4ec7c427_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_692863bc_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_725c6661_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_778ec4bc_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_90f5cb69_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_9319392b_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_938b5377_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_a2812aef_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_b3e4c436_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_badc00ac_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_bd298eac_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_bead19a2_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_cba6042a_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_dd88e70d_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_ddb5ff7c_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_dfb2d420_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_e009e74d_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_e2f01410_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_e75a438c_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.03_gpt5-mpu/exported_valid_code/sg/sg_f59a55a9_gpt5-mpu.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.08_abla-l1-gpt5/exported_valid_code/sg/sg_716a5c82_abla-l1-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.08_abla-l1-gpt5/exported_valid_code/sg/sg_76bf72db_abla-l1-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.08_abla-l1-gpt5/exported_valid_code/sg/sg_9dffa815_abla-l1-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_02cd0534_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_27620f1a_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_29ddee84_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_37611813_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_44a56389_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_4fc4db54_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_6159c1a4_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_751d37b5_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_781677be_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_7cecd391_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_7d3a1772_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_84f8ec32_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_8e15fa49_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_8fa46ebd_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_965d71e2_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_a6d6b188_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_ab48aa4f_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_c19e3372_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_cc2ad6db_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_d4e8d0e9_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] Error processing /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.09_abla-l2-gpt5/exported_valid_code/sg/sg_f9891987_abla-l2-gpt5.ino: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\n",
      "See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n",
      "[sg] no new rows written\n"
     ]
    }
   ],
   "source": [
    "# 4. Run Similarity Scoring Loop (All Three Scripts)\n",
    "results = {}\n",
    "common_columns = [\n",
    "    \"Candidate_ID\",\n",
    "    \"Model\",\n",
    "    \"prompt_level\",\n",
    "    \"Precision\",\n",
    "    \"Recall\",\n",
    "    \"F1\",\n",
    "    \"F3\",\n",
    "    # \"Reference_File\",\n",
    "    # \"Language\",\n",
    "    \"Processor\",\n",
    "    # \"Timestamp\",\n",
    "]\n",
    "\n",
    "for key, cfg in CONFIGS.items():\n",
    "    ensure_header(cfg[\"output_csv\"], common_columns)\n",
    "    processed_ids = get_processed_ids(cfg[\"output_csv\"])\n",
    "    candidate_files = candidate_sets.get(key, [])\n",
    "    ref_content = references.get(key)\n",
    "    if not ref_content:\n",
    "        continue\n",
    "\n",
    "    loop_records = []\n",
    "    for candidate_path in candidate_files:\n",
    "        candidate_id = candidate_path.relative_to(PROJECT_ROOT).as_posix()\n",
    "        if candidate_id in processed_ids:\n",
    "            continue\n",
    "\n",
    "        candidate_content = load_file_content(candidate_path)\n",
    "        if not candidate_content:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            P, R, F1, F3 = code_bert_score.score(\n",
    "                cands=[candidate_content],\n",
    "                refs=[ref_content],\n",
    "                lang=cfg[\"lang\"],\n",
    "                device=DEVICE,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                verbose=False,\n",
    "            )\n",
    "\n",
    "            p_val = P[0].item()\n",
    "            r_val = R[0].item()\n",
    "            f1_val = F1[0].item()\n",
    "            f3_val = F3[0].item()\n",
    "\n",
    "            model_name = extract_model_name(candidate_path)\n",
    "            base_model, prompt_level = parse_model_fields(model_name)\n",
    "            timestamp = datetime.now().isoformat()\n",
    "\n",
    "            record = {\n",
    "                \"Candidate_ID\": candidate_id,\n",
    "                \"Model\": base_model,\n",
    "                \"prompt_level\": prompt_level,\n",
    "                \"Precision\": p_val,\n",
    "                \"Recall\": r_val,\n",
    "                \"F1\": f1_val,\n",
    "                \"F3\": f3_val,\n",
    "                # \"Reference_File\": cfg[\"reference\"],\n",
    "                # \"Language\": cfg[\"lang\"],\n",
    "                \"Processor\": key,\n",
    "                # \"Timestamp\": timestamp,\n",
    "            }\n",
    "            loop_records.append(record)\n",
    "        except Exception as e:\n",
    "            print(f\"[{key}] Error processing {candidate_path}: {e}\")\n",
    "\n",
    "    if loop_records:\n",
    "        df_loop = pd.DataFrame(loop_records)\n",
    "        df_loop.to_csv(cfg[\"output_csv\"], mode=\"a\", header=False, index=False)\n",
    "        results[key] = df_loop\n",
    "        print(f\"[{key}] wrote {len(df_loop)} rows to {cfg['output_csv']}\")\n",
    "    else:\n",
    "        print(f\"[{key}] no new rows written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b7ccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined rows: 582\n",
      "Run counts (candidates -> csv rows):\n",
      "psg: 276 candidates; 276 rows in csv\n",
      "sg: 54 candidates; 0 rows in csv\n",
      "tpusg: 306 candidates; 306 rows in csv\n",
      "Totals discovered: 636 candidates across runs; 582 rows across csvs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2113783/2131280265.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined = pd.concat(merged, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# 5. Append and Merge CSV Outputs\n",
    "merged = []\n",
    "run_candidate_counts = {k: len(v) for k, v in candidate_sets.items()}\n",
    "output_row_counts = {}\n",
    "for key, cfg in CONFIGS.items():\n",
    "    if cfg[\"output_csv\"].exists():\n",
    "        try:\n",
    "            df = pd.read_csv(cfg[\"output_csv\"])\n",
    "            df[\"run\"] = key\n",
    "            merged.append(df)\n",
    "            output_row_counts[key] = len(df)\n",
    "        except Exception as e:\n",
    "            print(f\"[{key}] Error reading {cfg['output_csv']}: {e}\")\n",
    "\n",
    "# 1. Filter out empty DataFrames to avoid the warning\n",
    "valid_merged = [df for df in merged if not df.empty]\n",
    "\n",
    "# 2. Check if there are any valid DataFrames left to concatenate\n",
    "if valid_merged:\n",
    "    combined = pd.concat(valid_merged, ignore_index=True)\n",
    "    print(f\"Combined rows: {len(combined)}\")\n",
    "else:\n",
    "    combined = pd.DataFrame()\n",
    "    print(\"No CSVs to combine yet.\")\n",
    "\n",
    "print(\"Run counts (candidates -> csv rows):\")\n",
    "for key in CONFIGS:\n",
    "    cand = run_candidate_counts.get(key, 0)\n",
    "    rows = output_row_counts.get(key, 0)\n",
    "    print(f\"{key}: {cand} candidates; {rows} rows in csv\")\n",
    "total_candidates = sum(run_candidate_counts.values())\n",
    "total_rows = sum(output_row_counts.values())\n",
    "print(f\"Totals discovered: {total_candidates} candidates across runs; {total_rows} rows across csvs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b667a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate_ID</th>\n",
       "      <th>Model</th>\n",
       "      <th>prompt_level</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>F3</th>\n",
       "      <th>Processor</th>\n",
       "      <th>run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>langfuse_export/2025/07.30_abla-og-phi4/export...</td>\n",
       "      <td>phi4</td>\n",
       "      <td>original</td>\n",
       "      <td>0.874021</td>\n",
       "      <td>0.820260</td>\n",
       "      <td>0.846288</td>\n",
       "      <td>0.825337</td>\n",
       "      <td>psg</td>\n",
       "      <td>psg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>langfuse_export/2025/07.30_abla-og-phi4/export...</td>\n",
       "      <td>phi4</td>\n",
       "      <td>original</td>\n",
       "      <td>0.891725</td>\n",
       "      <td>0.831951</td>\n",
       "      <td>0.860802</td>\n",
       "      <td>0.837565</td>\n",
       "      <td>psg</td>\n",
       "      <td>psg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>langfuse_export/2025/07.30_abla-og-phi4/export...</td>\n",
       "      <td>phi4</td>\n",
       "      <td>original</td>\n",
       "      <td>0.885038</td>\n",
       "      <td>0.815476</td>\n",
       "      <td>0.848834</td>\n",
       "      <td>0.821936</td>\n",
       "      <td>psg</td>\n",
       "      <td>psg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>langfuse_export/2025/07.30_abla-og-phi4/export...</td>\n",
       "      <td>phi4</td>\n",
       "      <td>original</td>\n",
       "      <td>0.897614</td>\n",
       "      <td>0.819714</td>\n",
       "      <td>0.856897</td>\n",
       "      <td>0.826891</td>\n",
       "      <td>psg</td>\n",
       "      <td>psg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>langfuse_export/2025/07.30_abla-og-phi4/export...</td>\n",
       "      <td>phi4</td>\n",
       "      <td>original</td>\n",
       "      <td>0.874875</td>\n",
       "      <td>0.789581</td>\n",
       "      <td>0.830043</td>\n",
       "      <td>0.797354</td>\n",
       "      <td>psg</td>\n",
       "      <td>psg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Candidate_ID Model prompt_level  \\\n",
       "0  langfuse_export/2025/07.30_abla-og-phi4/export...  phi4     original   \n",
       "1  langfuse_export/2025/07.30_abla-og-phi4/export...  phi4     original   \n",
       "2  langfuse_export/2025/07.30_abla-og-phi4/export...  phi4     original   \n",
       "3  langfuse_export/2025/07.30_abla-og-phi4/export...  phi4     original   \n",
       "4  langfuse_export/2025/07.30_abla-og-phi4/export...  phi4     original   \n",
       "\n",
       "   Precision    Recall        F1        F3 Processor  run  \n",
       "0   0.874021  0.820260  0.846288  0.825337       psg  psg  \n",
       "1   0.891725  0.831951  0.860802  0.837565       psg  psg  \n",
       "2   0.885038  0.815476  0.848834  0.821936       psg  psg  \n",
       "3   0.897614  0.819714  0.856897  0.826891       psg  psg  \n",
       "4   0.874875  0.789581  0.830043  0.797354       psg  psg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate_ID</th>\n",
       "      <th>Model</th>\n",
       "      <th>prompt_level</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>F3</th>\n",
       "      <th>Processor</th>\n",
       "      <th>run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>langfuse_export/2026/02.23_abla-2p-phi4/export...</td>\n",
       "      <td>phi4</td>\n",
       "      <td>abla-2p</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.848934</td>\n",
       "      <td>0.879350</td>\n",
       "      <td>0.854848</td>\n",
       "      <td>tpusg</td>\n",
       "      <td>tpusg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>langfuse_export/2026/02.23_abla-2p-phi4/export...</td>\n",
       "      <td>phi4</td>\n",
       "      <td>abla-2p</td>\n",
       "      <td>0.902719</td>\n",
       "      <td>0.850820</td>\n",
       "      <td>0.876002</td>\n",
       "      <td>0.855740</td>\n",
       "      <td>tpusg</td>\n",
       "      <td>tpusg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>langfuse_export/2026/02.23_abla-2p-phi4/export...</td>\n",
       "      <td>phi4</td>\n",
       "      <td>abla-2p</td>\n",
       "      <td>0.902719</td>\n",
       "      <td>0.850820</td>\n",
       "      <td>0.876002</td>\n",
       "      <td>0.855740</td>\n",
       "      <td>tpusg</td>\n",
       "      <td>tpusg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>langfuse_export/2026/02.23_abla-2p-phi4/export...</td>\n",
       "      <td>phi4</td>\n",
       "      <td>abla-2p</td>\n",
       "      <td>0.911781</td>\n",
       "      <td>0.846815</td>\n",
       "      <td>0.878098</td>\n",
       "      <td>0.852892</td>\n",
       "      <td>tpusg</td>\n",
       "      <td>tpusg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>langfuse_export/2026/02.23_abla-2p-phi4/export...</td>\n",
       "      <td>phi4</td>\n",
       "      <td>abla-2p</td>\n",
       "      <td>0.911781</td>\n",
       "      <td>0.846815</td>\n",
       "      <td>0.878098</td>\n",
       "      <td>0.852892</td>\n",
       "      <td>tpusg</td>\n",
       "      <td>tpusg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Candidate_ID Model prompt_level  \\\n",
       "577  langfuse_export/2026/02.23_abla-2p-phi4/export...  phi4      abla-2p   \n",
       "578  langfuse_export/2026/02.23_abla-2p-phi4/export...  phi4      abla-2p   \n",
       "579  langfuse_export/2026/02.23_abla-2p-phi4/export...  phi4      abla-2p   \n",
       "580  langfuse_export/2026/02.23_abla-2p-phi4/export...  phi4      abla-2p   \n",
       "581  langfuse_export/2026/02.23_abla-2p-phi4/export...  phi4      abla-2p   \n",
       "\n",
       "     Precision    Recall        F1        F3 Processor    run  \n",
       "577   0.912027  0.848934  0.879350  0.854848     tpusg  tpusg  \n",
       "578   0.902719  0.850820  0.876002  0.855740     tpusg  tpusg  \n",
       "579   0.902719  0.850820  0.876002  0.855740     tpusg  tpusg  \n",
       "580   0.911781  0.846815  0.878098  0.852892     tpusg  tpusg  \n",
       "581   0.911781  0.846815  0.878098  0.852892     tpusg  tpusg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts by run:\n",
      "run\n",
      "psg      276\n",
      "tpusg    306\n",
      "Name: Candidate_ID, dtype: int64\n",
      "F1 stats:\n",
      "count    582.000000\n",
      "mean       0.857054\n",
      "std        0.022642\n",
      "min        0.615672\n",
      "25%        0.841676\n",
      "50%        0.863350\n",
      "75%        0.871842\n",
      "max        0.889104\n",
      "Name: F1, dtype: float64\n",
      "Coverage (rows vs discovered candidates):\n",
      "psg: 276 rows vs 276 candidates\n",
      "sg: 0 rows vs 54 candidates\n",
      "tpusg: 306 rows vs 306 candidates\n",
      "Total candidates: 636; total rows: 582\n"
     ]
    }
   ],
   "source": [
    "# 6. Quick Summary and Verification\n",
    "if not combined.empty:\n",
    "    display(combined.head())\n",
    "    display(combined.tail())\n",
    "    print(\"Counts by run:\")\n",
    "    print(combined.groupby(\"run\")[\"Candidate_ID\"].count())\n",
    "    print(\"F1 stats:\")\n",
    "    print(combined[\"F1\"].describe())\n",
    "    discovered = {k: len(v) for k, v in candidate_sets.items()}\n",
    "    print(\"Coverage (rows vs discovered candidates):\")\n",
    "    for key in CONFIGS:\n",
    "        rows = len(combined[combined[\"run\"] == key])\n",
    "        print(f\"{key}: {rows} rows vs {discovered.get(key, 0)} candidates\")\n",
    "    print(f\"Total candidates: {sum(discovered.values())}; total rows: {len(combined)}\")\n",
    "else:\n",
    "    print(\"No data to summarize yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psg: cleaned 276 rows -> /home/han/Projects/benchmark-tinyml_llm-2026/codebertscore-similarity/analyser-results/similarity_results_psg.csv\n",
      "sg: /home/han/Projects/benchmark-tinyml_llm-2026/codebertscore-similarity/analyser-results/similarity_results_sg.csv empty, skipping\n",
      "tpusg: cleaned 306 rows -> /home/han/Projects/benchmark-tinyml_llm-2026/codebertscore-similarity/analyser-results/similarity_results_tpusg.csv\n",
      "Backfill complete.\n"
     ]
    }
   ],
   "source": [
    "# 7. Backfill prompt_level and normalize Model for existing CSV outputs\n",
    "\n",
    "def parse_from_candidate_id(candidate_id: str):\n",
    "    \"\"\"Derive base model and prompt level from the Candidate_ID path token.\"\"\"\n",
    "    text = str(candidate_id)\n",
    "    run_segment = next(\n",
    "        (seg for seg in Path(text).parts if \"abla\" in seg or \"original\" in seg or \"og\" in seg),\n",
    "        text,\n",
    "    )\n",
    "    return parse_model_fields(run_segment)\n",
    "\n",
    "def backfill_outputs():\n",
    "    for c in [\"psg\", \"sg\", \"tpusg\"]:\n",
    "        csv_path = CONFIGS[c][\"output_csv\"]\n",
    "        if not csv_path.exists():\n",
    "            print(f\"{c}: {csv_path} missing, skipping\")\n",
    "            continue\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if df.empty:\n",
    "            print(f\"{c}: {csv_path} empty, skipping\")\n",
    "            continue\n",
    "        if \"Candidate_ID\" not in df.columns:\n",
    "            print(f\"{c}: Candidate_ID missing in {csv_path}, skipping backfill\")\n",
    "            continue\n",
    "        base_prompt = df[\"Candidate_ID\"].apply(parse_from_candidate_id).apply(pd.Series)\n",
    "        df[\"Model\"] = base_prompt[0]\n",
    "        df[\"prompt_level\"] = base_prompt[1]\n",
    "        if \"Candidate_Path\" in df.columns:\n",
    "            df = df.drop(columns=[\"Candidate_Path\"])\n",
    "        ordered_cols = [\n",
    "            \"Candidate_ID\",\n",
    "            \"Model\",\n",
    "            \"Precision\",\n",
    "            \"Recall\",\n",
    "            \"F1\",\n",
    "            \"F3\",\n",
    "            \"Processor\",\n",
    "            \"prompt_level\",\n",
    "        ]\n",
    "        df = df[[col for col in ordered_cols if col in df.columns]]\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"{c}: cleaned {len(df)} rows -> {csv_path}\")\n",
    "    print(\"Backfill complete.\")\n",
    "\n",
    "backfill_outputs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb3a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
