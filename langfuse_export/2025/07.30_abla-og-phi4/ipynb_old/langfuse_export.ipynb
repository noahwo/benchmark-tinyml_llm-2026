{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"phi4_85a9_psg_batch\",\n",
    "    \"phi4_85a9_tpusg_batch\"\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session phi4_85a9_psg_batch...\n",
      "Fetching observation data for time-18-11-28-752536_chatcmpl-dd956ed8-abdc-408e-9c8f-c9bc3d1a9594...\n",
      "Fetching observation data for time-18-11-45-698913_chatcmpl-acc8789c-241f-4f5b-9b8e-ecc7bda7987a...\n",
      "Fetching observation data for time-18-12-04-495158_chatcmpl-d067075c-3d0a-4479-9b69-0d84084be3e4...\n",
      "Fetching observation data for time-18-12-24-964026_chatcmpl-ca177c87-4371-4951-9a6f-0be42299218a...\n",
      "Fetching observation data for time-18-12-43-791408_chatcmpl-82fdc107-3ae2-445e-b0b1-3172542ea287...\n",
      "Fetching observation data for b4e23925-a38a-4a1a-85e9-a3bada9f3f25...\n",
      "Fetching observation data for time-18-10-41-237832_chatcmpl-03dfd56e-6a03-4647-bd68-7b30f973434b...\n",
      "Fetching observation data for time-18-10-59-085548_chatcmpl-499a67f9-8c52-47d8-903a-3636f79339c1...\n",
      "Fetching observation data for time-18-08-51-704470_chatcmpl-7a8d1acb-adac-4a43-8c18-4e4c68ede989...\n",
      "Fetching observation data for time-18-09-09-231708_chatcmpl-dd88f9db-a3fc-4d88-afeb-f83b4bbe8760...\n",
      "Fetching observation data for time-18-09-32-359617_chatcmpl-2afdc219-cde1-4ea3-8e02-e42627d21934...\n",
      "Fetching observation data for time-18-09-54-401037_chatcmpl-5911012f-c791-4185-8c8b-ead52da92a93...\n",
      "Fetching observation data for time-18-10-14-727367_chatcmpl-fbc448bf-d2e6-4de2-a7d0-60070ff8b58d...\n",
      "Fetching observation data for 46351dd3-33d3-4080-91c6-e651b274d6d9...\n",
      "Fetching observation data for time-18-07-13-824910_chatcmpl-a450d995-0040-4477-9ac5-706c18abbcb9...\n",
      "Fetching observation data for time-18-07-26-382952_chatcmpl-09eeadb6-f3e2-4c2c-ba3c-84529b9dc8fe...\n",
      "Fetching observation data for time-18-07-46-838011_chatcmpl-cbeff0fb-873b-400e-8889-52666a819bb7...\n",
      "Fetching observation data for time-18-08-04-703207_chatcmpl-07048276-ced3-473c-b6d3-20393e9a046a...\n",
      "Fetching observation data for time-18-08-25-008617_chatcmpl-ff1464b3-0ef9-4a3a-9747-a7a87a8a5a93...\n",
      "Fetching observation data for time-18-06-19-637546_chatcmpl-25953c1c-9c41-4458-a224-54d438ec1e71...\n",
      "Fetching observation data for time-18-04-43-152025_chatcmpl-12ba9e10-82ec-4f22-a15b-a1953bc00dc5...\n",
      "Fetching observation data for time-18-04-57-593920_chatcmpl-ab4677c6-1d85-4a21-b06e-ddf12a845577...\n",
      "Fetching observation data for time-18-05-15-297091_chatcmpl-c31b57c5-a4fe-4bc2-95a2-9346f6063a1e...\n",
      "Fetching observation data for time-18-05-33-490748_chatcmpl-4cec265d-9834-4451-b2fc-ff97908027ad...\n",
      "Fetching observation data for time-18-05-53-964860_chatcmpl-57e93528-cc26-450e-84ce-1c84c2a3bf28...\n",
      "Fetching observation data for 6c0aab8d-1f7a-4632-9f4a-655c72f48600...\n",
      "Fetching observation data for time-18-03-27-641041_chatcmpl-e4e52dc2-b0be-4672-8b72-973c404da093...\n",
      "Fetching observation data for time-18-03-44-879744_chatcmpl-9e7d0430-b1a1-4eb3-aacc-dda87a765b07...\n",
      "Fetching observation data for time-18-04-05-659420_chatcmpl-921692ee-ea12-489e-8274-cd778aafebd7...\n",
      "Fetching observation data for time-18-04-24-356546_chatcmpl-48fb09be-0656-4c37-9708-09136f42ae6f...\n",
      "Fetching observation data for time-18-02-01-022127_chatcmpl-810b550c-10d0-468a-98af-0d7928a15191...\n",
      "Fetching observation data for time-18-02-16-120531_chatcmpl-59e56eed-ad2b-4227-aecf-ce4583bd9d1f...\n",
      "Fetching observation data for time-18-02-33-077298_chatcmpl-33b47b0c-f9bb-4b39-8617-031edfe060d6...\n",
      "Fetching observation data for time-18-02-45-994255_chatcmpl-2d5685c1-810f-4f1b-b4fc-e74968064c2d...\n",
      "Fetching observation data for time-18-03-03-225272_chatcmpl-3c8af179-f40a-46b8-9773-19b66b8795a1...\n",
      "Fetching observation data for 8bc369c4-75b9-4165-8a72-9faece038cf3...\n",
      "Fetching observation data for time-18-00-23-516288_chatcmpl-4d077418-093d-4be3-8a48-1b823f4dfb60...\n",
      "Fetching observation data for time-18-00-38-520216_chatcmpl-f25661a6-732b-46f5-9f6c-0194cf2faa1b...\n",
      "Fetching observation data for time-18-00-57-854231_chatcmpl-b948599d-fb43-47eb-9f87-6df8d51220b7...\n",
      "Fetching observation data for time-18-01-18-909427_chatcmpl-61eb79bc-39e7-4fb1-8fe2-8145ed5d04c4...\n",
      "Fetching observation data for time-18-01-38-000251_chatcmpl-048ae5f0-ddd4-4b77-ab9d-1057caac9aed...\n",
      "Fetching observation data for 3bb162fb-ce39-4506-b748-64ddb7fce151...\n",
      "Fetching observation data for time-17-59-28-518678_chatcmpl-7a320247-74f8-495b-980d-9d3fdf06fff2...\n",
      "Fetching observation data for time-17-57-55-975338_chatcmpl-cabd4288-2820-4ec1-a8ab-34897ee9e9f1...\n",
      "Fetching observation data for time-17-58-09-691446_chatcmpl-d37b89dc-36ee-461e-b2a7-eaa65feaf47a...\n",
      "Fetching observation data for time-17-58-31-476670_chatcmpl-e814d142-f59a-4ddb-94ea-e17149136e59...\n",
      "Fetching observation data for time-17-58-44-558939_chatcmpl-68131539-5e4f-4932-9689-af7129716b82...\n",
      "Fetching observation data for time-17-59-02-325327_chatcmpl-4e8c39a5-36a2-4ebe-b6fd-503e98273e62...\n",
      "Fetching observation data for edeebc8f-a6c4-4b2b-9398-ea279d760217...\n",
      "Fetching observation data for time-17-57-03-414261_chatcmpl-aa7118b5-507d-4e01-9da7-d6435f46ce43...\n",
      "Fetching observation data for time-17-55-21-238759_chatcmpl-4844fe0f-5907-4caa-ac09-4cd54594b3e6...\n",
      "Fetching observation data for time-17-55-41-455349_chatcmpl-1cc2b5e0-6bf0-4184-ae65-0dbd72c823a6...\n",
      "Fetching observation data for time-17-55-57-514928_chatcmpl-e08cfcdd-32d4-4ccd-9541-5e9596449929...\n",
      "Fetching observation data for time-17-56-16-280889_chatcmpl-ffe79292-c44b-42d1-8e7b-de8bbb519618...\n",
      "Fetching observation data for time-17-56-36-111326_chatcmpl-611870d5-6e79-4683-b2b2-46182e166703...\n",
      "Fetching observation data for 00ce3c78-33f2-4fe4-9cc5-9251bec18075...\n",
      "Fetching observation data for time-17-53-35-144104_chatcmpl-2501f5a1-9c01-4644-84df-420fb3ee30a0...\n",
      "Fetching observation data for time-17-53-49-703263_chatcmpl-ef78a670-2ac3-4392-b218-0bd83d75c67e...\n",
      "Fetching observation data for time-17-54-12-084352_chatcmpl-3c636a29-33df-4384-8a23-38008cd772d3...\n",
      "Fetching observation data for time-17-54-37-959428_chatcmpl-41d8460c-a113-4807-9c63-bc9f241707de...\n",
      "Fetching observation data for time-17-54-54-801671_chatcmpl-87dd58f4-3c6a-4479-9748-34b34d78ada2...\n",
      "Fetching observation data for 3960c323-e21e-4e7c-80ed-f889d37db6f7...\n",
      "Fetching observation data for time-17-52-19-644291_chatcmpl-5e6d082b-f964-4770-9bbf-4e63414b041a...\n",
      "Fetching observation data for time-17-52-35-847451_chatcmpl-058fdd91-cc21-4cd2-9b8a-e87f6d61ac6f...\n",
      "Fetching observation data for time-17-52-52-502926_chatcmpl-815be0a0-a67d-447e-babb-5b70e0582733...\n",
      "Fetching observation data for time-17-53-07-630083_chatcmpl-6179f7ed-1800-4586-9b89-e2a03cd896ce...\n",
      "Fetching observation data for time-17-51-23-140350_chatcmpl-329e2c52-38d4-4be0-8b56-d2452fe40bf8...\n",
      "Fetching observation data for time-17-51-37-224868_chatcmpl-4fdf15b0-f7cc-4b83-9e40-12707d62a4ca...\n",
      "Fetching observation data for time-17-51-56-478203_chatcmpl-0c936ff3-8b2c-4541-90a5-afe229329965...\n",
      "Fetching observation data for time-17-49-52-533117_chatcmpl-1adeaca7-8166-46f6-8057-352099c487b4...\n",
      "Fetching observation data for time-17-50-09-275903_chatcmpl-af1cd419-667f-4cf0-a185-ec405030c1bc...\n",
      "Fetching observation data for time-17-50-27-173025_chatcmpl-4fdfb62f-2a67-4650-b46b-082d26c49353...\n",
      "Fetching observation data for time-17-50-45-186091_chatcmpl-d46543a4-c5c5-446e-93c5-0cf8b5f0f8d0...\n",
      "Fetching observation data for time-17-51-02-532568_chatcmpl-2531cd39-3632-423a-b2da-f7c72a4ec15c...\n",
      "Fetching observation data for 06f92596-3067-4c9d-9526-5331c75842fc...\n",
      "Fetching observation data for time-17-47-49-959042_chatcmpl-a8509032-0c63-4348-bfdd-3e300f2dd0a5...\n",
      "Fetching observation data for time-17-48-30-143058_chatcmpl-083a3c7c-062e-44cf-8999-bd0bed58f08b...\n",
      "Fetching observation data for time-17-48-46-407968_chatcmpl-5e6503cf-5d4e-401f-a198-af53f6b6e9b9...\n",
      "Fetching observation data for time-17-49-02-618771_chatcmpl-c7f4bfbf-b337-422c-9264-5a1381d67187...\n",
      "Fetching observation data for time-17-49-26-627518_chatcmpl-c9679421-da5c-40e6-a08c-58fc53f6857f...\n",
      "Fetching observation data for time-17-46-14-361591_chatcmpl-c5d99aa3-8cad-47cc-bc4d-3e4f2983b31e...\n",
      "Fetching observation data for time-17-46-33-714068_chatcmpl-b40f6624-2884-4b9f-a66a-a06d25852a95...\n",
      "Fetching observation data for time-17-46-51-406951_chatcmpl-ff176136-f244-4125-866a-4608c20e7a42...\n",
      "Fetching observation data for time-17-47-08-791840_chatcmpl-35b670ed-8189-477e-856a-116ad20f64ab...\n",
      "Fetching observation data for time-17-47-24-979717_chatcmpl-9f8a1dfb-eb72-47a3-a621-12965de7ad17...\n",
      "Fetching observation data for time-17-44-35-783635_chatcmpl-ed328c1f-03e6-4858-ba2d-bc80a8464ad2...\n",
      "Fetching observation data for time-17-44-48-910425_chatcmpl-1e5fefc2-5f06-4c16-b790-f3f3a04a1aba...\n",
      "Fetching observation data for time-17-45-08-682961_chatcmpl-02f1bf68-61f1-4bbc-8c36-03323acd3bf9...\n",
      "Fetching observation data for time-17-45-25-334990_chatcmpl-06f30927-f7f3-4aaf-82fa-6c4575c58e1d...\n",
      "Fetching observation data for time-17-43-03-257944_chatcmpl-806c6682-8e8d-4728-85cb-715fb7152f51...\n",
      "Fetching observation data for time-17-43-21-750827_chatcmpl-e0230eb8-6d01-479c-ba32-84d00b7c8d8a...\n",
      "Fetching observation data for time-17-43-37-216616_chatcmpl-3dee92c4-c939-4318-b60e-e5336c4672c8...\n",
      "Fetching observation data for time-17-43-53-466684_chatcmpl-4fc9abec-be0b-4096-83c6-2df63c9feabe...\n",
      "Fetching observation data for time-17-44-12-986292_chatcmpl-4b532150-4f30-4736-b21a-7c7c44352260...\n",
      "Fetching observation data for bd88c8f8-6696-4b64-823f-3daee44501c8...\n",
      "Fetching observation data for time-17-41-39-738546_chatcmpl-3408d067-5027-48b7-b988-747b4bb00ee9...\n",
      "Fetching observation data for time-17-41-52-462998_chatcmpl-977c50b5-19c2-434d-b52f-070b4dd6ce1d...\n",
      "Fetching observation data for time-17-42-07-936497_chatcmpl-2fdd5b82-18c5-43b9-8b7f-e16fb84e8dd1...\n",
      "Fetching observation data for time-17-42-25-173028_chatcmpl-7c497f76-adad-416f-b0ad-5154069fbbb3...\n",
      "Fetching observation data for time-17-42-44-758630_chatcmpl-218e556a-3b74-4717-aa64-e7dae9e0dd22...\n",
      "Fetching observation data for time-17-40-09-222882_chatcmpl-3dc38c6c-16ba-47c4-ad3f-eb5ed00b4acb...\n",
      "Fetching observation data for time-17-40-24-740891_chatcmpl-5fcae92f-5ae9-44a8-a9ef-a04369134623...\n",
      "Fetching observation data for time-17-40-43-649803_chatcmpl-fc93cea3-890c-402a-85b2-e51f61886b19...\n",
      "Fetching observation data for time-17-41-04-118806_chatcmpl-fed17400-4564-4266-9324-e49f02c735e5...\n",
      "Fetching observation data for time-17-41-18-445230_chatcmpl-046c250f-3986-4563-a44c-16593da8aa29...\n",
      "Fetching observation data for d880391b-ab02-4b55-bb65-0d2cb1ab37bf...\n",
      "Fetching observation data for time-17-38-37-704174_chatcmpl-d5834686-5697-4cff-a397-e08b32e18bb4...\n",
      "Fetching observation data for time-17-38-54-816549_chatcmpl-c0a7a442-9b9d-49f9-8636-0484873eb864...\n",
      "Fetching observation data for time-17-39-14-252496_chatcmpl-099eff5a-8f41-4478-9188-5067c6c58ac8...\n",
      "Fetching observation data for time-17-39-29-755471_chatcmpl-fd96eb03-b17b-4d5a-bc1f-c3c5572e497e...\n",
      "Fetching observation data for time-17-39-46-597277_chatcmpl-952df35d-8b75-490a-80ca-2d5c5352fc2c...\n",
      "Fetching observation data for 72db5a31-6638-403f-a2a4-d806cabcf858...\n",
      "Fetching observation data for time-17-37-42-207485_chatcmpl-6d7f1cc4-9e65-4585-9c8e-8b47cd7c9186...\n",
      "Fetching observation data for time-17-37-57-476630_chatcmpl-0fdeeb73-4597-4ad5-9701-ab04a2647431...\n",
      "Fetching observation data for time-17-38-13-584192_chatcmpl-c4e42a79-9fe3-4daf-a80d-6abb9e8db500...\n",
      "Fetching observation data for time-17-36-49-696875_chatcmpl-8b88a0ad-31e2-4f18-9519-9eaa9ab37cc0...\n",
      "Fetching observation data for time-17-35-56-205786_chatcmpl-d63b9bca-cf49-494d-9f52-47f94bd5ff68...\n",
      "Fetching observation data for time-17-35-04-680468_chatcmpl-4558fdee-1db4-421b-85cb-99d33abcbcff...\n",
      "Fetching observation data for time-17-33-51-133199_chatcmpl-30c8d523-ee10-492e-87c1-abb37bfbe3d3...\n",
      "Fetching observation data for time-17-34-07-605954_chatcmpl-012ed8b2-919d-4c8b-8d05-6ffea4bf54b3...\n",
      "Fetching observation data for time-17-34-31-607658_chatcmpl-a9fbea91-0d2e-4a4d-91ab-3cc3f2c4bd37...\n",
      "Fetching observation data for time-17-31-56-606856_chatcmpl-21b31c34-bb13-4b9e-8d89-ce794931d3fa...\n",
      "Fetching observation data for time-17-32-15-092665_chatcmpl-d4648ed9-022e-4d34-8328-8a7e8e21d815...\n",
      "Fetching observation data for time-17-32-34-606362_chatcmpl-743b4412-538b-493b-878c-dfc31c22404a...\n",
      "Fetching observation data for time-17-32-52-512616_chatcmpl-c5c402d5-63bd-423f-a37c-c4101a4c594c...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/langfuse_export/07.30/raw_export/raw_phi4_85a9_psg_batch.json\n",
      "Fetching traces for session phi4_85a9_tpusg_batch...\n",
      "Fetching observation data for time-17-30-41-093456_chatcmpl-47912e18-97d7-4d0f-8767-8c0e9fb2ebf1...\n",
      "Fetching observation data for time-17-29-22-587537_chatcmpl-5ca74e09-36be-4917-af35-040edc49d70e...\n",
      "Fetching observation data for time-17-28-04-054968_chatcmpl-1ed036dc-7b2c-4fd1-989e-bcef2cb213be...\n",
      "Fetching observation data for time-17-26-18-996305_chatcmpl-0a0f4c67-8245-4245-bd4b-f65f4cf0a3e2...\n",
      "Fetching observation data for time-17-26-44-069414_chatcmpl-102937f2-afc0-48cb-8377-0e58955f6c4a...\n",
      "Fetching observation data for time-17-24-26-511058_chatcmpl-810927b5-d823-4f57-88ab-d94e8c8e9faa...\n",
      "Fetching observation data for time-17-24-55-644371_chatcmpl-fc60186e-c294-4b1d-87e3-2744f0643b82...\n",
      "Fetching observation data for time-17-23-08-023013_chatcmpl-10a9a7b9-ab63-4b5b-a0c6-4aa16f779071...\n",
      "Fetching observation data for time-17-21-19-200179_chatcmpl-cb85afac-7052-4cce-bbf1-04619f8d2a2a...\n",
      "Fetching observation data for time-17-21-45-644444_chatcmpl-467af3b0-8358-4d22-b8b3-a5b26c8f8f24...\n",
      "Fetching observation data for time-17-20-04-715296_chatcmpl-46412d08-bfe5-46d0-98a5-50d0eedeaa23...\n",
      "Fetching observation data for time-17-18-45-212091_chatcmpl-02ac8e7b-9ca3-411f-b16a-26df425a97da...\n",
      "Fetching observation data for time-17-17-25-653976_chatcmpl-31494601-1a5d-449c-b5e6-2ca8a67d9dd2...\n",
      "Fetching observation data for time-17-16-07-101715_chatcmpl-8765d3ac-c3aa-47ee-b819-8286f0e96b1b...\n",
      "Fetching observation data for time-17-14-47-580125_chatcmpl-cb553b4a-4dcc-4533-a0f9-d647a1a845d1...\n",
      "Fetching observation data for time-17-13-30-034118_chatcmpl-0a35a490-b443-42fe-bfdd-b0648b512b51...\n",
      "Fetching observation data for time-17-11-44-506065_chatcmpl-4ae4c7c1-e564-4892-947d-84e965e5e11d...\n",
      "Fetching observation data for time-17-12-09-451780_chatcmpl-6bf7de82-01fd-42ee-b266-1830195a2ec6...\n",
      "Fetching observation data for time-17-09-52-932763_chatcmpl-bee389da-a425-403d-8871-8def13c83a63...\n",
      "Fetching observation data for time-17-10-23-353297_chatcmpl-d9ed75a3-c347-4179-8dd0-f58efd91e762...\n",
      "Fetching observation data for time-17-07-35-418284_chatcmpl-95119d10-db59-487f-b01d-42fa408b309b...\n",
      "Fetching observation data for time-17-08-01-770971_chatcmpl-1755c3ea-d0dc-4a72-a1e7-150b82504d82...\n",
      "Fetching observation data for time-17-08-33-208428_chatcmpl-bd0f1448-303c-415d-8667-ca7098cfa20d...\n",
      "Fetching observation data for time-17-06-15-921349_chatcmpl-9fd51585-efff-4bef-a3b2-cc0f1c75ca26...\n",
      "Fetching observation data for time-17-03-24-312431_chatcmpl-3abf618f-80f3-4c45-9df2-13bb9240f590...\n",
      "Fetching observation data for time-17-03-54-859661_chatcmpl-e3427f95-2955-4ac7-96aa-e6e92f6d4b21...\n",
      "Fetching observation data for time-17-04-29-108881_chatcmpl-68eab2a9-116b-469a-afc7-26a6e80f33f0...\n",
      "Fetching observation data for time-17-04-55-345927_chatcmpl-ddb15fe4-1aa4-4681-b8c5-e3270e7c7b1a...\n",
      "Fetching observation data for time-17-02-03-768816_chatcmpl-4377686e-c3a3-4d20-862a-222d4b4550fa...\n",
      "Fetching observation data for time-17-00-39-258967_chatcmpl-d0c5b2a4-b865-4593-8a4f-b40e186f5440...\n",
      "Fetching observation data for time-16-58-51-630991_chatcmpl-966b3a77-091e-414d-b000-89ee1a70dfce...\n",
      "Fetching observation data for time-16-59-16-006877_chatcmpl-5c25b45b-a7f5-4922-9867-bcfab76e9457...\n",
      "Fetching observation data for time-16-57-36-987611_chatcmpl-19f5104f-26c6-4f81-881a-70ae098a50f3...\n",
      "Fetching observation data for time-16-56-19-462645_chatcmpl-a503406a-7404-403a-8bb1-50238e4003b4...\n",
      "Fetching observation data for time-16-55-02-933076_chatcmpl-6da7602c-6366-4e10-bda3-d21f7c246fe8...\n",
      "Fetching observation data for time-16-53-47-364217_chatcmpl-dfee83ff-b81a-47be-8720-ea288d1a493d...\n",
      "Fetching observation data for time-16-52-26-801153_chatcmpl-8a934ec3-1818-4e2b-ad2d-2b8e4154d1e6...\n",
      "Fetching observation data for time-16-50-41-250106_chatcmpl-64e571b0-895e-4378-a9d5-038aba69c75f...\n",
      "Fetching observation data for time-16-51-07-994948_chatcmpl-b19aa381-77ca-4d90-8a80-6c1211b490de...\n",
      "Fetching observation data for time-16-49-19-729591_chatcmpl-a0b224b9-93e4-40cf-8649-84f477851628...\n",
      "Fetching observation data for time-16-46-58-111419_chatcmpl-8e3007bd-58e6-4f3d-89ac-c6eb779b831a...\n",
      "Fetching observation data for time-16-47-25-348846_chatcmpl-ccb172fb-48e7-4d71-bcc7-9fbaa8ebd8d4...\n",
      "Fetching observation data for time-16-47-57-737405_chatcmpl-5ee05c5f-8ead-4603-ae8f-44ce1c975e0b...\n",
      "Fetching observation data for time-16-44-55-584677_chatcmpl-577b1567-e77d-40f2-a13c-f2f644beb8c1...\n",
      "Fetching observation data for time-16-45-35-922883_chatcmpl-b3d510d0-e357-4fd9-b07f-cc3eb328c7c5...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/langfuse_export/07.30/raw_export/raw_phi4_85a9_tpusg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_3d_psg_failure_signal_py_sketch_generator: Failed. Last error:   File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730181304_psg_phi4:latest/tmp_20250730181304_psg_phi4:latest.py\", line 2\n",
      "    for input_detail in interpreter.get_input_details():\n",
      "IndentationError: unexpected indent\n",
      "\n",
      "SPAN error_f6_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730181034_psg_phi4:latest/tmp_20250730181034_psg_phi4:latest.py\", line 41, in <module>\n",
      "    boxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n",
      "TypeError: string indices must be integers\n",
      "\n",
      "SPAN error_14_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "qt.qpa.xcb: could not connect to display \n",
      "qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/cv2/qt/plugins\" even though it was found.\n",
      "This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n",
      "\n",
      "Available platform plugins are: xcb.\n",
      "\n",
      "\n",
      "SPAN error_30_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730180320_psg_phi4:latest/tmp_20250730180320_psg_phi4:latest.py\", line 54, in <module>\n",
      "    if output_data[i] > 0.5:  # Example threshold; adjust as needed\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "\n",
      "SPAN error_ca_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730180153_psg_phi4:latest/tmp_20250730180153_psg_phi4:latest.py\", line 72, in <module>\n",
      "    main()\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730180153_psg_phi4:latest/tmp_20250730180153_psg_phi4:latest.py\", line 17, in main\n",
      "    interpreter = Interpreter(model_path=model_path)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 464, in __init__\n",
      "    self._interpreter = _interpreter_wrapper.CreateWrapperFromFile(\n",
      "ValueError: Could not open 'path_to_your_model.tflite'.\n",
      "\n",
      "SPAN error_32_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730175922_psg_phi4:latest/tmp_20250730175922_psg_phi4:latest.py\", line 84, in <module>\n",
      "    output_data = run_inference(interpreter, input_data)\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730175922_psg_phi4:latest/tmp_20250730175922_psg_phi4:latest.py\", line 40, in run_inference\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_45_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730175656_psg_phi4:latest/tmp_20250730175656_psg_phi4:latest.py\", line 1, in <module>\n",
      "    from ai_edge_litter.interpreter import Interpreter\n",
      "ModuleNotFoundError: No module named 'ai_edge_litter'\n",
      "\n",
      "SPAN error_8b_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730175514_psg_phi4:latest/tmp_20250730175514_psg_phi4:latest.py\", line 45, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_93_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730175116_psg_phi4:latest/tmp_20250730175116_psg_phi4:latest.py\", line 19, in <module>\n",
      "    input_shape = input_details[0]['shape']\n",
      "TypeError: string indices must be integers\n",
      "\n",
      "SPAN error_15_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730174429_psg_phi4:latest/tmp_20250730174429_psg_phi4:latest.py\", line 53, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_12_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "qt.qpa.xcb: could not connect to display \n",
      "qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/cv2/qt/plugins\" even though it was found.\n",
      "This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n",
      "\n",
      "Available platform plugins are: xcb.\n",
      "\n",
      "\n",
      "SPAN error_8b_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730174002_psg_phi4:latest/tmp_20250730174002_psg_phi4:latest.py\", line 20, in <module>\n",
      "    input_shape = input_details[0]['shape']\n",
      "TypeError: string indices must be integers\n",
      "\n",
      "Successfully processed and saved trimmed data for session phi4_85a9_psg_batch\n",
      "Successfully processed and saved trimmed data for session phi4_85a9_tpusg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session phi4_85a9_psg_batch, simple id phi4_85a9. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/langfuse_export/07.30/raw_export/trimmed_phi4_85a9_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/langfuse_export/07.30/processed_data/phi4_85a9/clean_phi4_85a9_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/langfuse_export/07.30/processed_data/phi4_85a9/clean_phi4_85a9_psg_batch.csv\n",
      "Processing session phi4_85a9_tpusg_batch, simple id phi4_85a9. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/langfuse_export/07.30/raw_export/trimmed_phi4_85a9_tpusg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/langfuse_export/07.30/processed_data/phi4_85a9/clean_phi4_85a9_tpusg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/langfuse_export/07.30/processed_data/phi4_85a9/clean_phi4_85a9_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below is archived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Simply calculate success rate\"\"\"\n",
    "\n",
    "\n",
    "# def cal_success_rate(session_id):\n",
    "\n",
    "#     end_signal_count = 0\n",
    "#     failure_signal_count = 0\n",
    "#     # Function to print the name of each observation\n",
    "#     with open(f\"{raw_export_dir}/trimmed_{session_id}.json\", \"r\") as file:\n",
    "#         data = json.load(file)[\"data\"]\n",
    "#     for i in data:\n",
    "\n",
    "#         observations = i[\"observations\"]\n",
    "\n",
    "#         for observation in observations:\n",
    "#             # print(type(observation))\n",
    "#             for key, value in observation.items():\n",
    "#                 # print(f\"{key}: {value}\")\n",
    "#                 for key, value in value.items():\n",
    "#                     # print(f\"{key}: {value}\")\n",
    "#                     if key == \"name\":\n",
    "#                         if \"end_\" in value:\n",
    "\n",
    "#                             end_signal_count += 1\n",
    "#                         if \"failure_signal\" in value:\n",
    "\n",
    "#                             failure_signal_count += 1\n",
    "\n",
    "#     print(f\"Session ID: {session_id}\")\n",
    "#     total_count = end_signal_count + failure_signal_count\n",
    "#     if total_count > 0:\n",
    "#         success_rate = end_signal_count / total_count\n",
    "#         print(f\"Success rate: {success_rate:.4f}\")\n",
    "#     else:\n",
    "#         print(\"Success rate: N/A (no signals found)\")\n",
    "#     print(f\"Passed:\\t{end_signal_count}\\nFailed:\\t{failure_signal_count}\")\n",
    "#     print(\n",
    "#         \"\"\n",
    "#         if total_count == 30\n",
    "#         else \"Number of ending signals does not match the expected number!\"\n",
    "#     )\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# for session_id in session_id_list:\n",
    "#     cal_success_rate(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_time(start_time, end_time):\n",
    "#     time_diff = datetime.fromisoformat(\n",
    "#         end_time.replace(\"Z\", \"+00:00\")\n",
    "#     ) - datetime.fromisoformat(start_time.replace(\"Z\", \"+00:00\"))\n",
    "#     seconds_diff = time_diff.total_seconds()\n",
    "#     return seconds_diff\n",
    "\n",
    "\n",
    "# print(cal_time(\"2025-01-15T03:31:56.150000+00:00\", \"2025-01-15T03:32:59.384Z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Print the complete structure of exported json file\"\"\"\n",
    "# def print_keys(d, parent_key=''):\n",
    "#     if isinstance(d, dict):\n",
    "#         for key, value in d.items():\n",
    "#             full_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "#             print(full_key)\n",
    "#             print_keys(value, full_key)\n",
    "#     elif isinstance(d, list):\n",
    "#         for i, item in enumerate(d):\n",
    "#             full_key = f\"{parent_key}[{i}]\"\n",
    "#             print_keys(item, full_key)\n",
    "\n",
    "# # Load JSON data from a file\n",
    "# with open('fetch_traces_response.json', 'r') as file:\n",
    "#     data = json.load(file)['data'][0]\n",
    "# # Print all keys\n",
    "# print_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747226053\n",
      "1747226053.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "timestamp_str = \"2025-05-14T12:34:13.100000+00:00\"\n",
    "dt = parser.isoparse(\n",
    "    timestamp_str\n",
    ")  # Or datetime.fromisoformat(timestamp_str) if no timezone offset\n",
    "unix_ts = int(dt.timestamp())\n",
    "\n",
    "print(unix_ts)  # This will print the integer Unix timestamp\n",
    "print(datetime.fromisoformat(timestamp_str).timestamp())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
