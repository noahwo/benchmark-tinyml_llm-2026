{
  "data": [
    {
      "id": "1cb7a485",
      "timestamp": "2026-02-19T15:23:58.194000+00:00",
      "name": "1cb7_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef preprocess_frame(frame):\n    # Resize and normalize the frame\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5  # Normalize to [-1, 1]\n    return input_data\n\ndef postprocess(output_data):\n    # Extract detection results\n    num_detections = int(output_data[0][0])\n    boxes = output_data[1][0]\n    classes = output_data[2][0].astype(np.int32)\n    scores = output_data[3][0]\n\n    detections = []\n    for i in range(num_detections):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[classes[i]]\n            detections.append((label, scores[i], left, top, right, bottom))\n    return detections\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_frame(frame)\n\n    # Set input tensor\n    interpreter.set_tensor(input_index, input_data.astype(np.float32))\n\n    # Run inference\n    interpreter.invoke()\n\n    # Get output tensors\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Postprocess the results\n    detections = postprocess([scores, boxes, classes])\n\n    # Draw detection boxes and labels on the frame\n    for label, score, left, top, right, bottom in detections:\n        cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n        text = f'{label}: {score:.2f}'\n        cv2.putText(frame, text, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_0cca7d0b_1771514728.py\", line 73, in <module>\n    interpreter.set_tensor(input_index, input_data.astype(np.float32))\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor ."
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 98.446,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-23-58-195594_chatcmpl-a67b5643-219e-4337-807f-cf5e18c3475c",
          "traceId": "1cb7a485",
          "type": "GENERATION",
          "name": "1cb7_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T15:23:58.195000+00:00",
          "endTime": "2026-02-19T15:24:08.490000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10295.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-24-16-206613_chatcmpl-2af15301-bda6-4942-9d1d-1d0fa7d2b69c",
          "traceId": "1cb7a485",
          "type": "GENERATION",
          "name": "1cb7_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T15:24:16.206000+00:00",
          "endTime": "2026-02-19T15:24:28.663000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12457.0,
          "completionTokens": 935,
          "environment": "default",
          "totalTokens": 1502,
          "promptTokens": 567,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-24-36-862033_chatcmpl-b89183a4-897d-46c8-a582-a1c465f9aca2",
          "traceId": "1cb7a485",
          "type": "GENERATION",
          "name": "1cb7_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T15:24:36.862000+00:00",
          "endTime": "2026-02-19T15:24:47.672000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10810.0,
          "completionTokens": 812,
          "environment": "default",
          "totalTokens": 1439,
          "promptTokens": 627,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-24-55-940311_chatcmpl-e14aaa0b-67c6-483b-9b48-06798779e2c7",
          "traceId": "1cb7a485",
          "type": "GENERATION",
          "name": "1cb7_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T15:24:55.940000+00:00",
          "endTime": "2026-02-19T15:25:07.519000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11579.0,
          "completionTokens": 872,
          "environment": "default",
          "totalTokens": 1466,
          "promptTokens": 594,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-25-15-794233_chatcmpl-ab6a2ff7-b666-4e9f-8fe8-2a0f80948f78",
          "traceId": "1cb7a485",
          "type": "GENERATION",
          "name": "1cb7_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T15:25:15.794000+00:00",
          "endTime": "2026-02-19T15:25:28.344000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12550.0,
          "completionTokens": 944,
          "environment": "default",
          "totalTokens": 1567,
          "promptTokens": 623,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "e84caa31-dbc9-4cd4-b086-3c0e09dc63b2",
          "traceId": "1cb7a485",
          "type": "SPAN",
          "name": "error_1c_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2026-02-19T15:25:36.641000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_0cca7d0b_1771514728.py\", line 73, in <module>\n    interpreter.set_tensor(input_index, input_data.astype(np.float32))\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor .",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T15:23:58.740Z",
      "environment": "default",
      "updatedAt": "2026-02-19T15:25:41.995Z"
    },
    {
      "id": "921cb5be",
      "timestamp": "2026-02-19T15:21:53.747000+00:00",
      "name": "921c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef preprocess_frame(frame):\n    # Resize and normalize the frame\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5  # Normalize to [-1, 1]\n    return input_data\n\ndef postprocess(output_data):\n    # Extract detection results\n    boxes = output_data[0][0]  # Bounding box coordinates\n    classes = output_data[1][0]  # Class indices\n    scores = output_data[2][0]  # Confidence scores\n\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[int(classes[i])]\n            detections.append((label, scores[i], left, top, right, bottom))\n    return detections\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_frame(frame)\n\n    # Set tensor and run inference\n    interpreter.set_tensor(input_index, input_data.astype(np.float32))\n\n    interpreter.invoke()\n\n    # Get output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])\n    classes = interpreter.get_tensor(output_details[1]['index'])\n    scores = interpreter.get_tensor(output_details[2]['index'])\n\n    # Postprocess the results\n    detections = postprocess([boxes, classes, scores])\n\n    # Draw detection boxes and labels on the frame\n    for label, score, left, top, right, bottom in detections:\n        cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n        text = f'{label}: {score:.2f}'\n        cv2.putText(frame, text, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_dfb4ab15_1771514603.py\", line 72, in <module>\n    interpreter.set_tensor(input_index, input_data.astype(np.float32))\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor ."
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 98.131,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-21-53-748735_chatcmpl-f0ac414b-3188-46de-8046-88805ed54a43",
          "traceId": "921cb5be",
          "type": "GENERATION",
          "name": "921c_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T15:21:53.748000+00:00",
          "endTime": "2026-02-19T15:22:04.034000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10286.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-22-11-790305_chatcmpl-d8986c67-4b9b-4f04-adfe-66650c018716",
          "traceId": "921cb5be",
          "type": "GENERATION",
          "name": "921c_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T15:22:11.790000+00:00",
          "endTime": "2026-02-19T15:22:24.171000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12381.0,
          "completionTokens": 926,
          "environment": "default",
          "totalTokens": 1491,
          "promptTokens": 565,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-22-32-429910_chatcmpl-e983f8a2-da63-4b7f-b760-33635122bf01",
          "traceId": "921cb5be",
          "type": "GENERATION",
          "name": "921c_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T15:22:32.429000+00:00",
          "endTime": "2026-02-19T15:22:43.261000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10832.0,
          "completionTokens": 812,
          "environment": "default",
          "totalTokens": 1439,
          "promptTokens": 627,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-22-51-731530_chatcmpl-39b3ffbf-fc88-4f8c-b5fb-c1d5fb7e9fce",
          "traceId": "921cb5be",
          "type": "GENERATION",
          "name": "921c_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T15:22:51.731000+00:00",
          "endTime": "2026-02-19T15:23:03.241000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11510.0,
          "completionTokens": 866,
          "environment": "default",
          "totalTokens": 1460,
          "promptTokens": 594,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-23-11-405436_chatcmpl-59bea433-3244-4851-a2e5-f6b1ba29a126",
          "traceId": "921cb5be",
          "type": "GENERATION",
          "name": "921c_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T15:23:11.405000+00:00",
          "endTime": "2026-02-19T15:23:23.721000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12316.0,
          "completionTokens": 926,
          "environment": "default",
          "totalTokens": 1548,
          "promptTokens": 622,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "05437172-e9fc-4d1a-8603-a8e65f5fad4b",
          "traceId": "921cb5be",
          "type": "SPAN",
          "name": "error_92_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2026-02-19T15:23:31.879000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_dfb4ab15_1771514603.py\", line 72, in <module>\n    interpreter.set_tensor(input_index, input_data.astype(np.float32))\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor .",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T15:21:54.290Z",
      "environment": "default",
      "updatedAt": "2026-02-19T15:23:37.545Z"
    },
    {
      "id": "3de67a40",
      "timestamp": "2026-02-19T15:19:44.288000+00:00",
      "name": "3de6_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n# Function to preprocess input image\ndef preprocess_image(frame):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_details[0]['shape'][2], input_details[0]['shape'][1]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.uint8)\n    return input_data\n\n# Function to draw bounding boxes and labels\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        ymin, xmin, ymax, xmax = detection['bounding_box']\n        class_id = int(detection['class_id'])\n        score = detection['score']\n\n        if score >= confidence_threshold:\n            left, right, top, bottom = (xmin * width), (xmax * width), (ymin * height), (ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[class_id]}: {score:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\n# Main processing loop\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the input image\n    input_data = preprocess_image(frame)\n\n    # Set the tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            detections.append({\n                'bounding_box': (ymin, xmin, ymax, xmax),\n                'class_id': int(classes[i]),\n                'score': float(scores[i])\n            })\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Processing complete. Output saved at:\", output_path)"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 50.653,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-19-44-289387_chatcmpl-20920bea-384d-4a6a-bae6-c478f62c3720",
          "traceId": "3de67a40",
          "type": "GENERATION",
          "name": "3de6_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T15:19:44.289000+00:00",
          "endTime": "2026-02-19T15:19:54.589000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10300.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-20-02-298506_chatcmpl-1ee8237d-8d99-474c-a98b-a14f5f568280",
          "traceId": "3de67a40",
          "type": "GENERATION",
          "name": "3de6_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T15:20:02.298000+00:00",
          "endTime": "2026-02-19T15:20:14.378000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12080.0,
          "completionTokens": 906,
          "environment": "default",
          "totalTokens": 1470,
          "promptTokens": 564,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-20-22-648957_chatcmpl-80e2bd70-9e63-4a52-b156-32ca7a9cff2a",
          "traceId": "3de67a40",
          "type": "GENERATION",
          "name": "3de6_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T15:20:22.648000+00:00",
          "endTime": "2026-02-19T15:20:34.942000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12294.0,
          "completionTokens": 923,
          "environment": "default",
          "totalTokens": 1550,
          "promptTokens": 627,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T15:19:44.831Z",
      "environment": "default",
      "updatedAt": "2026-02-19T15:21:32.991Z"
    },
    {
      "id": "6e19e897",
      "timestamp": "2026-02-19T15:16:56.713000+00:00",
      "name": "6e19_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5  # Normalize to [-1, 1]\n    input_data = input_data.astype(np.uint8)\n\n    # Inference\n    interpreter.set_tensor(input_index, input_data)\n    interpreter.invoke()\n\n    # Output handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n\n            # Draw bounding box and label\n            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n            object_name = labels[int(classes[i])]\n            label = f'{object_name}: {int(scores[i] * 100)}%'\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (left, top - round(1.5*label_size[1])), (left + round(1.5*label_size[0]), top + base_line), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Video processing complete.\")"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 89.885,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-16-56-715083_chatcmpl-34c7fa96-aa7e-42eb-b2cd-cd65530b58cd",
          "traceId": "6e19e897",
          "type": "GENERATION",
          "name": "6e19_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T15:16:56.715000+00:00",
          "endTime": "2026-02-19T15:17:07.010000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10295.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-17-14-736096_chatcmpl-2fb7ad2a-798f-4de8-96d6-f505470b6d51",
          "traceId": "6e19e897",
          "type": "GENERATION",
          "name": "6e19_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T15:17:14.736000+00:00",
          "endTime": "2026-02-19T15:17:27.307000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12571.0,
          "completionTokens": 943,
          "environment": "default",
          "totalTokens": 1509,
          "promptTokens": 566,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-17-35-478795_chatcmpl-1e49200b-3eee-408f-8511-ec6358be6977",
          "traceId": "6e19e897",
          "type": "GENERATION",
          "name": "6e19_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T15:17:35.478000+00:00",
          "endTime": "2026-02-19T15:17:46.520000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11042.0,
          "completionTokens": 830,
          "environment": "default",
          "totalTokens": 1458,
          "promptTokens": 628,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-17-54-877115_chatcmpl-d6fa3903-3c13-4d23-97e7-2cdac0513ea5",
          "traceId": "6e19e897",
          "type": "GENERATION",
          "name": "6e19_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T15:17:54.877000+00:00",
          "endTime": "2026-02-19T15:18:06.466000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11589.0,
          "completionTokens": 873,
          "environment": "default",
          "totalTokens": 1469,
          "promptTokens": 596,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-18-14-626639_chatcmpl-153d33d4-a28b-4153-9cc3-8510b2e54e7d",
          "traceId": "6e19e897",
          "type": "GENERATION",
          "name": "6e19_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T15:18:14.626000+00:00",
          "endTime": "2026-02-19T15:18:26.600000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11974.0,
          "completionTokens": 900,
          "environment": "default",
          "totalTokens": 1526,
          "promptTokens": 626,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T15:16:57.255Z",
      "environment": "default",
      "updatedAt": "2026-02-19T15:19:24.034Z"
    },
    {
      "id": "09e56857",
      "timestamp": "2026-02-19T15:14:10.249000+00:00",
      "name": "09e5_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef preprocess_frame(frame):\n    # Resize and normalize the frame\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5  # Normalize to [-1, 1]\n    return input_data.astype(np.uint8)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_frame(frame)\n    \n    # Set the tensor and run inference\n    interpreter.set_tensor(input_index, input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            \n            # Draw bounding box and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 88.498,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-14-10-251232_chatcmpl-9891e6af-c90e-4e80-a224-886cd46f3683",
          "traceId": "09e56857",
          "type": "GENERATION",
          "name": "09e5_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T15:14:10.251000+00:00",
          "endTime": "2026-02-19T15:14:20.576000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10325.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-14-28-562071_chatcmpl-7f7152ef-e5b7-49ae-886d-63ae3d20ddf6",
          "traceId": "09e56857",
          "type": "GENERATION",
          "name": "09e5_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T15:14:28.562000+00:00",
          "endTime": "2026-02-19T15:14:40.901000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12339.0,
          "completionTokens": 926,
          "environment": "default",
          "totalTokens": 1492,
          "promptTokens": 566,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-14-49-143065_chatcmpl-98d7a6dc-4fa7-49b8-ab8e-03134747abff",
          "traceId": "09e56857",
          "type": "GENERATION",
          "name": "09e5_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T15:14:49.143000+00:00",
          "endTime": "2026-02-19T15:14:59.754000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10611.0,
          "completionTokens": 798,
          "environment": "default",
          "totalTokens": 1426,
          "promptTokens": 628,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-15-08-118032_chatcmpl-a2c57df4-f72c-4394-9d15-b0b5ed54a809",
          "traceId": "09e56857",
          "type": "GENERATION",
          "name": "09e5_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T15:15:08.118000+00:00",
          "endTime": "2026-02-19T15:15:19.767000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11649.0,
          "completionTokens": 877,
          "environment": "default",
          "totalTokens": 1474,
          "promptTokens": 597,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-15-27-994278_chatcmpl-724781c3-7bcd-451b-b162-2fc2a59bb0fd",
          "traceId": "09e56857",
          "type": "GENERATION",
          "name": "09e5_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T15:15:27.994000+00:00",
          "endTime": "2026-02-19T15:15:38.749000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10755.0,
          "completionTokens": 809,
          "environment": "default",
          "totalTokens": 1434,
          "promptTokens": 625,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T15:14:10.797Z",
      "environment": "default",
      "updatedAt": "2026-02-19T15:16:36.556Z"
    },
    {
      "id": "5be284c3",
      "timestamp": "2026-02-19T15:12:05.476000+00:00",
      "name": "5be2_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef preprocess_frame(frame):\n    # Resize and normalize the frame\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5  # Normalize to [-1, 1]\n    return input_data\n\ndef postprocess(output_data):\n    # Extract detection results\n    num_detections = int(output_data[0][0])\n    boxes = output_data[1][0]\n    classes = output_data[2][0].astype(np.int32)\n    scores = output_data[3][0]\n\n    detections = []\n    for i in range(num_detections):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[classes[i]]\n            detections.append((label, scores[i], left, top, right, bottom))\n    return detections\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_frame(frame)\n\n    # Set input tensor\n    interpreter.set_tensor(input_index, input_data.astype(np.float32))\n\n    # Run inference\n    interpreter.invoke()\n\n    # Get output tensors\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Postprocess the results\n    detections = postprocess([boxes, classes, scores])\n\n    # Draw detection boxes and labels on the frame\n    for label, score, left, top, right, bottom in detections:\n        cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n        text = f'{label}: {score:.2f}'\n        cv2.putText(frame, text, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_0fd4441f_1771514016.py\", line 73, in <module>\n    interpreter.set_tensor(input_index, input_data.astype(np.float32))\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor ."
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 98.926,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-12-05-477543_chatcmpl-67712ad9-3d34-4ce3-8088-4a35bda31b12",
          "traceId": "5be284c3",
          "type": "GENERATION",
          "name": "5be2_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T15:12:05.477000+00:00",
          "endTime": "2026-02-19T15:12:15.992000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10515.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-12-23-878306_chatcmpl-56c79670-d662-4c49-a753-29c568cb34b1",
          "traceId": "5be284c3",
          "type": "GENERATION",
          "name": "5be2_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T15:12:23.878000+00:00",
          "endTime": "2026-02-19T15:12:36.072000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12194.0,
          "completionTokens": 915,
          "environment": "default",
          "totalTokens": 1481,
          "promptTokens": 566,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-12-44-731886_chatcmpl-266f9976-4d1e-48ec-80ee-47e63734a9c7",
          "traceId": "5be284c3",
          "type": "GENERATION",
          "name": "5be2_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T15:12:44.731000+00:00",
          "endTime": "2026-02-19T15:12:55.537000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10806.0,
          "completionTokens": 812,
          "environment": "default",
          "totalTokens": 1438,
          "promptTokens": 626,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-13-03-693373_chatcmpl-d1d452b3-dee7-4c0c-9c5c-be93be7f10d6",
          "traceId": "5be284c3",
          "type": "GENERATION",
          "name": "5be2_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T15:13:03.693000+00:00",
          "endTime": "2026-02-19T15:13:15.185000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11492.0,
          "completionTokens": 866,
          "environment": "default",
          "totalTokens": 1460,
          "promptTokens": 594,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-13-23-672874_chatcmpl-87c66ee3-7907-4dfb-b7e8-60d860671818",
          "traceId": "5be284c3",
          "type": "GENERATION",
          "name": "5be2_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T15:13:23.672000+00:00",
          "endTime": "2026-02-19T15:13:36.131000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12459.0,
          "completionTokens": 936,
          "environment": "default",
          "totalTokens": 1559,
          "promptTokens": 623,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "0b30af6f-2f2d-4204-a736-3c5ffce06249",
          "traceId": "5be284c3",
          "type": "SPAN",
          "name": "error_5b_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2026-02-19T15:13:44.403000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_0fd4441f_1771514016.py\", line 73, in <module>\n    interpreter.set_tensor(input_index, input_data.astype(np.float32))\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor .",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T15:12:06.014Z",
      "environment": "default",
      "updatedAt": "2026-02-19T15:13:49.678Z"
    },
    {
      "id": "8bbe347b",
      "timestamp": "2026-02-19T15:10:16.998000+00:00",
      "name": "8bbe_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise ValueError(\"Error opening video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Preprocessing function\ndef preprocess_frame(frame):\n    input_shape = input_details[0]['shape']\n    image_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(image_resized, axis=0)\n    return input_data\n\n# Inference and postprocessing function\ndef detect_objects(input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    return boxes, classes, scores\n\n# Main processing loop\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_data = preprocess_frame(frame)\n    boxes, classes, scores = detect_objects(input_data)\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n            \n            # Draw bounding box and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\n\nprint(\"Processing complete. Output saved to:\", output_path)"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 29.323,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-10-17-000134_chatcmpl-ba63f894-79e2-4ec0-bf95-30953bea0833",
          "traceId": "8bbe347b",
          "type": "GENERATION",
          "name": "8bbe_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T15:10:17+00:00",
          "endTime": "2026-02-19T15:10:27.294000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10294.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-10-35-212686_chatcmpl-bf4d5f91-ceec-46ac-8a28-578754571be9",
          "traceId": "8bbe347b",
          "type": "GENERATION",
          "name": "8bbe_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T15:10:35.212000+00:00",
          "endTime": "2026-02-19T15:10:46.323000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11111.0,
          "completionTokens": 832,
          "environment": "default",
          "totalTokens": 1401,
          "promptTokens": 569,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T15:10:17.535Z",
      "environment": "default",
      "updatedAt": "2026-02-19T15:11:44.238Z"
    },
    {
      "id": "1139f111",
      "timestamp": "2026-02-19T15:08:07.457000+00:00",
      "name": "1139_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n# Function to preprocess input image\ndef preprocess_image(frame):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_details[0]['shape'][2], input_details[0]['shape'][1]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.uint8)\n    return input_data\n\n# Function to draw bounding boxes and labels\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        ymin, xmin, ymax, xmax = detection['bounding_box']\n        class_id = int(detection['class_id'])\n        score = float(detection['score'])\n\n        if score >= confidence_threshold:\n            left = int(xmin * width)\n            right = int(xmax * width)\n            top = int(ymin * height)\n            bottom = int(ymax * height)\n\n            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n            label = f\"{labels[class_id]}: {score:.2f}\"\n            cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\n# Main processing loop\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the input image\n    input_data = preprocess_image(frame)\n\n    # Set the tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            detections.append({\n                'bounding_box': (ymin, xmin, ymax, xmax),\n                'class_id': int(classes[i]),\n                'score': float(scores[i])\n            })\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Processing complete. Output saved at:\", output_path)"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 51.297,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-08-07-458795_chatcmpl-f04458bb-28a9-4f36-ae8b-567e2def914d",
          "traceId": "1139f111",
          "type": "GENERATION",
          "name": "1139_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T15:08:07.458000+00:00",
          "endTime": "2026-02-19T15:08:18.056000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10598.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-08-26-078074_chatcmpl-c039bc72-2a1c-43e7-ae0c-f306f13da4f8",
          "traceId": "1139f111",
          "type": "GENERATION",
          "name": "1139_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T15:08:26.078000+00:00",
          "endTime": "2026-02-19T15:08:38.211000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12133.0,
          "completionTokens": 910,
          "environment": "default",
          "totalTokens": 1478,
          "promptTokens": 568,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-08-46-461210_chatcmpl-770cd642-f576-4aa6-977f-0c1ea6b0449d",
          "traceId": "1139f111",
          "type": "GENERATION",
          "name": "1139_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T15:08:46.461000+00:00",
          "endTime": "2026-02-19T15:08:58.755000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12294.0,
          "completionTokens": 924,
          "environment": "default",
          "totalTokens": 1553,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T15:08:07.992Z",
      "environment": "default",
      "updatedAt": "2026-02-19T15:09:56.765Z"
    },
    {
      "id": "ba8b8534",
      "timestamp": "2026-02-19T15:05:17.778000+00:00",
      "name": "ba8b_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\ndef load_labels(label_path):\n    \"\"\"Load the labels from a file.\"\"\"\n    with open(label_path, 'r', encoding='utf-8') as f:\n        return [line.strip() for line in f.readlines()]\n\ndef set_input_tensor(interpreter, image):\n    \"\"\"Preprocess the input image and set it to the interpreter.\"\"\"\n    # Get input details\n    input_details = interpreter.get_input_details()\n    input_shape = input_details[0]['shape']\n    \n    # Resize and normalize the image\n    image = cv2.resize(image, (input_shape[1], input_shape[2]))\n    image = np.expand_dims(image, axis=0)\n    image = (image / 255.0).astype(np.float32)\n\n    # Set the tensor to the interpreter\n    interpreter.set_tensor(input_details[0]['index'], image.astype(np.uint8))\n\ndef get_output(interpreter):\n    \"\"\"Get detection results from the interpreter.\"\"\"\n    output_details = interpreter.get_output_details()\n    \n    # Get all outputs from the model\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n    \n    return boxes, classes, scores\n\ndef draw_detections(image, boxes, classes, scores, labels, threshold):\n    \"\"\"Draw bounding boxes and labels on the image.\"\"\"\n    for i in range(len(scores)):\n        if scores[i] >= threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * image.shape[1], xmax * image.shape[1],\n                                          ymin * image.shape[0], ymax * image.shape[0])\n            \n            # Draw rectangle and label\n            cv2.rectangle(image, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {int(scores[i]*100)}%\"\n            cv2.putText(image, label, (int(left), int(top-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\ndef main():\n    # Configuration parameters\n    model_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\n    label_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\n    input_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\n    output_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n    confidence_threshold = 0.5\n\n    # Load labels\n    labels = load_labels(label_path)\n\n    # Initialize the TFLite interpreter with EdgeTPU delegate\n    interpreter = Interpreter(\n        model_path=model_path,\n        experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n    )\n    interpreter.allocate_tensors()\n\n    # Open video files\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Set input tensor\n        set_input_tensor(interpreter, frame)\n\n        # Run inference\n        interpreter.invoke()\n\n        # Get output and draw detections\n        boxes, classes, scores = get_output(interpreter)\n        draw_detections(frame, boxes, classes, scores, labels, confidence_threshold)\n\n        # Write the frame with detections to the output video\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == \"__main__\":\n    main()"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 90.792,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-05-17-779977_chatcmpl-9d20d8b7-2e2b-41eb-bb50-51bb38286d86",
          "traceId": "ba8b8534",
          "type": "GENERATION",
          "name": "ba8b_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T15:05:17.779000+00:00",
          "endTime": "2026-02-19T15:05:28.066000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10287.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-05-36-005966_chatcmpl-3de99453-afe5-4bab-b315-3061808e0ad9",
          "traceId": "ba8b8534",
          "type": "GENERATION",
          "name": "ba8b_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T15:05:36.005000+00:00",
          "endTime": "2026-02-19T15:05:48.470000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12465.0,
          "completionTokens": 935,
          "environment": "default",
          "totalTokens": 1502,
          "promptTokens": 567,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-05-56-644589_chatcmpl-6876aab5-db90-4e00-b586-83d4d686fc5e",
          "traceId": "ba8b8534",
          "type": "GENERATION",
          "name": "ba8b_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T15:05:56.644000+00:00",
          "endTime": "2026-02-19T15:06:07.380000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10736.0,
          "completionTokens": 807,
          "environment": "default",
          "totalTokens": 1434,
          "promptTokens": 627,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-06-15-589602_chatcmpl-225bf720-68e2-4542-9dfd-e69386c9e2e6",
          "traceId": "ba8b8534",
          "type": "GENERATION",
          "name": "ba8b_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T15:06:15.589000+00:00",
          "endTime": "2026-02-19T15:06:27.759000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12170.0,
          "completionTokens": 917,
          "environment": "default",
          "totalTokens": 1512,
          "promptTokens": 595,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-06-36-108282_chatcmpl-41ab742e-7d40-41bb-b6d9-85854724fe3a",
          "traceId": "ba8b8534",
          "type": "GENERATION",
          "name": "ba8b_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T15:06:36.108000+00:00",
          "endTime": "2026-02-19T15:06:48.571000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12463.0,
          "completionTokens": 934,
          "environment": "default",
          "totalTokens": 1585,
          "promptTokens": 651,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T15:05:18.314Z",
      "environment": "default",
      "updatedAt": "2026-02-19T15:07:46.608Z"
    },
    {
      "id": "299fcb93",
      "timestamp": "2026-02-19T15:02:31.279000+00:00",
      "name": "299f_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef preprocess_frame(frame):\n    # Resize and normalize the frame\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5  # Normalize to [-1, 1]\n    return input_data.astype(np.uint8)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_frame(frame)\n    \n    # Set the tensor and run inference\n    interpreter.set_tensor(input_index, input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            \n            # Draw bounding box and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Video processing complete.\")"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 88.695,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-02-31-281068_chatcmpl-f2774c0e-76cb-4d79-8aa4-8415870b4292",
          "traceId": "299fcb93",
          "type": "GENERATION",
          "name": "299f_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T15:02:31.281000+00:00",
          "endTime": "2026-02-19T15:02:41.573000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10292.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-02-49-406508_chatcmpl-3bbad74f-3e61-4fe5-9d07-14021e069ce0",
          "traceId": "299fcb93",
          "type": "GENERATION",
          "name": "299f_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T15:02:49.406000+00:00",
          "endTime": "2026-02-19T15:03:01.837000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12431.0,
          "completionTokens": 932,
          "environment": "default",
          "totalTokens": 1497,
          "promptTokens": 565,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-03-10-342982_chatcmpl-9b72eec7-6c62-421f-a1cb-b356aa1e80ee",
          "traceId": "299fcb93",
          "type": "GENERATION",
          "name": "299f_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T15:03:10.342000+00:00",
          "endTime": "2026-02-19T15:03:21.146000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10804.0,
          "completionTokens": 812,
          "environment": "default",
          "totalTokens": 1439,
          "promptTokens": 627,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-03-29-325529_chatcmpl-ffc0b6eb-8569-44ab-90a5-821ee0140ad2",
          "traceId": "299fcb93",
          "type": "GENERATION",
          "name": "299f_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T15:03:29.325000+00:00",
          "endTime": "2026-02-19T15:03:40.645000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11320.0,
          "completionTokens": 853,
          "environment": "default",
          "totalTokens": 1447,
          "promptTokens": 594,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-03-49-134462_chatcmpl-27a17165-0e40-4fde-b592-677ada48c00e",
          "traceId": "299fcb93",
          "type": "GENERATION",
          "name": "299f_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T15:03:49.134000+00:00",
          "endTime": "2026-02-19T15:03:59.976000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10842.0,
          "completionTokens": 816,
          "environment": "default",
          "totalTokens": 1439,
          "promptTokens": 623,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T15:02:31.816Z",
      "environment": "default",
      "updatedAt": "2026-02-19T15:04:57.513Z"
    },
    {
      "id": "ee0e41ac",
      "timestamp": "2026-02-19T15:00:25.780000+00:00",
      "name": "ee0e_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\ndef load_labels(path):\n    with open(path, 'r', encoding='utf-8') as f:\n        lines = f.readlines()\n    return {i: line.strip() for i, line in enumerate(lines)}\n\ndef main():\n    # Load labels\n    labels = load_labels(label_path)\n\n    # Initialize the TFLite interpreter with EdgeTPU delegate\n    interpreter = Interpreter(\n        model_path=model_path,\n        experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n    )\n    interpreter.allocate_tensors()\n\n    # Get input and output details\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    # Open video files\n    cap = cv2.VideoCapture(input_path)\n    if not cap.isOpened():\n        print(\"Error: Could not open input video.\")\n        return\n\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n\n    # Define the codec and create VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocess the input image\n        input_frame = cv2.resize(frame, (input_details[0]['shape'][2], input_details[0]['shape'][1]))\n        input_frame = np.expand_dims(input_frame, axis=0)\n        input_frame = (np.float32(input_frame) - 127.5) / 127.5\n\n        # Set the tensor to point to the input data\n        interpreter.set_tensor(input_details[0]['index'], input_frame)\n\n        # Run inference\n        interpreter.invoke()\n\n        # Retrieve detection results\n        boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n        classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n        scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n        # Loop over all detections and draw detection box if confidence is above the threshold\n        for i in range(len(scores)):\n            if scores[i] >= confidence_threshold:\n                ymin, xmin, ymax, xmax = boxes[i]\n                (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n                \n                # Draw bounding box and label on the frame\n                cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n                object_name = labels[int(classes[i])]\n                label = f\"{object_name}: {int(scores[i] * 100)}%\"\n                label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n                top = max(top, label_size[1])\n                cv2.rectangle(frame, (int(left), int(top - round(1.5 * label_size[1]))),\n                              (int(left + round(1.5 * label_size[0])), int(top + base_line)),\n                              (255, 255, 255), cv2.FILLED)\n                cv2.putText(frame, label, (int(left), int(top)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n        # Write the frame with detections\n        out.write(frame)\n\n    # Release resources\n    cap.release()\n    out.release()\n\nif __name__ == \"__main__\":\n    main()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_9f357b38_1771513316.py\", line 93, in <module>\n    main()\n  File \"script_9f357b38_1771513316.py\", line 58, in main\n    interpreter.set_tensor(input_details[0]['index'], input_frame)\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor ."
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 99.141,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-00-25-781824_chatcmpl-ce9cd29a-4f3b-4010-9f45-894639fa7ba2",
          "traceId": "ee0e41ac",
          "type": "GENERATION",
          "name": "ee0e_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T15:00:25.781000+00:00",
          "endTime": "2026-02-19T15:00:36.077000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10296.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-00-43-974871_chatcmpl-165a97fa-129d-4704-81c8-ff74a1f21f74",
          "traceId": "ee0e41ac",
          "type": "GENERATION",
          "name": "ee0e_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T15:00:43.974000+00:00",
          "endTime": "2026-02-19T15:00:56.174000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12200.0,
          "completionTokens": 916,
          "environment": "default",
          "totalTokens": 1481,
          "promptTokens": 565,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-01-04-529449_chatcmpl-fbb4e2a6-76cc-40d5-9d57-61b28ff9a75c",
          "traceId": "ee0e41ac",
          "type": "GENERATION",
          "name": "ee0e_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T15:01:04.529000+00:00",
          "endTime": "2026-02-19T15:01:15.331000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10802.0,
          "completionTokens": 811,
          "environment": "default",
          "totalTokens": 1438,
          "promptTokens": 627,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-01-23-629602_chatcmpl-0dd0976e-720a-4e4c-872f-07af05017698",
          "traceId": "ee0e41ac",
          "type": "GENERATION",
          "name": "ee0e_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T15:01:23.629000+00:00",
          "endTime": "2026-02-19T15:01:35.418000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11789.0,
          "completionTokens": 888,
          "environment": "default",
          "totalTokens": 1483,
          "promptTokens": 595,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-01-43-592541_chatcmpl-80545466-4ee3-48f9-94f9-71ac4655f2ed",
          "traceId": "ee0e41ac",
          "type": "GENERATION",
          "name": "ee0e_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T15:01:43.592000+00:00",
          "endTime": "2026-02-19T15:01:56.686000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13094.0,
          "completionTokens": 980,
          "environment": "default",
          "totalTokens": 1631,
          "promptTokens": 651,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "b443b864-e17b-4964-92fd-196d1548983e",
          "traceId": "ee0e41ac",
          "type": "SPAN",
          "name": "error_ee_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2026-02-19T15:02:04.922000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_9f357b38_1771513316.py\", line 93, in <module>\n    main()\n  File \"script_9f357b38_1771513316.py\", line 58, in main\n    interpreter.set_tensor(input_details[0]['index'], input_frame)\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor .",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T15:00:26.317Z",
      "environment": "default",
      "updatedAt": "2026-02-19T15:02:10.537Z"
    },
    {
      "id": "a6ef0b6e",
      "timestamp": "2026-02-19T14:58:16.352000+00:00",
      "name": "a6ef_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n# Function to preprocess input image\ndef preprocess_image(frame):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_details[0]['shape'][2], input_details[0]['shape'][1]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.uint8)\n    return input_data\n\n# Function to draw bounding boxes and labels\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        ymin, xmin, ymax, xmax = detection['bounding_box']\n        class_id = int(detection['class_id'])\n        score = float(detection['score'])\n\n        if score >= confidence_threshold:\n            left = int(xmin * width)\n            right = int(xmax * width)\n            top = int(ymin * height)\n            bottom = int(ymax * height)\n\n            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n            label = f\"{labels[class_id]}: {score:.2f}\"\n            cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\n# Main processing loop\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the input image\n    input_data = preprocess_image(frame)\n\n    # Set the tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            detection = {\n                'bounding_box': (ymin, xmin, ymax, xmax),\n                'class_id': int(classes[i]),\n                'score': float(scores[i])\n            }\n            detections.append(detection)\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Processing complete. Output saved at:\", output_path)"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 50.706,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-58-16-353617_chatcmpl-37b9d813-9964-4476-9048-0faef669405e",
          "traceId": "a6ef0b6e",
          "type": "GENERATION",
          "name": "a6ef_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:58:16.353000+00:00",
          "endTime": "2026-02-19T14:58:26.638000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10285.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-58-34-574094_chatcmpl-2a404074-4d44-418b-a409-8c0b8c1d9c85",
          "traceId": "a6ef0b6e",
          "type": "GENERATION",
          "name": "a6ef_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:58:34.574000+00:00",
          "endTime": "2026-02-19T14:58:46.520000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11946.0,
          "completionTokens": 897,
          "environment": "default",
          "totalTokens": 1462,
          "promptTokens": 565,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-58-54-676673_chatcmpl-be717675-f5d5-4832-8588-3adf2b06cadd",
          "traceId": "a6ef0b6e",
          "type": "GENERATION",
          "name": "a6ef_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T14:58:54.676000+00:00",
          "endTime": "2026-02-19T14:59:07.059000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12383.0,
          "completionTokens": 930,
          "environment": "default",
          "totalTokens": 1557,
          "promptTokens": 627,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:58:16.890Z",
      "environment": "default",
      "updatedAt": "2026-02-19T15:00:05.197Z"
    },
    {
      "id": "963cd59d",
      "timestamp": "2026-02-19T14:55:30.782000+00:00",
      "name": "963c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef preprocess_frame(frame):\n    # Resize and normalize the frame\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5  # Normalize to [-1, 1]\n    return input_data.astype(np.uint8)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_frame(frame)\n    \n    # Set the tensor and run inference\n    interpreter.set_tensor(input_index, input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            \n            # Draw bounding box and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Video processing complete.\")"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 88.272,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-55-30-783663_chatcmpl-51403e71-b7af-47ab-a7ca-b5f17a172477",
          "traceId": "963cd59d",
          "type": "GENERATION",
          "name": "963c_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:55:30.783000+00:00",
          "endTime": "2026-02-19T14:55:41.064000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10281.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-55-48-938724_chatcmpl-25bac891-3baf-4ba5-8a6d-02083d77483c",
          "traceId": "963cd59d",
          "type": "GENERATION",
          "name": "963c_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:55:48.938000+00:00",
          "endTime": "2026-02-19T14:56:01.324000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12386.0,
          "completionTokens": 930,
          "environment": "default",
          "totalTokens": 1496,
          "promptTokens": 566,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-56-09-555133_chatcmpl-27d3a136-0ea0-4fb9-92c1-ac2e44cd605c",
          "traceId": "963cd59d",
          "type": "GENERATION",
          "name": "963c_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T14:56:09.555000+00:00",
          "endTime": "2026-02-19T14:56:20.163000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10608.0,
          "completionTokens": 797,
          "environment": "default",
          "totalTokens": 1425,
          "promptTokens": 628,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-56-28-334596_chatcmpl-a6494b3d-ea1b-4fad-b589-9831d21d7f6f",
          "traceId": "963cd59d",
          "type": "GENERATION",
          "name": "963c_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T14:56:28.334000+00:00",
          "endTime": "2026-02-19T14:56:39.976000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11642.0,
          "completionTokens": 877,
          "environment": "default",
          "totalTokens": 1470,
          "promptTokens": 593,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-56-48-200962_chatcmpl-3f6721e2-16e2-43c1-9a86-bfbb1d0b675d",
          "traceId": "963cd59d",
          "type": "GENERATION",
          "name": "963c_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T14:56:48.200000+00:00",
          "endTime": "2026-02-19T14:56:59.055000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10855.0,
          "completionTokens": 816,
          "environment": "default",
          "totalTokens": 1439,
          "promptTokens": 623,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:55:31.321Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:57:56.564Z"
    },
    {
      "id": "decb317c",
      "timestamp": "2026-02-19T14:52:42.156000+00:00",
      "name": "decb_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5  # Normalize to [-1, 1]\n    input_data = input_data.astype(np.uint8)\n\n    # Inference\n    interpreter.set_tensor(input_index, input_data)\n    interpreter.invoke()\n\n    # Output handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n\n            # Draw bounding box and label\n            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n            object_name = labels[int(classes[i])]\n            label = f'{object_name}: {int(scores[i] * 100)}%'\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (left, top - round(1.5*label_size[1])), (left + round(1.5*label_size[0]), top + base_line), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Video processing complete.\")"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 90.152,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-52-42-157399_chatcmpl-0e1da3ed-2f88-4e79-b26a-02c1c4d682ed",
          "traceId": "decb317c",
          "type": "GENERATION",
          "name": "decb_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:52:42.157000+00:00",
          "endTime": "2026-02-19T14:52:52.446000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10289.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-53-00-430375_chatcmpl-855f5b1d-27d6-4576-a10f-47152f12bd55",
          "traceId": "decb317c",
          "type": "GENERATION",
          "name": "decb_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:53:00.430000+00:00",
          "endTime": "2026-02-19T14:53:12.755000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12325.0,
          "completionTokens": 925,
          "environment": "default",
          "totalTokens": 1493,
          "promptTokens": 568,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-53-21-021140_chatcmpl-3e612b93-fd44-431a-ac16-79386117fa76",
          "traceId": "decb317c",
          "type": "GENERATION",
          "name": "decb_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T14:53:21.021000+00:00",
          "endTime": "2026-02-19T14:53:32.298000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11277.0,
          "completionTokens": 848,
          "environment": "default",
          "totalTokens": 1475,
          "promptTokens": 627,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-53-40-505623_chatcmpl-4aedd01c-86bc-4b74-9958-b1923f49c731",
          "traceId": "decb317c",
          "type": "GENERATION",
          "name": "decb_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T14:53:40.505000+00:00",
          "endTime": "2026-02-19T14:53:52.074000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11569.0,
          "completionTokens": 871,
          "environment": "default",
          "totalTokens": 1467,
          "promptTokens": 596,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-54-00-316580_chatcmpl-5b73eed3-2dcd-4e65-82b5-3fe97a8d5aa2",
          "traceId": "decb317c",
          "type": "GENERATION",
          "name": "decb_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T14:54:00.316000+00:00",
          "endTime": "2026-02-19T14:54:12.309000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11993.0,
          "completionTokens": 902,
          "environment": "default",
          "totalTokens": 1525,
          "promptTokens": 623,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:52:42.698Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:55:09.980Z"
    },
    {
      "id": "ef5a7669",
      "timestamp": "2026-02-19T14:49:55.504000+00:00",
      "name": "ef5a_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise ValueError(\"Error opening video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing: Resize and normalize the input image\n    input_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_frame, axis=0).astype(np.uint8)\n\n    # Set tensor and run inference\n    interpreter.set_tensor(input_index, input_data)\n    interpreter.invoke()\n\n    # Get detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    # Draw detection boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw rectangle and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\n\nprint(\"Video processing complete.\")"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 87.943,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-49-55-505697_chatcmpl-0d4d5cdc-2f59-4d6a-b237-3c34cdd5498b",
          "traceId": "ef5a7669",
          "type": "GENERATION",
          "name": "ef5a_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:49:55.505000+00:00",
          "endTime": "2026-02-19T14:50:05.815000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10310.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-50-13-741594_chatcmpl-a15a1d19-3e68-45d8-9d9d-ef8fec66ca31",
          "traceId": "ef5a7669",
          "type": "GENERATION",
          "name": "ef5a_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:50:13.741000+00:00",
          "endTime": "2026-02-19T14:50:25.950000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12209.0,
          "completionTokens": 916,
          "environment": "default",
          "totalTokens": 1482,
          "promptTokens": 566,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-50-34-210196_chatcmpl-6f92f554-9f00-4ed0-97ad-cf44a8ad438f",
          "traceId": "ef5a7669",
          "type": "GENERATION",
          "name": "ef5a_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T14:50:34.210000+00:00",
          "endTime": "2026-02-19T14:50:44.944000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10734.0,
          "completionTokens": 807,
          "environment": "default",
          "totalTokens": 1435,
          "promptTokens": 628,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-50-53-155349_chatcmpl-9a520a6d-7952-4b97-b975-6817d7abadc3",
          "traceId": "ef5a7669",
          "type": "GENERATION",
          "name": "ef5a_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T14:50:53.155000+00:00",
          "endTime": "2026-02-19T14:51:04.573000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11418.0,
          "completionTokens": 860,
          "environment": "default",
          "totalTokens": 1461,
          "promptTokens": 601,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-51-12-790396_chatcmpl-45be1adb-03f4-4a28-b244-40db8e0f1616",
          "traceId": "ef5a7669",
          "type": "GENERATION",
          "name": "ef5a_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T14:51:12.790000+00:00",
          "endTime": "2026-02-19T14:51:23.448000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10658.0,
          "completionTokens": 801,
          "environment": "default",
          "totalTokens": 1424,
          "promptTokens": 623,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:49:56.048Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:52:21.293Z"
    },
    {
      "id": "7d390e85",
      "timestamp": "2026-02-19T14:47:46.965000+00:00",
      "name": "7d39_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n# Function to preprocess input image\ndef preprocess_image(frame):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_details[0]['shape'][2], input_details[0]['shape'][1]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.uint8)\n    return input_data\n\n# Function to draw bounding boxes and labels\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        ymin, xmin, ymax, xmax = detection['bounding_box']\n        class_id = int(detection['class_id'])\n        score = detection['score']\n\n        if score >= confidence_threshold:\n            left, right, top, bottom = (xmin * width), (xmax * width), (ymin * height), (ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[class_id]}: {score:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\n# Main processing loop\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the input image\n    input_data = preprocess_image(frame)\n\n    # Set the tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            detections.append({\n                'bounding_box': (ymin, xmin, ymax, xmax),\n                'class_id': int(classes[i]),\n                'score': float(scores[i])\n            })\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Processing complete. Output saved at:\", output_path)"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 50.68,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-47-46-966431_chatcmpl-27c1ca60-9ca5-45ec-8c61-73eb5b763e8d",
          "traceId": "7d390e85",
          "type": "GENERATION",
          "name": "7d39_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:47:46.966000+00:00",
          "endTime": "2026-02-19T14:47:57.305000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10339.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-48-05-154879_chatcmpl-1142c790-504c-43db-a728-a28c2652ff77",
          "traceId": "7d390e85",
          "type": "GENERATION",
          "name": "7d39_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:48:05.154000+00:00",
          "endTime": "2026-02-19T14:48:17.067000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11913.0,
          "completionTokens": 894,
          "environment": "default",
          "totalTokens": 1460,
          "promptTokens": 566,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-48-25-356565_chatcmpl-73498ee0-8960-4d00-b318-ca02eedfc703",
          "traceId": "7d390e85",
          "type": "GENERATION",
          "name": "7d39_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T14:48:25.356000+00:00",
          "endTime": "2026-02-19T14:48:37.646000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12290.0,
          "completionTokens": 923,
          "environment": "default",
          "totalTokens": 1552,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:47:47.510Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:49:35.211Z"
    },
    {
      "id": "3a737222",
      "timestamp": "2026-02-19T14:45:58.545000+00:00",
      "name": "3a73_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration Parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise ValueError(\"Error opening video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Preprocessing function\ndef preprocess_frame(frame):\n    input_shape = input_details[0]['shape']\n    image_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(image_resized, axis=0)\n    return input_data\n\n# Inference and postprocessing function\ndef detect_objects(input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    return boxes, classes, scores\n\n# Main processing loop\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_data = preprocess_frame(frame)\n    boxes, classes, scores = detect_objects(input_data)\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n            \n            # Draw bounding box and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\n\nprint(\"Processing complete. Output saved to:\", output_path)"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 29.442,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-45-58-546584_chatcmpl-3e487075-85a5-40a5-a799-2b4a1a53347a",
          "traceId": "3a737222",
          "type": "GENERATION",
          "name": "3a73_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:45:58.546000+00:00",
          "endTime": "2026-02-19T14:46:08.986000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10440.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-46-16-823856_chatcmpl-0eb8819b-6d04-4f12-8432-77ce3ddc0ac7",
          "traceId": "3a737222",
          "type": "GENERATION",
          "name": "3a73_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:46:16.823000+00:00",
          "endTime": "2026-02-19T14:46:27.988000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11165.0,
          "completionTokens": 838,
          "environment": "default",
          "totalTokens": 1406,
          "promptTokens": 568,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:45:59.092Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:47:26.263Z"
    },
    {
      "id": "226b25f9",
      "timestamp": "2026-02-19T14:43:12.027000+00:00",
      "name": "226b_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5  # Normalize to [-1, 1]\n    input_data = input_data.astype(np.uint8)\n\n    # Inference\n    interpreter.set_tensor(input_index, input_data)\n    interpreter.invoke()\n\n    # Output handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n\n            # Draw bounding box and label\n            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n            object_name = labels[int(classes[i])]\n            label = f'{object_name}: {int(scores[i] * 100)}%'\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (left, top - round(1.5*label_size[1])), (left + round(1.5*label_size[0]), top + base_line), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Video processing complete.\")"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 89.168,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-43-12-028779_chatcmpl-b64f39ab-595c-4746-9fb8-7dfbabdb27e3",
          "traceId": "226b25f9",
          "type": "GENERATION",
          "name": "226b_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:43:12.028000+00:00",
          "endTime": "2026-02-19T14:43:22.312000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10284.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-43-30-219551_chatcmpl-24f6ed39-fb09-4e00-b140-22402a4bf8f0",
          "traceId": "226b25f9",
          "type": "GENERATION",
          "name": "226b_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:43:30.219000+00:00",
          "endTime": "2026-02-19T14:43:42.101000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11882.0,
          "completionTokens": 892,
          "environment": "default",
          "totalTokens": 1459,
          "promptTokens": 567,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-43-50-539078_chatcmpl-511c6b61-e1fe-4794-809d-f73bfc8dee68",
          "traceId": "226b25f9",
          "type": "GENERATION",
          "name": "226b_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T14:43:50.539000+00:00",
          "endTime": "2026-02-19T14:44:01.332000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10793.0,
          "completionTokens": 811,
          "environment": "default",
          "totalTokens": 1437,
          "promptTokens": 626,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-44-09-642196_chatcmpl-f8227470-9d26-4658-a205-081aa0b8ee24",
          "traceId": "226b25f9",
          "type": "GENERATION",
          "name": "226b_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T14:44:09.642000+00:00",
          "endTime": "2026-02-19T14:44:20.964000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11322.0,
          "completionTokens": 853,
          "environment": "default",
          "totalTokens": 1446,
          "promptTokens": 593,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-44-29-236169_chatcmpl-7791b302-f8dd-4a8d-a4b1-f7062b867fbf",
          "traceId": "226b25f9",
          "type": "GENERATION",
          "name": "226b_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T14:44:29.236000+00:00",
          "endTime": "2026-02-19T14:44:41.196000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11960.0,
          "completionTokens": 900,
          "environment": "default",
          "totalTokens": 1525,
          "promptTokens": 625,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:43:12.579Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:45:38.796Z"
    },
    {
      "id": "13c73670",
      "timestamp": "2026-02-19T14:40:24.515000+00:00",
      "name": "13c7_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5  # Normalize to [-1, 1]\n    input_data = input_data.astype(np.uint8)\n\n    # Inference\n    interpreter.set_tensor(input_index, input_data)\n    interpreter.invoke()\n\n    # Output handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n\n            # Draw bounding box and label\n            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n            object_name = labels[int(classes[i])]\n            label = f'{object_name}: {int(scores[i] * 100)}%'\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (left, top - round(1.5*label_size[1])), (left + round(1.5*label_size[0]), top + base_line), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Video processing complete.\")"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 89.475,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-40-24-516598_chatcmpl-1d93a084-b4bf-4ca3-bd83-57caac305fb9",
          "traceId": "13c73670",
          "type": "GENERATION",
          "name": "13c7_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:40:24.516000+00:00",
          "endTime": "2026-02-19T14:40:34.821000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10305.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-40-42-768195_chatcmpl-2e9f42b1-ad29-4344-855e-1b02f1da56da",
          "traceId": "13c73670",
          "type": "GENERATION",
          "name": "13c7_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:40:42.768000+00:00",
          "endTime": "2026-02-19T14:40:54.745000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11977.0,
          "completionTokens": 898,
          "environment": "default",
          "totalTokens": 1465,
          "promptTokens": 567,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-41-03-033465_chatcmpl-5da5c193-63cf-430e-8d01-1981fd0299a4",
          "traceId": "13c73670",
          "type": "GENERATION",
          "name": "13c7_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T14:41:03.033000+00:00",
          "endTime": "2026-02-19T14:41:14.326000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11293.0,
          "completionTokens": 848,
          "environment": "default",
          "totalTokens": 1474,
          "promptTokens": 626,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-41-22-579182_chatcmpl-bfa5ae6d-094d-459f-ba0b-6e156607f9d0",
          "traceId": "13c73670",
          "type": "GENERATION",
          "name": "13c7_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T14:41:22.579000+00:00",
          "endTime": "2026-02-19T14:41:33.818000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11239.0,
          "completionTokens": 846,
          "environment": "default",
          "totalTokens": 1442,
          "promptTokens": 596,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-41-42-020707_chatcmpl-80af7420-e2cf-46a1-b8a7-abf421e2c102",
          "traceId": "13c73670",
          "type": "GENERATION",
          "name": "13c7_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T14:41:42.020000+00:00",
          "endTime": "2026-02-19T14:41:53.991000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11971.0,
          "completionTokens": 900,
          "environment": "default",
          "totalTokens": 1525,
          "promptTokens": 625,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:40:25.072Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:42:51.820Z"
    },
    {
      "id": "cbd90c04",
      "timestamp": "2026-02-19T14:38:20.069000+00:00",
      "name": "cbd9_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n# Function to preprocess input image\ndef preprocess_image(image):\n    # Resize and normalize the image\n    image_resized = cv2.resize(image, (input_shape[1], input_shape[2]))\n    image_normalized = image_resized / 255.0\n    return np.expand_dims(image_normalized, axis=0).astype(np.float32)\n\n# Function to postprocess output data\ndef postprocess(output_data):\n    # Extract detection results\n    num_detections = int(output_data[0][0])\n    boxes = output_data[1][0]\n    classes = output_data[2][0].astype(int)\n    scores = output_data[3][0]\n\n    detections = []\n    for i in range(num_detections):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[classes[i]]\n            detections.append((label, scores[i], left, top, right, bottom))\n    return detections\n\n# Main processing loop\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the input image\n    input_data = preprocess_image(frame)\n\n    # Set input tensor and run inference\n    interpreter.set_tensor(input_index, input_data)\n    interpreter.invoke()\n\n    # Get output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])\n    classes = interpreter.get_tensor(output_details[1]['index'])\n    scores = interpreter.get_tensor(output_details[2]['index'])\n    count = int(interpreter.get_tensor(output_details[3]['index'])[0])\n\n    # Postprocess the results\n    detections = postprocess([count, boxes, classes, scores])\n\n    # Draw detection boxes and labels on the frame\n    for label, score, left, top, right, bottom in detections:\n        cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n        text = f'{label}: {score:.2f}'\n        cv2.putText(frame, text, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_11e6cfd0_1771511990.py\", line 75, in <module>\n    interpreter.set_tensor(input_index, input_data)\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor ."
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 98.744,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-38-20-071298_chatcmpl-8df7d051-d350-4dde-9a3e-6f0ef04585e6",
          "traceId": "cbd90c04",
          "type": "GENERATION",
          "name": "cbd9_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:38:20.071000+00:00",
          "endTime": "2026-02-19T14:38:30.353000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10282.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-38-38-450633_chatcmpl-49a77ff1-d57a-46c2-853b-df524a9ea01d",
          "traceId": "cbd90c04",
          "type": "GENERATION",
          "name": "cbd9_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:38:38.450000+00:00",
          "endTime": "2026-02-19T14:38:50.785000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12335.0,
          "completionTokens": 926,
          "environment": "default",
          "totalTokens": 1493,
          "promptTokens": 567,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-38-59-071583_chatcmpl-d3472780-2366-49cb-a461-8e018157498c",
          "traceId": "cbd90c04",
          "type": "GENERATION",
          "name": "cbd9_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T14:38:59.071000+00:00",
          "endTime": "2026-02-19T14:39:09.889000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10818.0,
          "completionTokens": 812,
          "environment": "default",
          "totalTokens": 1438,
          "promptTokens": 626,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-39-18-227700_chatcmpl-db2f1419-33aa-413d-ad2b-2cdf18375b00",
          "traceId": "cbd90c04",
          "type": "GENERATION",
          "name": "cbd9_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T14:39:18.227000+00:00",
          "endTime": "2026-02-19T14:39:29.970000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11743.0,
          "completionTokens": 884,
          "environment": "default",
          "totalTokens": 1481,
          "promptTokens": 597,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-39-38-275383_chatcmpl-91535879-d03b-4726-b057-0e0413edeae1",
          "traceId": "cbd90c04",
          "type": "GENERATION",
          "name": "cbd9_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T14:39:38.275000+00:00",
          "endTime": "2026-02-19T14:39:50.334000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12059.0,
          "completionTokens": 905,
          "environment": "default",
          "totalTokens": 1529,
          "promptTokens": 624,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "57057946-ffcc-4828-b664-26ad59f25569",
          "traceId": "cbd90c04",
          "type": "SPAN",
          "name": "error_cb_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2026-02-19T14:39:58.815000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_11e6cfd0_1771511990.py\", line 75, in <module>\n    interpreter.set_tensor(input_index, input_data)\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor .",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T14:38:20.630Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:40:04.328Z"
    },
    {
      "id": "362366cb",
      "timestamp": "2026-02-19T14:35:34.487000+00:00",
      "name": "3623_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef preprocess_frame(frame):\n    # Resize and normalize the frame\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5  # Normalize to [-1, 1]\n    return input_data.astype(np.uint8)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_frame(frame)\n    \n    # Set the tensor and run inference\n    interpreter.set_tensor(input_index, input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            \n            # Draw bounding box and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Video processing complete.\")"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 10
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 88.325,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-35-34-488612_chatcmpl-7b188554-c252-458f-8274-2baa02e6defa",
          "traceId": "362366cb",
          "type": "GENERATION",
          "name": "3623_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:35:34.488000+00:00",
          "endTime": "2026-02-19T14:35:44.768000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10280.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-35-52-731849_chatcmpl-abdfa30b-ddd8-4d5d-8618-d59376f1642b",
          "traceId": "362366cb",
          "type": "GENERATION",
          "name": "3623_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:35:52.731000+00:00",
          "endTime": "2026-02-19T14:36:04.733000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12002.0,
          "completionTokens": 900,
          "environment": "default",
          "totalTokens": 1468,
          "promptTokens": 568,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-36-13-210739_chatcmpl-4415358e-522f-41c4-8bbd-6ca075503941",
          "traceId": "362366cb",
          "type": "GENERATION",
          "name": "3623_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T14:36:13.210000+00:00",
          "endTime": "2026-02-19T14:36:23.967000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10757.0,
          "completionTokens": 807,
          "environment": "default",
          "totalTokens": 1433,
          "promptTokens": 626,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-36-32-168054_chatcmpl-d7d8721c-382a-471a-843f-c6f4eb35399a",
          "traceId": "362366cb",
          "type": "GENERATION",
          "name": "3623_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T14:36:32.168000+00:00",
          "endTime": "2026-02-19T14:36:43.541000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11373.0,
          "completionTokens": 856,
          "environment": "default",
          "totalTokens": 1455,
          "promptTokens": 599,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-36-51-938110_chatcmpl-0960945c-fb42-4bbc-9a38-fe62e90f2d3b",
          "traceId": "362366cb",
          "type": "GENERATION",
          "name": "3623_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T14:36:51.938000+00:00",
          "endTime": "2026-02-19T14:37:02.813000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10875.0,
          "completionTokens": 817,
          "environment": "default",
          "totalTokens": 1439,
          "promptTokens": 622,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:35:35.055Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:38:00.289Z"
    },
    {
      "id": "d131bc07",
      "timestamp": "2026-02-19T14:33:30.940000+00:00",
      "name": "d131_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef preprocess_frame(frame):\n    # Resize and normalize the frame\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5  # Normalize to [-1, 1]\n    return input_data\n\ndef postprocess(output_data):\n    # Extract detection results\n    num_detections = int(output_data[0][0])\n    boxes = output_data[1][0]\n    classes = output_data[2][0].astype(np.int32)\n    scores = output_data[3][0]\n\n    detections = []\n    for i in range(num_detections):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[classes[i]]\n            detections.append((label, scores[i], left, top, right, bottom))\n    return detections\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_frame(frame)\n\n    # Set input tensor\n    interpreter.set_tensor(input_index, input_data.astype(np.float32))\n\n    # Run inference\n    interpreter.invoke()\n\n    # Get output tensors\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Postprocess the results\n    detections = postprocess([boxes, classes, scores])\n\n    # Draw detection boxes and labels on the frame\n    for label, score, left, top, right, bottom in detections:\n        cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n        text = f'{label}: {score:.2f}'\n        cv2.putText(frame, text, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_92931d93_1771511699.py\", line 73, in <module>\n    interpreter.set_tensor(input_index, input_data.astype(np.float32))\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor ."
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 9
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 97.361,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-33-30-942255_chatcmpl-47181add-15e3-44df-ad1c-cd6db29ea992",
          "traceId": "d131bc07",
          "type": "GENERATION",
          "name": "d131_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:33:30.942000+00:00",
          "endTime": "2026-02-19T14:33:41.252000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10310.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-33-49-381415_chatcmpl-82ae7e4a-661c-440f-91d7-396c1ec13d23",
          "traceId": "d131bc07",
          "type": "GENERATION",
          "name": "d131_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:33:49.381000+00:00",
          "endTime": "2026-02-19T14:34:01.730000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12349.0,
          "completionTokens": 925,
          "environment": "default",
          "totalTokens": 1492,
          "promptTokens": 567,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-34-10-126502_chatcmpl-6174f43a-6817-459e-87e2-b5a3ad97af8a",
          "traceId": "d131bc07",
          "type": "GENERATION",
          "name": "d131_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T14:34:10.126000+00:00",
          "endTime": "2026-02-19T14:34:20.640000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10514.0,
          "completionTokens": 790,
          "environment": "default",
          "totalTokens": 1417,
          "promptTokens": 627,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-34-28-919730_chatcmpl-561203d6-3b18-40ce-adda-86234c3724d1",
          "traceId": "d131bc07",
          "type": "GENERATION",
          "name": "d131_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T14:34:28.919000+00:00",
          "endTime": "2026-02-19T14:34:39.033000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10114.0,
          "completionTokens": 762,
          "environment": "default",
          "totalTokens": 1358,
          "promptTokens": 596,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-34-47-370729_chatcmpl-53950c61-a2d7-4407-9547-d43dbf1b8e81",
          "traceId": "d131bc07",
          "type": "GENERATION",
          "name": "d131_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T14:34:47.370000+00:00",
          "endTime": "2026-02-19T14:34:59.963000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12593.0,
          "completionTokens": 945,
          "environment": "default",
          "totalTokens": 1567,
          "promptTokens": 622,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "0aa4c567-995d-4af9-8b9e-806f206df565",
          "traceId": "d131bc07",
          "type": "SPAN",
          "name": "error_d1_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2026-02-19T14:35:08.303000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_92931d93_1771511699.py\", line 73, in <module>\n    interpreter.set_tensor(input_index, input_data.astype(np.float32))\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor .",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T14:33:31.515Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:35:13.708Z"
    },
    {
      "id": "728819c8",
      "timestamp": "2026-02-19T14:30:43.355000+00:00",
      "name": "7288_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef preprocess_frame(frame):\n    # Resize and normalize the frame\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5  # Normalize to [-1, 1]\n    return input_data.astype(np.uint8)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_frame(frame)\n    \n    # Set the tensor and run inference\n    interpreter.set_tensor(input_index, input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            \n            # Draw bounding box and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Video processing complete.\")"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 8
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 89.067,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-30-43-356682_chatcmpl-64e5e1cf-da5f-405d-8f92-b2885ba01e6e",
          "traceId": "728819c8",
          "type": "GENERATION",
          "name": "7288_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:30:43.356000+00:00",
          "endTime": "2026-02-19T14:30:53.823000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10467.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-31-01-858039_chatcmpl-8e8e4d86-2dcc-4673-8f9a-8f66c7692d64",
          "traceId": "728819c8",
          "type": "GENERATION",
          "name": "7288_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:31:01.858000+00:00",
          "endTime": "2026-02-19T14:31:14.083000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12225.0,
          "completionTokens": 917,
          "environment": "default",
          "totalTokens": 1485,
          "promptTokens": 568,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-31-22-384425_chatcmpl-3ae71203-fb72-4c66-aa5e-b27a64159c4c",
          "traceId": "728819c8",
          "type": "GENERATION",
          "name": "7288_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T14:31:22.384000+00:00",
          "endTime": "2026-02-19T14:31:33.665000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11281.0,
          "completionTokens": 848,
          "environment": "default",
          "totalTokens": 1475,
          "promptTokens": 627,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-31-42-178848_chatcmpl-e79dee88-3449-4a23-8a15-01f4b0b42915",
          "traceId": "728819c8",
          "type": "GENERATION",
          "name": "7288_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T14:31:42.178000+00:00",
          "endTime": "2026-02-19T14:31:53.443000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11265.0,
          "completionTokens": 847,
          "environment": "default",
          "totalTokens": 1439,
          "promptTokens": 592,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-32-01-568033_chatcmpl-44e53341-9e23-4c99-8cb0-cb86f887273c",
          "traceId": "728819c8",
          "type": "GENERATION",
          "name": "7288_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T14:32:01.568000+00:00",
          "endTime": "2026-02-19T14:32:12.423000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10855.0,
          "completionTokens": 816,
          "environment": "default",
          "totalTokens": 1441,
          "promptTokens": 625,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:30:43.931Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:33:10.179Z"
    },
    {
      "id": "f0c3b28d",
      "timestamp": "2026-02-19T14:28:33.698000+00:00",
      "name": "f0c3_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n# Function to preprocess input image\ndef preprocess_image(frame):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_details[0]['shape'][2], input_details[0]['shape'][1]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.uint8)\n    return input_data\n\n# Function to draw bounding boxes and labels\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        ymin, xmin, ymax, xmax = detection['bounding_box']\n        class_id = int(detection['class_id'])\n        score = detection['score']\n\n        if score >= confidence_threshold:\n            left, right, top, bottom = (xmin * width, xmax * width,\n                                        ymin * height, ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[class_id]}: {score:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\n# Main processing loop\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the input image\n    input_data = preprocess_image(frame)\n\n    # Set input tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            detections.append({\n                'bounding_box': (ymin, xmin, ymax, xmax),\n                'class_id': int(classes[i]),\n                'score': float(scores[i])\n            })\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Video processing complete. Output saved at:\", output_path)"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 7
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 51.017,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-28-33-700644_chatcmpl-e6cb7686-27b2-4725-96a7-53db7adacf2d",
          "traceId": "f0c3b28d",
          "type": "GENERATION",
          "name": "f0c3_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:28:33.700000+00:00",
          "endTime": "2026-02-19T14:28:43.980000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10280.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-28-51-969392_chatcmpl-21d23811-dbc5-41e2-b7ba-1a51ff2a5a0c",
          "traceId": "f0c3b28d",
          "type": "GENERATION",
          "name": "f0c3_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:28:51.969000+00:00",
          "endTime": "2026-02-19T14:29:04.037000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12068.0,
          "completionTokens": 905,
          "environment": "default",
          "totalTokens": 1473,
          "promptTokens": 568,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-29-12-430071_chatcmpl-ee1ed8e2-3e77-4bc5-b192-50f4595de5ed",
          "traceId": "f0c3b28d",
          "type": "GENERATION",
          "name": "f0c3_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T14:29:12.430000+00:00",
          "endTime": "2026-02-19T14:29:24.717000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12287.0,
          "completionTokens": 921,
          "environment": "default",
          "totalTokens": 1550,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:28:34.273Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:30:22.486Z"
    },
    {
      "id": "f58ac416",
      "timestamp": "2026-02-19T14:25:45.945000+00:00",
      "name": "f58a_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n# Preprocessing function\ndef preprocess_frame(frame):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.uint8)\n    return input_data\n\n# Inference function\ndef infer(input_data):\n    interpreter.set_tensor(input_index, input_data)\n    interpreter.invoke()\n    \n    # Extract output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n    \n    return boxes, classes, scores\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    input_data = preprocess_frame(frame)\n    \n    boxes, classes, scores = infer(input_data)\n    \n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            \n            # Draw bounding box and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n    \n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Video processing complete.\")"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 6
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 89.043,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-25-45-947217_chatcmpl-48008a0d-279d-4371-9328-e4b769a86f13",
          "traceId": "f58ac416",
          "type": "GENERATION",
          "name": "f58a_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:25:45.947000+00:00",
          "endTime": "2026-02-19T14:25:56.246000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10299.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-26-04-272099_chatcmpl-6f349329-d09e-4847-9642-9e69b3be2d8d",
          "traceId": "f58ac416",
          "type": "GENERATION",
          "name": "f58a_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:26:04.272000+00:00",
          "endTime": "2026-02-19T14:26:16.721000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12449.0,
          "completionTokens": 933,
          "environment": "default",
          "totalTokens": 1498,
          "promptTokens": 565,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-26-24-964121_chatcmpl-32413871-e660-42f4-b19b-1f762004ec8c",
          "traceId": "f58ac416",
          "type": "GENERATION",
          "name": "f58a_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T14:26:24.964000+00:00",
          "endTime": "2026-02-19T14:26:36.240000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11276.0,
          "completionTokens": 848,
          "environment": "default",
          "totalTokens": 1476,
          "promptTokens": 628,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-26-44-453595_chatcmpl-9b5165c9-225b-4778-ae64-3646e59406ec",
          "traceId": "f58ac416",
          "type": "GENERATION",
          "name": "f58a_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T14:26:44.453000+00:00",
          "endTime": "2026-02-19T14:26:56.044000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11591.0,
          "completionTokens": 873,
          "environment": "default",
          "totalTokens": 1469,
          "promptTokens": 596,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-27-04-228236_chatcmpl-2e43ebda-7b57-44dc-b505-d7eddaab483d",
          "traceId": "f58ac416",
          "type": "GENERATION",
          "name": "f58a_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T14:27:04.228000+00:00",
          "endTime": "2026-02-19T14:27:14.990000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10762.0,
          "completionTokens": 808,
          "environment": "default",
          "totalTokens": 1432,
          "promptTokens": 624,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:25:46.519Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:28:13.252Z"
    },
    {
      "id": "37693021",
      "timestamp": "2026-02-19T14:22:59.192000+00:00",
      "name": "3769_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef preprocess_frame(frame):\n    # Resize and normalize the frame\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5  # Normalize to [-1, 1]\n    return input_data.astype(np.uint8)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_frame(frame)\n    \n    # Set the tensor and run inference\n    interpreter.set_tensor(input_index, input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            \n            # Draw bounding box and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 5
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 88.561,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-22-59-193491_chatcmpl-77e540f9-b023-429c-a2ac-7f2067f8b991",
          "traceId": "37693021",
          "type": "GENERATION",
          "name": "3769_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:22:59.193000+00:00",
          "endTime": "2026-02-19T14:23:09.482000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10289.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-23-17-365313_chatcmpl-6f47428c-c782-4c3a-b6b8-6f057f73916c",
          "traceId": "37693021",
          "type": "GENERATION",
          "name": "3769_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:23:17.365000+00:00",
          "endTime": "2026-02-19T14:23:29.689000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12324.0,
          "completionTokens": 924,
          "environment": "default",
          "totalTokens": 1490,
          "promptTokens": 566,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-23-38-223242_chatcmpl-324d9a36-76a9-483e-b829-b4de0dd253e1",
          "traceId": "37693021",
          "type": "GENERATION",
          "name": "3769_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T14:23:38.223000+00:00",
          "endTime": "2026-02-19T14:23:48.847000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10624.0,
          "completionTokens": 798,
          "environment": "default",
          "totalTokens": 1425,
          "promptTokens": 627,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-23-57-173053_chatcmpl-ad7951cb-daa2-4d33-a4b2-963140214eb5",
          "traceId": "37693021",
          "type": "GENERATION",
          "name": "3769_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T14:23:57.173000+00:00",
          "endTime": "2026-02-19T14:24:08.818000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11645.0,
          "completionTokens": 877,
          "environment": "default",
          "totalTokens": 1476,
          "promptTokens": 599,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-24-16-983038_chatcmpl-6faa3aa9-211f-4b60-90f3-134e49231947",
          "traceId": "37693021",
          "type": "GENERATION",
          "name": "3769_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T14:24:16.983000+00:00",
          "endTime": "2026-02-19T14:24:27.754000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10771.0,
          "completionTokens": 810,
          "environment": "default",
          "totalTokens": 1434,
          "promptTokens": 624,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:22:59.763Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:25:25.671Z"
    },
    {
      "id": "34343985",
      "timestamp": "2026-02-19T14:20:10.593000+00:00",
      "name": "3434_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5  # Normalize to [-1, 1]\n    input_data = input_data.astype(np.uint8)\n\n    # Inference\n    interpreter.set_tensor(input_index, input_data)\n    interpreter.invoke()\n\n    # Output handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n\n            # Draw bounding box and label\n            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n            object_name = labels[int(classes[i])]\n            label = f'{object_name}: {int(scores[i] * 100)}%'\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (left, top - round(1.5*label_size[1])), (left + round(1.5*label_size[0]), top + base_line), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Video processing complete.\")"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 4
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 90.53,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-20-10-594857_chatcmpl-04c73ffe-3b9e-46a2-b39a-bf82a643b2ee",
          "traceId": "34343985",
          "type": "GENERATION",
          "name": "3434_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:20:10.594000+00:00",
          "endTime": "2026-02-19T14:20:20.884000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10290.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-20-28-880333_chatcmpl-03851cbd-310d-4d7a-883a-c8ddaa519deb",
          "traceId": "34343985",
          "type": "GENERATION",
          "name": "3434_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:20:28.880000+00:00",
          "endTime": "2026-02-19T14:20:41.353000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12473.0,
          "completionTokens": 935,
          "environment": "default",
          "totalTokens": 1502,
          "promptTokens": 567,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-20-49-675504_chatcmpl-67adf19e-882b-419a-9d57-560ed9b4d871",
          "traceId": "34343985",
          "type": "GENERATION",
          "name": "3434_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T14:20:49.675000+00:00",
          "endTime": "2026-02-19T14:21:00.971000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11296.0,
          "completionTokens": 848,
          "environment": "default",
          "totalTokens": 1476,
          "promptTokens": 628,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-21-09-272636_chatcmpl-6ea952f2-e865-4a64-aac5-46bd47b58680",
          "traceId": "34343985",
          "type": "GENERATION",
          "name": "3434_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T14:21:09.272000+00:00",
          "endTime": "2026-02-19T14:21:20.853000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11581.0,
          "completionTokens": 871,
          "environment": "default",
          "totalTokens": 1465,
          "promptTokens": 594,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-21-29-106345_chatcmpl-b1a31d11-2d3b-4ffc-a828-ca287a718636",
          "traceId": "34343985",
          "type": "GENERATION",
          "name": "3434_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T14:21:29.106000+00:00",
          "endTime": "2026-02-19T14:21:41.124000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12018.0,
          "completionTokens": 902,
          "environment": "default",
          "totalTokens": 1526,
          "promptTokens": 624,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:20:11.165Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:22:38.890Z"
    },
    {
      "id": "6a4b7770",
      "timestamp": "2026-02-19T14:17:24.155000+00:00",
      "name": "6a4b_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter with EdgeTPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef preprocess_frame(frame):\n    # Resize and normalize the frame\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5  # Normalize to [-1, 1]\n    return input_data.astype(np.uint8)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_frame(frame)\n    \n    # Set the tensor and run inference\n    interpreter.set_tensor(input_index, input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            \n            # Draw bounding box and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 3
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 88.609,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-17-24-157592_chatcmpl-16155276-dc74-4302-b1c0-ae6f3638bf7d",
          "traceId": "6a4b7770",
          "type": "GENERATION",
          "name": "6a4b_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:17:24.157000+00:00",
          "endTime": "2026-02-19T14:17:34.735000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10578.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-17-42-735274_chatcmpl-9dba22fb-4e32-4987-917c-752bc5337fcc",
          "traceId": "6a4b7770",
          "type": "GENERATION",
          "name": "6a4b_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:17:42.735000+00:00",
          "endTime": "2026-02-19T14:17:54.038000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11303.0,
          "completionTokens": 845,
          "environment": "default",
          "totalTokens": 1411,
          "promptTokens": 566,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-18-02-318718_chatcmpl-aad76794-cc02-4232-9ad5-e1b9efceb82e",
          "traceId": "6a4b7770",
          "type": "GENERATION",
          "name": "6a4b_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T14:18:02.318000+00:00",
          "endTime": "2026-02-19T14:18:13.540000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11222.0,
          "completionTokens": 837,
          "environment": "default",
          "totalTokens": 1500,
          "promptTokens": 663,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-18-22-051980_chatcmpl-aa26004f-f9ec-4eeb-8c40-737ee7e95a79",
          "traceId": "6a4b7770",
          "type": "GENERATION",
          "name": "6a4b_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T14:18:22.051000+00:00",
          "endTime": "2026-02-19T14:18:33.472000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11421.0,
          "completionTokens": 857,
          "environment": "default",
          "totalTokens": 1451,
          "promptTokens": 594,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-18-41-956171_chatcmpl-eac7c28a-db48-4120-95ad-c398ae61ed26",
          "traceId": "6a4b7770",
          "type": "GENERATION",
          "name": "6a4b_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T14:18:41.956000+00:00",
          "endTime": "2026-02-19T14:18:52.766000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10810.0,
          "completionTokens": 810,
          "environment": "default",
          "totalTokens": 1434,
          "promptTokens": 624,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:17:24.725Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:19:50.605Z"
    },
    {
      "id": "cb217186",
      "timestamp": "2026-02-19T14:14:36.217000+00:00",
      "name": "cb21_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\ndef load_labels(path):\n    with open(path, 'r', encoding='utf-8') as f:\n        lines = f.readlines()\n    return {i: line.strip() for i, line in enumerate(lines)}\n\ndef main():\n    # Load labels\n    labels = load_labels(label_path)\n\n    # Initialize the TFLite interpreter with EdgeTPU delegate\n    interpreter = Interpreter(\n        model_path=model_path,\n        experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n    )\n    interpreter.allocate_tensors()\n\n    # Get input and output details\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    input_shape = input_details[0]['shape']\n    input_index = input_details[0]['index']\n\n    # Open video files\n    cap = cv2.VideoCapture(input_path)\n    if not cap.isOpened():\n        print(\"Error: Could not open input video.\")\n        return\n\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n\n    # Define the codec and create VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocess the input image\n        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        img_resized = cv2.resize(img_rgb, (input_shape[1], input_shape[2]))\n        input_data = np.expand_dims(img_resized, axis=0).astype(np.uint8)\n\n        # Run inference\n        interpreter.set_tensor(input_index, input_data)\n        interpreter.invoke()\n\n        # Retrieve detection results\n        boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n        classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n        scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n        for i in range(len(scores)):\n            if scores[i] >= confidence_threshold:\n                ymin, xmin, ymax, xmax = boxes[i]\n                (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n                \n                # Draw bounding box and label on the frame\n                cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n                object_name = labels[int(classes[i])]\n                label = f\"{object_name}: {scores[i]:.2f}\"\n                cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n        # Write the frame with detections\n        out.write(frame)\n\n    # Release resources\n    cap.release()\n    out.release()\n\nif __name__ == \"__main__\":\n    main()"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 2
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 89.437,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-14-36-219051_chatcmpl-5630eb86-1b3d-4d85-a6ed-7cb15a78f8a5",
          "traceId": "cb217186",
          "type": "GENERATION",
          "name": "cb21_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:14:36.219000+00:00",
          "endTime": "2026-02-19T14:14:46.521000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10302.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-14-54-253536_chatcmpl-5ef2aaaf-172c-4b47-9e26-53df07972043",
          "traceId": "cb217186",
          "type": "GENERATION",
          "name": "cb21_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:14:54.253000+00:00",
          "endTime": "2026-02-19T14:15:06.870000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12617.0,
          "completionTokens": 946,
          "environment": "default",
          "totalTokens": 1515,
          "promptTokens": 569,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-15-15-175211_chatcmpl-ae9d4622-f256-43eb-aae3-ce571bd9ca14",
          "traceId": "cb217186",
          "type": "GENERATION",
          "name": "cb21_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T14:15:15.175000+00:00",
          "endTime": "2026-02-19T14:15:25.928000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10753.0,
          "completionTokens": 807,
          "environment": "default",
          "totalTokens": 1436,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-15-33-958098_chatcmpl-cf6732f1-63cd-4ea1-a92c-ec28f3f19a57",
          "traceId": "cb217186",
          "type": "GENERATION",
          "name": "cb21_tpusg_gen_attempt#4",
          "startTime": "2026-02-19T14:15:33.958000+00:00",
          "endTime": "2026-02-19T14:15:45.677000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11719.0,
          "completionTokens": 881,
          "environment": "default",
          "totalTokens": 1474,
          "promptTokens": 593,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-15-54-190271_chatcmpl-e62a8bf5-da0d-4772-bc50-695c9a0efb25",
          "traceId": "cb217186",
          "type": "GENERATION",
          "name": "cb21_tpusg_gen_attempt#5",
          "startTime": "2026-02-19T14:15:54.190000+00:00",
          "endTime": "2026-02-19T14:16:05.656000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11466.0,
          "completionTokens": 859,
          "environment": "default",
          "totalTokens": 1508,
          "promptTokens": 649,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:14:36.786Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:17:03.505Z"
    },
    {
      "id": "76ad1565",
      "timestamp": "2026-02-19T14:12:27.755000+00:00",
      "name": "76ad_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration parameters\nmodel_path = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\ndef load_model():\n    # Initialize the TFLite interpreter with EdgeTPU delegate\n    interpreter = Interpreter(\n        model_path=model_path,\n        experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n    )\n    interpreter.allocate_tensors()\n    return interpreter\n\ndef preprocess_frame(frame, input_details):\n    # Resize and normalize the frame to match the model's expected input\n    input_shape = input_details[0]['shape']\n    image_size = (input_shape[1], input_shape[2])\n    frame_resized = cv2.resize(frame, image_size)\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.uint8)\n    return input_data\n\ndef infer(interpreter, input_data):\n    # Set the tensor to be used for inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Run inference\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    return boxes, classes, scores\n\ndef draw_detections(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {int(scores[i] * 100)}%\"\n            cv2.putText(frame, label, (int(left), int(top) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\ndef main():\n    # Load the TFLite model and allocate tensors\n    interpreter = load_model()\n\n    global input_details, output_details\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    # Open video file\n    cap = cv2.VideoCapture(input_path)\n    if not cap.isOpened():\n        print(\"Error: Could not open video.\")\n        return\n\n    # Get video properties\n    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n\n    # Define the codec and create VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocess the frame\n        input_data = preprocess_frame(frame, input_details)\n\n        # Perform inference\n        boxes, classes, scores = infer(interpreter, input_data)\n\n        # Draw detections on the frame\n        draw_detections(frame, boxes, classes, scores)\n\n        # Write the frame with detections to output video\n        out.write(frame)\n\n    # Release resources\n    cap.release()\n    out.release()\n\nif __name__ == \"__main__\":\n    main()"
      },
      "session_id": "phi4_29a1_tpusg_batch",
      "metadata": {
        "num_run": 1
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 50.314,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-12-27-756623_chatcmpl-8d187bf3-436c-48d7-aadc-03c7f610609d",
          "traceId": "76ad1565",
          "type": "GENERATION",
          "name": "76ad_tpusg_gen_attempt#1",
          "startTime": "2026-02-19T14:12:27.756000+00:00",
          "endTime": "2026-02-19T14:12:38.114000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10358.0,
          "completionTokens": 775,
          "environment": "default",
          "totalTokens": 1229,
          "promptTokens": 454,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-12-45-924248_chatcmpl-88b57aac-184b-4d81-b990-46cc319dde95",
          "traceId": "76ad1565",
          "type": "GENERATION",
          "name": "76ad_tpusg_gen_attempt#2",
          "startTime": "2026-02-19T14:12:45.924000+00:00",
          "endTime": "2026-02-19T14:12:57.217000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11293.0,
          "completionTokens": 845,
          "environment": "default",
          "totalTokens": 1412,
          "promptTokens": 567,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-13-05-353394_chatcmpl-18339e69-7a99-4c00-997f-083b828011b5",
          "traceId": "76ad1565",
          "type": "GENERATION",
          "name": "76ad_tpusg_gen_attempt#3",
          "startTime": "2026-02-19T14:13:05.353000+00:00",
          "endTime": "2026-02-19T14:13:18.070000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12717.0,
          "completionTokens": 950,
          "environment": "default",
          "totalTokens": 1615,
          "promptTokens": 665,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:12:28.322Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:14:16.200Z"
    }
  ],
  "meta": {
    "total_items": 30
  }
}