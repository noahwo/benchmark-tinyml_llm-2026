{
  "data": [
    {
      "id": "b05aea00",
      "timestamp": "2026-02-19T14:11:24.305000+00:00",
      "name": "b05a_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Function to preprocess input image\ndef preprocess_image(frame):\n    # Resize and normalize the image\n    input_size = input_details[0]['shape'][1:3]\n    resized_frame = cv2.resize(frame, input_size)\n    normalized_frame = np.expand_dims(resized_frame / 255.0, axis=0).astype(np.float32)\n    return normalized_frame\n\n# Function to draw bounding boxes and labels\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        # Extract information from the detection\n        ymin, xmin, ymax, xmax = detection['bbox']\n        class_id = int(detection['class_id'])\n        score = float(detection['score'])\n\n        if score >= confidence_threshold:\n            label = labels[class_id]\n            cv2.rectangle(frame, (int(xmin * frame_width), int(ymin * frame_height)),\n                          (int(xmax * frame_width), int(ymax * frame_height)), (0, 255, 0), 2)\n            text = f'{label}: {score:.2f}'\n            cv2.putText(frame, text, (int(xmin * frame_width), int(ymin * frame_height - 10)),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n# Main processing loop\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the input image\n    input_data = preprocess_image(frame)\n    \n    # Set the tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            detection = {\n                'bbox': (ymin, xmin, ymax, xmax),\n                'class_id': int(classes[i]),\n                'score': float(scores[i])\n            }\n            detections.append(detection)\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219161221_psg_phi4:latest/tmp_20260219161221_psg_phi4:latest.py\", line 68, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 57.169,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-11-24-307265_chatcmpl-d6e475c9-c165-4e91-a1ec-c1c1f596f912",
          "traceId": "b05aea00",
          "type": "GENERATION",
          "name": "b05a_psg_gen_attempt#1",
          "startTime": "2026-02-19T14:11:24.307000+00:00",
          "endTime": "2026-02-19T14:11:34.835000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10528.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-11-34-999166_chatcmpl-84597a51-4698-42b2-ace4-76860ee4b75f",
          "traceId": "b05aea00",
          "type": "GENERATION",
          "name": "b05a_psg_gen_attempt#2",
          "startTime": "2026-02-19T14:11:34.999000+00:00",
          "endTime": "2026-02-19T14:11:44.808000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9809.0,
          "completionTokens": 736,
          "environment": "default",
          "totalTokens": 1296,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-11-45-121643_chatcmpl-3da42a00-1e9e-4ba4-a4b2-f34b002a38bc",
          "traceId": "b05aea00",
          "type": "GENERATION",
          "name": "b05a_psg_gen_attempt#3",
          "startTime": "2026-02-19T14:11:45.121000+00:00",
          "endTime": "2026-02-19T14:11:57.159000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12038.0,
          "completionTokens": 906,
          "environment": "default",
          "totalTokens": 1535,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-11-57-310332_chatcmpl-cfb24544-fc4d-480c-99f3-565c38ef404a",
          "traceId": "b05aea00",
          "type": "GENERATION",
          "name": "b05a_psg_gen_attempt#4",
          "startTime": "2026-02-19T14:11:57.310000+00:00",
          "endTime": "2026-02-19T14:12:09.600000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12290.0,
          "completionTokens": 924,
          "environment": "default",
          "totalTokens": 1557,
          "promptTokens": 633,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-12-09-752744_chatcmpl-0ad33ed8-def2-4507-8c60-9fceaf2ef8f2",
          "traceId": "b05aea00",
          "type": "GENERATION",
          "name": "b05a_psg_gen_attempt#5",
          "startTime": "2026-02-19T14:12:09.752000+00:00",
          "endTime": "2026-02-19T14:12:21.319000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11567.0,
          "completionTokens": 870,
          "environment": "default",
          "totalTokens": 1499,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "15ab852e-3b14-4c7d-a013-cc36ae676db1",
          "traceId": "b05aea00",
          "type": "SPAN",
          "name": "error_b0_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-19T14:12:21.476000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219161221_psg_phi4:latest/tmp_20260219161221_psg_phi4:latest.py\", line 68, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T14:11:24.874Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:12:27.011Z"
    },
    {
      "id": "53056a44",
      "timestamp": "2026-02-19T14:10:00.781000+00:00",
      "name": "5305_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise ValueError(\"Error opening video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Function to preprocess input image\ndef preprocess_image(image):\n    # Resize and normalize the image\n    input_shape = input_details[0]['shape']\n    resized_image = cv2.resize(image, (input_shape[2], input_shape[1]))\n    normalized_image = np.expand_dims(resized_image, axis=0).astype(np.float32)\n    normalized_image /= 255.0\n    return normalized_image\n\n# Function to draw bounding boxes and labels on the image\ndef draw_boxes(image, detections):\n    for detection in detections:\n        # Extract information from the detection\n        ymin, xmin, ymax, xmax = detection['bbox']\n        class_id = int(detection['class_id'])\n        score = float(detection['score'])\n\n        if score >= confidence_threshold:\n            label = labels[class_id]\n            left, right, top, bottom = (xmin * image.shape[1], xmax * image.shape[1],\n                                        ymin * image.shape[0], ymax * image.shape[0])\n            \n            # Draw rectangle and label\n            cv2.rectangle(image, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            text = f'{label}: {score:.2f}'\n            cv2.putText(image, text, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_data = preprocess_image(frame)\n    \n    # Set tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    # Prepare detections list\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            detection = {\n                'bbox': (ymin, xmin, ymax, xmax),\n                'class_id': int(classes[i]),\n                'score': float(scores[i])\n            }\n            detections.append(detection)\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n    \n    # Write the frame with detections to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219161057_psg_phi4:latest/tmp_20260219161057_psg_phi4:latest.py\", line 74, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 56.661,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-10-00-782801_chatcmpl-971c0814-cdad-4f47-b8be-f474acb20459",
          "traceId": "53056a44",
          "type": "GENERATION",
          "name": "5305_psg_gen_attempt#1",
          "startTime": "2026-02-19T14:10:00.782000+00:00",
          "endTime": "2026-02-19T14:10:11.316000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10534.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-10-11-475551_chatcmpl-51ee9e77-c50c-4d91-aff7-955ab2104739",
          "traceId": "53056a44",
          "type": "GENERATION",
          "name": "5305_psg_gen_attempt#2",
          "startTime": "2026-02-19T14:10:11.475000+00:00",
          "endTime": "2026-02-19T14:10:21.005000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9530.0,
          "completionTokens": 715,
          "environment": "default",
          "totalTokens": 1275,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-10-21-206294_chatcmpl-b00e3619-4d80-4c84-84dd-384b9432ec74",
          "traceId": "53056a44",
          "type": "GENERATION",
          "name": "5305_psg_gen_attempt#3",
          "startTime": "2026-02-19T14:10:21.206000+00:00",
          "endTime": "2026-02-19T14:10:32.562000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11356.0,
          "completionTokens": 854,
          "environment": "default",
          "totalTokens": 1483,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-10-32-736357_chatcmpl-d99f5896-8219-439c-85af-86ea6e4b1214",
          "traceId": "53056a44",
          "type": "GENERATION",
          "name": "5305_psg_gen_attempt#4",
          "startTime": "2026-02-19T14:10:32.736000+00:00",
          "endTime": "2026-02-19T14:10:44.760000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12024.0,
          "completionTokens": 901,
          "environment": "default",
          "totalTokens": 1530,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-10-45-011553_chatcmpl-e11ebb1a-fff5-4bc2-a883-0ae9686aa2a0",
          "traceId": "53056a44",
          "type": "GENERATION",
          "name": "5305_psg_gen_attempt#5",
          "startTime": "2026-02-19T14:10:45.011000+00:00",
          "endTime": "2026-02-19T14:10:57.282000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12271.0,
          "completionTokens": 922,
          "environment": "default",
          "totalTokens": 1555,
          "promptTokens": 633,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "7a0a64a6-790c-464b-ab50-c846c0325f32",
          "traceId": "53056a44",
          "type": "SPAN",
          "name": "error_53_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-19T14:10:57.443000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219161057_psg_phi4:latest/tmp_20260219161057_psg_phi4:latest.py\", line 74, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T14:10:01.349Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:11:03.205Z"
    },
    {
      "id": "5a20d359",
      "timestamp": "2026-02-19T14:08:19.287000+00:00",
      "name": "5a20_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Function to preprocess input image\ndef preprocess_image(frame):\n    # Resize and normalize the image\n    input_size = input_details[0]['shape'][1:3]\n    frame_resized = cv2.resize(frame, input_size)\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    input_data = (input_data / 127.5) - 1.0\n    return input_data\n\n# Function to draw bounding boxes and labels on the frame\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        # Extract information from the detection\n        ymin, xmin, ymax, xmax, score, class_id = detection\n        if score < confidence_threshold:\n            continue\n        \n        # Scale box to original image size\n        (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                     ymin * frame.shape[0], ymax * frame.shape[0])\n        \n        # Draw rectangle and label on the frame\n        cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n        label = f\"{labels[int(class_id)]}: {score:.2f}\"\n        cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_image(frame)\n    \n    # Set tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.uint8))\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    # Prepare detections for drawing\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            class_id = int(classes[i])\n            score = float(scores[i])\n            detections.append((ymin, xmin, ymax, xmax, score, class_id))\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 43.952,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-08-19-288620_chatcmpl-d13586fa-b119-408b-8cc3-6faf996314a9",
          "traceId": "5a20d359",
          "type": "GENERATION",
          "name": "5a20_psg_gen_attempt#1",
          "startTime": "2026-02-19T14:08:19.288000+00:00",
          "endTime": "2026-02-19T14:08:29.814000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10526.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-08-29-962402_chatcmpl-95309af2-04e9-40bb-b518-0e3eb7a971b5",
          "traceId": "5a20d359",
          "type": "GENERATION",
          "name": "5a20_psg_gen_attempt#2",
          "startTime": "2026-02-19T14:08:29.962000+00:00",
          "endTime": "2026-02-19T14:08:40+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10038.0,
          "completionTokens": 753,
          "environment": "default",
          "totalTokens": 1313,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-08-40-158798_chatcmpl-d5a09acc-8729-4454-86f6-1d7396996e66",
          "traceId": "5a20d359",
          "type": "GENERATION",
          "name": "5a20_psg_gen_attempt#3",
          "startTime": "2026-02-19T14:08:40.158000+00:00",
          "endTime": "2026-02-19T14:08:51.053000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10895.0,
          "completionTokens": 819,
          "environment": "default",
          "totalTokens": 1448,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-08-51-210949_chatcmpl-98890fbe-79a4-4a59-b20f-f40b91d83beb",
          "traceId": "5a20d359",
          "type": "GENERATION",
          "name": "5a20_psg_gen_attempt#4",
          "startTime": "2026-02-19T14:08:51.210000+00:00",
          "endTime": "2026-02-19T14:09:03.240000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12030.0,
          "completionTokens": 905,
          "environment": "default",
          "totalTokens": 1534,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:08:19.853Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:09:40.506Z"
    },
    {
      "id": "21fab17c",
      "timestamp": "2026-02-19T14:06:54.884000+00:00",
      "name": "21fa_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Function to preprocess input image\ndef preprocess_image(image):\n    # Resize and normalize the image\n    input_shape = input_details[0]['shape']\n    resized_image = cv2.resize(image, (input_shape[2], input_shape[1]))\n    normalized_image = np.expand_dims(resized_image / 255.0, axis=0).astype(np.float32)\n    return normalized_image\n\n# Function to draw bounding boxes and labels\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        # Extract information from the detection\n        ymin, xmin, ymax, xmax = detection['bbox']\n        class_id = int(detection['class_id'])\n        score = float(detection['score'])\n\n        if score >= confidence_threshold:\n            # Scale bounding box to frame dimensions\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            # Draw rectangle and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[class_id]}: {score:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n# Main processing loop\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the input image\n    input_data = preprocess_image(frame)\n    \n    # Set the tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n    interpreter.invoke()\n\n    # Extract output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    # Prepare detections list\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            detections.append({\n                'bbox': (ymin, xmin, ymax, xmax),\n                'class_id': int(classes[i]),\n                'score': float(scores[i])\n            })\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219160752_psg_phi4:latest/tmp_20260219160752_psg_phi4:latest.py\", line 70, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 57.438,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-06-54-885369_chatcmpl-4105a6f5-5d18-4654-aaee-0e3a294e298c",
          "traceId": "21fab17c",
          "type": "GENERATION",
          "name": "21fa_psg_gen_attempt#1",
          "startTime": "2026-02-19T14:06:54.885000+00:00",
          "endTime": "2026-02-19T14:07:05.399000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10514.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-07-05-539653_chatcmpl-c8643ecc-d234-42b4-8794-6c283fbc96b1",
          "traceId": "21fab17c",
          "type": "GENERATION",
          "name": "21fa_psg_gen_attempt#2",
          "startTime": "2026-02-19T14:07:05.539000+00:00",
          "endTime": "2026-02-19T14:07:15.468000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9929.0,
          "completionTokens": 745,
          "environment": "default",
          "totalTokens": 1305,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-07-15-624764_chatcmpl-c43acc81-29f8-4462-9c34-68fe9383a6cb",
          "traceId": "21fab17c",
          "type": "GENERATION",
          "name": "21fa_psg_gen_attempt#3",
          "startTime": "2026-02-19T14:07:15.624000+00:00",
          "endTime": "2026-02-19T14:07:27.616000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11992.0,
          "completionTokens": 902,
          "environment": "default",
          "totalTokens": 1531,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-07-27-769940_chatcmpl-001e7641-806d-4510-8fe5-0a8e55b8516a",
          "traceId": "21fab17c",
          "type": "GENERATION",
          "name": "21fa_psg_gen_attempt#4",
          "startTime": "2026-02-19T14:07:27.769000+00:00",
          "endTime": "2026-02-19T14:07:39.964000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12195.0,
          "completionTokens": 917,
          "environment": "default",
          "totalTokens": 1550,
          "promptTokens": 633,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-07-40-128639_chatcmpl-03e7e532-b5fe-4615-b7a6-d9b003449bd2",
          "traceId": "21fab17c",
          "type": "GENERATION",
          "name": "21fa_psg_gen_attempt#5",
          "startTime": "2026-02-19T14:07:40.128000+00:00",
          "endTime": "2026-02-19T14:07:52.170000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12042.0,
          "completionTokens": 906,
          "environment": "default",
          "totalTokens": 1535,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "f592e1c7-5c19-45db-a08f-35ffc90d277b",
          "traceId": "21fab17c",
          "type": "SPAN",
          "name": "error_21_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-19T14:07:52.323000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219160752_psg_phi4:latest/tmp_20260219160752_psg_phi4:latest.py\", line 70, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T14:06:55.452Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:07:58.328Z"
    },
    {
      "id": "fbdb534b",
      "timestamp": "2026-02-19T14:05:01.398000+00:00",
      "name": "fbdb_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise ValueError(\"Error opening video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Function to preprocess input image\ndef preprocess_image(image):\n    # Resize and normalize the image\n    input_size = input_details[0]['shape'][1:3]\n    image_resized = cv2.resize(image, input_size)\n    image_normalized = image_resized / 255.0\n    return np.expand_dims(image_normalized, axis=0).astype(np.float32)\n\n# Function to draw bounding boxes and labels on the image\ndef draw_boxes(image, detections, threshold):\n    for detection in detections:\n        score = detection[2]\n        if score > threshold:\n            ymin, xmin, ymax, xmax = detection[0:4]\n            left, right, top, bottom = int(xmin * frame_width), int(xmax * frame_width), int(ymin * frame_height), int(ymax * frame_height)\n            \n            # Draw rectangle\n            cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n\n            # Get label and draw text\n            class_id = int(detection[1])\n            label = f\"{labels[class_id]}: {score:.2f}\"\n            cv2.putText(image, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_data = preprocess_image(frame)\n    \n    # Set tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.uint8))\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    # Combine results into a single array\n    detections = np.concatenate((boxes, classes[:, None], scores[:, None]), axis=1)\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections, confidence_threshold)\n\n    # Write the frame with detections to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Video processing complete. Output saved at:\", output_path)"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 55.751,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-05-01-400225_chatcmpl-1427d9e8-2003-41e8-8d6b-a5a488c156ba",
          "traceId": "fbdb534b",
          "type": "GENERATION",
          "name": "fbdb_psg_gen_attempt#1",
          "startTime": "2026-02-19T14:05:01.400000+00:00",
          "endTime": "2026-02-19T14:05:11.924000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10524.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-05-12-076253_chatcmpl-78b707f8-b820-4a55-8aa4-80437e3661ec",
          "traceId": "fbdb534b",
          "type": "GENERATION",
          "name": "fbdb_psg_gen_attempt#2",
          "startTime": "2026-02-19T14:05:12.076000+00:00",
          "endTime": "2026-02-19T14:05:20.980000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 8904.0,
          "completionTokens": 667,
          "environment": "default",
          "totalTokens": 1227,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-05-21-137059_chatcmpl-ec316e88-2146-491d-8f9e-470de59c2dbd",
          "traceId": "fbdb534b",
          "type": "GENERATION",
          "name": "fbdb_psg_gen_attempt#3",
          "startTime": "2026-02-19T14:05:21.137000+00:00",
          "endTime": "2026-02-19T14:05:33.187000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12050.0,
          "completionTokens": 906,
          "environment": "default",
          "totalTokens": 1535,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-05-33-354296_chatcmpl-97e4089b-75c6-483c-b146-6d130e9ba0c4",
          "traceId": "fbdb534b",
          "type": "GENERATION",
          "name": "fbdb_psg_gen_attempt#4",
          "startTime": "2026-02-19T14:05:33.354000+00:00",
          "endTime": "2026-02-19T14:05:45.460000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12106.0,
          "completionTokens": 909,
          "environment": "default",
          "totalTokens": 1542,
          "promptTokens": 633,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-05-45-609165_chatcmpl-b07bd126-4d32-4e8a-95de-dbc6c2196b9e",
          "traceId": "fbdb534b",
          "type": "GENERATION",
          "name": "fbdb_psg_gen_attempt#5",
          "startTime": "2026-02-19T14:05:45.609000+00:00",
          "endTime": "2026-02-19T14:05:57.151000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11542.0,
          "completionTokens": 866,
          "environment": "default",
          "totalTokens": 1495,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T14:05:01.963Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:06:34.628Z"
    },
    {
      "id": "a79648ac",
      "timestamp": "2026-02-19T14:03:37.964000+00:00",
      "name": "a796_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise ValueError(\"Error opening video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Function to preprocess input image\ndef preprocess_image(image):\n    # Resize and normalize the image\n    input_size = input_details[0]['shape'][1:3]\n    image_resized = cv2.resize(image, input_size)\n    image_normalized = image_resized / 255.0\n    return np.expand_dims(image_normalized, axis=0).astype(np.float32)\n\n# Function to draw bounding boxes and labels on the image\ndef draw_boxes(image, detections, threshold):\n    for detection in detections:\n        score = detection[2]\n        if score >= threshold:\n            ymin, xmin, ymax, xmax = detection[1:5]\n            left, right, top, bottom = int(xmin * frame_width), int(xmax * frame_width), int(ymin * frame_height), int(ymax * frame_height)\n            \n            # Draw rectangle\n            cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n            \n            # Get label and draw text\n            class_id = int(detection[0])\n            label = f\"{labels[class_id]}: {score:.2f}\"\n            cv2.putText(image, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_data = preprocess_image(frame)\n    \n    # Set tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.uint8))\n    interpreter.invoke()\n\n    # Get output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    # Combine boxes, classes, and scores into a single list for easier processing\n    detections = np.stack([classes, boxes, scores], axis=1)\n\n    # Draw bounding boxes on the frame\n    draw_boxes(frame, detections, confidence_threshold)\n\n    # Write the frame with detections to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Video processing complete. Output saved at:\", output_path)",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219160434_psg_phi4:latest/tmp_20260219160434_psg_phi4:latest.py\", line 80, in <module>\n    detections = np.stack([classes, boxes, scores], axis=1)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/core/shape_base.py\", line 449, in stack\n    raise ValueError('all input arrays must have the same shape')\nValueError: all input arrays must have the same shape\n"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 57.273,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-03-37-965431_chatcmpl-567b6beb-fcc4-4ed7-ae54-d9a860e9a724",
          "traceId": "a79648ac",
          "type": "GENERATION",
          "name": "a796_psg_gen_attempt#1",
          "startTime": "2026-02-19T14:03:37.965000+00:00",
          "endTime": "2026-02-19T14:03:48.745000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10780.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-03-48-889231_chatcmpl-6157b4d5-1191-436c-a208-34adb242ece0",
          "traceId": "a79648ac",
          "type": "GENERATION",
          "name": "a796_psg_gen_attempt#2",
          "startTime": "2026-02-19T14:03:48.889000+00:00",
          "endTime": "2026-02-19T14:03:58.726000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9837.0,
          "completionTokens": 733,
          "environment": "default",
          "totalTokens": 1293,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-03-58-885700_chatcmpl-5aa18fac-c7f0-4185-8fa2-abc0281e63f8",
          "traceId": "a79648ac",
          "type": "GENERATION",
          "name": "a796_psg_gen_attempt#3",
          "startTime": "2026-02-19T14:03:58.885000+00:00",
          "endTime": "2026-02-19T14:04:10.948000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12063.0,
          "completionTokens": 907,
          "environment": "default",
          "totalTokens": 1536,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-04-11-104759_chatcmpl-d3cb313d-b230-40d7-ba28-2db587dbb36c",
          "traceId": "a79648ac",
          "type": "GENERATION",
          "name": "a796_psg_gen_attempt#4",
          "startTime": "2026-02-19T14:04:11.104000+00:00",
          "endTime": "2026-02-19T14:04:23.039000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11935.0,
          "completionTokens": 896,
          "environment": "default",
          "totalTokens": 1529,
          "promptTokens": 633,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-04-23-196559_chatcmpl-e156fc86-be2b-410c-b6be-d42b371957aa",
          "traceId": "a79648ac",
          "type": "GENERATION",
          "name": "a796_psg_gen_attempt#5",
          "startTime": "2026-02-19T14:04:23.196000+00:00",
          "endTime": "2026-02-19T14:04:34.889000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11693.0,
          "completionTokens": 877,
          "environment": "default",
          "totalTokens": 1506,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "f962e28c-c7d1-4838-9ca6-73d147e7b543",
          "traceId": "a79648ac",
          "type": "SPAN",
          "name": "error_a7_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-19T14:04:35.238000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219160434_psg_phi4:latest/tmp_20260219160434_psg_phi4:latest.py\", line 80, in <module>\n    detections = np.stack([classes, boxes, scores], axis=1)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/core/shape_base.py\", line 449, in stack\n    raise ValueError('all input arrays must have the same shape')\nValueError: all input arrays must have the same shape\n",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T14:03:38.527Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:04:40.618Z"
    },
    {
      "id": "1d89d072",
      "timestamp": "2026-02-19T14:02:14.420000+00:00",
      "name": "1d89_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise ValueError(\"Error opening video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Function to preprocess input image\ndef preprocess_image(image):\n    # Resize and normalize the image\n    input_shape = input_details[0]['shape']\n    resized_image = cv2.resize(image, (input_shape[2], input_shape[1]))\n    normalized_image = resized_image / 255.0\n    return np.expand_dims(normalized_image, axis=0).astype(np.float32)\n\n# Function to draw bounding boxes and labels on the image\ndef draw_boxes(image, detections):\n    for detection in detections:\n        # Extract information from the detection\n        ymin, xmin, ymax, xmax = detection['bbox']\n        class_id = int(detection['class_id'])\n        score = float(detection['score'])\n\n        if score >= confidence_threshold:\n            label = labels[class_id]\n            left, right, top, bottom = (xmin * image.shape[1], xmax * image.shape[1],\n                                        ymin * image.shape[0], ymax * image.shape[0])\n            \n            # Draw rectangle and label\n            cv2.rectangle(image, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            text = f'{label}: {score:.2f}'\n            cv2.putText(image, text, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_data = preprocess_image(frame)\n    \n    # Set tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    # Prepare detections list\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            detections.append({\n                'bbox': (ymin, xmin, ymax, xmax),\n                'class_id': int(classes[i]),\n                'score': float(scores[i])\n            })\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the frame with detections to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219160312_psg_phi4:latest/tmp_20260219160312_psg_phi4:latest.py\", line 73, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 58.338,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-02-14-421145_chatcmpl-8c766e49-b986-4917-bb74-ba0543dea39d",
          "traceId": "1d89d072",
          "type": "GENERATION",
          "name": "1d89_psg_gen_attempt#1",
          "startTime": "2026-02-19T14:02:14.421000+00:00",
          "endTime": "2026-02-19T14:02:24.989000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10568.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-02-25-143041_chatcmpl-19b6131c-d610-4316-bfc9-a36a9b46fbee",
          "traceId": "1d89d072",
          "type": "GENERATION",
          "name": "1d89_psg_gen_attempt#2",
          "startTime": "2026-02-19T14:02:25.143000+00:00",
          "endTime": "2026-02-19T14:02:34.905000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9762.0,
          "completionTokens": 733,
          "environment": "default",
          "totalTokens": 1293,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-02-35-069150_chatcmpl-02f632ff-84e4-4326-ae60-8c18c5abe17b",
          "traceId": "1d89d072",
          "type": "GENERATION",
          "name": "1d89_psg_gen_attempt#3",
          "startTime": "2026-02-19T14:02:35.069000+00:00",
          "endTime": "2026-02-19T14:02:47.125000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12056.0,
          "completionTokens": 897,
          "environment": "default",
          "totalTokens": 1526,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-02-47-365308_chatcmpl-26d55373-aba4-4915-8e91-369963ef20c9",
          "traceId": "1d89d072",
          "type": "GENERATION",
          "name": "1d89_psg_gen_attempt#4",
          "startTime": "2026-02-19T14:02:47.365000+00:00",
          "endTime": "2026-02-19T14:02:59.963000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12598.0,
          "completionTokens": 907,
          "environment": "default",
          "totalTokens": 1536,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-03-00-122031_chatcmpl-7f47c92a-ff08-4231-b7de-875927fbde2b",
          "traceId": "1d89d072",
          "type": "GENERATION",
          "name": "1d89_psg_gen_attempt#5",
          "startTime": "2026-02-19T14:03:00.122000+00:00",
          "endTime": "2026-02-19T14:03:12.598000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12476.0,
          "completionTokens": 910,
          "environment": "default",
          "totalTokens": 1543,
          "promptTokens": 633,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "80d467fa-81dd-42ba-9a5d-58afddcdbbfd",
          "traceId": "1d89d072",
          "type": "SPAN",
          "name": "error_1d_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-19T14:03:12.759000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219160312_psg_phi4:latest/tmp_20260219160312_psg_phi4:latest.py\", line 73, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T14:02:14.982Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:03:18.113Z"
    },
    {
      "id": "b4c38383",
      "timestamp": "2026-02-19T14:00:48.989000+00:00",
      "name": "b4c3_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Function to preprocess input image\ndef preprocess_image(frame):\n    # Resize and normalize the image\n    input_size = input_details[0]['shape'][1:3]\n    frame_resized = cv2.resize(frame, input_size)\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    input_data = (input_data / 127.5) - 1.0\n    return input_data\n\n# Function to draw bounding boxes and labels on the frame\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        # Extract information from the detection\n        ymin, xmin, ymax, xmax, score, class_id = detection\n        if score < confidence_threshold:\n            continue\n        \n        # Scale box to original image size\n        (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                     ymin * frame.shape[0], ymax * frame.shape[0])\n        \n        # Draw rectangle and label on the frame\n        cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n        label = f\"{labels[int(class_id)]}: {score:.2f}\"\n        cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_image(frame)\n    \n    # Set tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    # Filter out detections below the confidence threshold\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            class_id = int(classes[i])\n            detections.append((ymin, xmin, ymax, xmax, scores[i], class_id))\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219160147_psg_phi4:latest/tmp_20260219160147_psg_phi4:latest.py\", line 70, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 58.722,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-16-00-48-989614_chatcmpl-7de79223-8cff-4435-ba65-7a42a0b2ee9b",
          "traceId": "b4c38383",
          "type": "GENERATION",
          "name": "b4c3_psg_gen_attempt#1",
          "startTime": "2026-02-19T14:00:48.989000+00:00",
          "endTime": "2026-02-19T14:00:59.503000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10514.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-00-59-644478_chatcmpl-d170def8-618a-40bc-9d2e-c06961e0a0c4",
          "traceId": "b4c38383",
          "type": "GENERATION",
          "name": "b4c3_psg_gen_attempt#2",
          "startTime": "2026-02-19T14:00:59.644000+00:00",
          "endTime": "2026-02-19T14:01:11.073000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11429.0,
          "completionTokens": 859,
          "environment": "default",
          "totalTokens": 1419,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-01-11-237526_chatcmpl-5b86f699-f58b-46bc-a002-8715fb036220",
          "traceId": "b4c38383",
          "type": "GENERATION",
          "name": "b4c3_psg_gen_attempt#3",
          "startTime": "2026-02-19T14:01:11.237000+00:00",
          "endTime": "2026-02-19T14:01:23.296000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12059.0,
          "completionTokens": 907,
          "environment": "default",
          "totalTokens": 1536,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-01-23-454147_chatcmpl-e4c2993a-7179-497d-aab8-89a549262a60",
          "traceId": "b4c38383",
          "type": "GENERATION",
          "name": "b4c3_psg_gen_attempt#4",
          "startTime": "2026-02-19T14:01:23.454000+00:00",
          "endTime": "2026-02-19T14:01:35.350000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11896.0,
          "completionTokens": 895,
          "environment": "default",
          "totalTokens": 1528,
          "promptTokens": 633,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-01-35-501667_chatcmpl-01a83a62-c44d-44c0-a976-c1feb8a21961",
          "traceId": "b4c38383",
          "type": "GENERATION",
          "name": "b4c3_psg_gen_attempt#5",
          "startTime": "2026-02-19T14:01:35.501000+00:00",
          "endTime": "2026-02-19T14:01:47.448000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11947.0,
          "completionTokens": 899,
          "environment": "default",
          "totalTokens": 1528,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "b782160d-ceb6-448d-94f8-5e08e642bdfd",
          "traceId": "b4c38383",
          "type": "SPAN",
          "name": "error_b4_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-19T14:01:47.711000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219160147_psg_phi4:latest/tmp_20260219160147_psg_phi4:latest.py\", line 70, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T14:00:49.551Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:01:53.512Z"
    },
    {
      "id": "7c979bda",
      "timestamp": "2026-02-19T13:59:24.414000+00:00",
      "name": "7c97_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Function to preprocess input image\ndef preprocess_image(frame):\n    # Resize and normalize the image\n    input_size = input_details[0]['shape'][1:3]\n    frame_resized = cv2.resize(frame, input_size)\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    input_data = (input_data / 127.5) - 1.0\n    return input_data\n\n# Function to draw bounding boxes and labels on the frame\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        # Extract information from the detection\n        ymin, xmin, ymax, xmax, score, class_id = detection\n        if score < confidence_threshold:\n            continue\n        \n        # Scale box to original image size\n        (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                     ymin * frame.shape[0], ymax * frame.shape[0])\n        \n        # Draw rectangle and label on the frame\n        cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n        label = f\"{labels[int(class_id)]}: {score:.2f}\"\n        cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_image(frame)\n    \n    # Set tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    # Prepare detections for drawing\n    num_detections = len(scores)\n    detections = []\n    for i in range(num_detections):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            class_id = int(classes[i])\n            score = float(scores[i])\n            detections.append((ymin, xmin, ymax, xmax, score, class_id))\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219160020_psg_phi4:latest/tmp_20260219160020_psg_phi4:latest.py\", line 70, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 56.55,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-59-24-416159_chatcmpl-ce87f287-c62a-4f8c-bee9-9f509ec07ef7",
          "traceId": "7c979bda",
          "type": "GENERATION",
          "name": "7c97_psg_gen_attempt#1",
          "startTime": "2026-02-19T13:59:24.416000+00:00",
          "endTime": "2026-02-19T13:59:34.954000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10538.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-59-35-114383_chatcmpl-3bb30214-de81-4d80-ba56-57f7279662ec",
          "traceId": "7c979bda",
          "type": "GENERATION",
          "name": "7c97_psg_gen_attempt#2",
          "startTime": "2026-02-19T13:59:35.114000+00:00",
          "endTime": "2026-02-19T13:59:45.114000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10000.0,
          "completionTokens": 751,
          "environment": "default",
          "totalTokens": 1311,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-59-45-417643_chatcmpl-a9478ce4-9681-4be6-89b5-7fc589cf8cae",
          "traceId": "7c979bda",
          "type": "GENERATION",
          "name": "7c97_psg_gen_attempt#3",
          "startTime": "2026-02-19T13:59:45.417000+00:00",
          "endTime": "2026-02-19T13:59:56.770000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11353.0,
          "completionTokens": 854,
          "environment": "default",
          "totalTokens": 1483,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-59-56-919289_chatcmpl-be6b4d10-a0a3-4ed1-915e-a1b1930e78a4",
          "traceId": "7c979bda",
          "type": "GENERATION",
          "name": "7c97_psg_gen_attempt#4",
          "startTime": "2026-02-19T13:59:56.919000+00:00",
          "endTime": "2026-02-19T14:00:08.775000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11856.0,
          "completionTokens": 892,
          "environment": "default",
          "totalTokens": 1521,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-16-00-08-924868_chatcmpl-d66b0771-f6a3-45a0-94bf-10a47309053e",
          "traceId": "7c979bda",
          "type": "GENERATION",
          "name": "7c97_psg_gen_attempt#5",
          "startTime": "2026-02-19T14:00:08.924000+00:00",
          "endTime": "2026-02-19T14:00:20.811000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11887.0,
          "completionTokens": 894,
          "environment": "default",
          "totalTokens": 1527,
          "promptTokens": 633,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "989dd9ec-9057-46ef-9c27-412637278504",
          "traceId": "7c979bda",
          "type": "SPAN",
          "name": "error_7c_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-19T14:00:20.966000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219160020_psg_phi4:latest/tmp_20260219160020_psg_phi4:latest.py\", line 70, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T13:59:24.977Z",
      "environment": "default",
      "updatedAt": "2026-02-19T14:00:26.894Z"
    },
    {
      "id": "7d1d333a",
      "timestamp": "2026-02-19T13:58:01.013000+00:00",
      "name": "7d1d_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Function to preprocess input image\ndef preprocess_image(frame):\n    # Resize and normalize the image\n    input_size = input_details[0]['shape'][1:3]\n    resized_frame = cv2.resize(frame, input_size)\n    normalized_frame = np.expand_dims(resized_frame / 255.0, axis=0).astype(np.float32)\n    return normalized_frame\n\n# Function to draw bounding boxes and labels\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        # Extract information from the detection\n        ymin, xmin, ymax, xmax = detection['bbox']\n        class_id = int(detection['class_id'])\n        score = float(detection['score'])\n\n        if score >= confidence_threshold:\n            label = labels[class_id]\n            left, right, top, bottom = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                        ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            # Draw rectangle and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            text = f'{label}: {score:.2f}'\n            cv2.putText(frame, text, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the input image\n    input_data = preprocess_image(frame)\n    \n    # Set the tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n    interpreter.invoke()\n\n    # Extract output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    # Prepare detections for drawing\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            detections.append({\n                'bbox': (ymin, xmin, ymax, xmax),\n                'class_id': int(classes[i]),\n                'score': float(scores[i])\n            })\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219155857_psg_phi4:latest/tmp_20260219155857_psg_phi4:latest.py\", line 70, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 57.008,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-58-01-015216_chatcmpl-d409463c-0fa1-4fdb-b5ba-3a89a6efe40a",
          "traceId": "7d1d333a",
          "type": "GENERATION",
          "name": "7d1d_psg_gen_attempt#1",
          "startTime": "2026-02-19T13:58:01.015000+00:00",
          "endTime": "2026-02-19T13:58:11.566000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10551.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-58-11-710651_chatcmpl-74f319fe-0fc0-4398-b0d0-aecd7c69daa6",
          "traceId": "7d1d333a",
          "type": "GENERATION",
          "name": "7d1d_psg_gen_attempt#2",
          "startTime": "2026-02-19T13:58:11.710000+00:00",
          "endTime": "2026-02-19T13:58:21.288000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9578.0,
          "completionTokens": 719,
          "environment": "default",
          "totalTokens": 1279,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-58-21-498305_chatcmpl-b3e97614-0c53-4796-b845-9a5d4de8d34d",
          "traceId": "7d1d333a",
          "type": "GENERATION",
          "name": "7d1d_psg_gen_attempt#3",
          "startTime": "2026-02-19T13:58:21.498000+00:00",
          "endTime": "2026-02-19T13:58:33.571000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12073.0,
          "completionTokens": 908,
          "environment": "default",
          "totalTokens": 1537,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-58-33-733749_chatcmpl-716364cb-3294-436e-950d-9cc54c104fc6",
          "traceId": "7d1d333a",
          "type": "GENERATION",
          "name": "7d1d_psg_gen_attempt#4",
          "startTime": "2026-02-19T13:58:33.733000+00:00",
          "endTime": "2026-02-19T13:58:45.834000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12101.0,
          "completionTokens": 910,
          "environment": "default",
          "totalTokens": 1543,
          "promptTokens": 633,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-58-45-996933_chatcmpl-c82cd8a7-88ce-4137-8898-8982cc59b766",
          "traceId": "7d1d333a",
          "type": "GENERATION",
          "name": "7d1d_psg_gen_attempt#5",
          "startTime": "2026-02-19T13:58:45.996000+00:00",
          "endTime": "2026-02-19T13:58:57.866000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11870.0,
          "completionTokens": 893,
          "environment": "default",
          "totalTokens": 1522,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "723061d4-90b3-479f-8b39-95c72729d7f4",
          "traceId": "7d1d333a",
          "type": "SPAN",
          "name": "error_7d_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-19T13:58:58.023000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219155857_psg_phi4:latest/tmp_20260219155857_psg_phi4:latest.py\", line 70, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T13:58:01.576Z",
      "environment": "default",
      "updatedAt": "2026-02-19T13:59:03.598Z"
    },
    {
      "id": "29fc120b",
      "timestamp": "2026-02-19T13:56:38.563000+00:00",
      "name": "29fc_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\nheight, width, _ = input_shape\n\ndef preprocess_frame(frame):\n    frame_resized = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data.astype(np.float32)\n\ndef postprocess(output_data):\n    boxes = output_data[0][0]  # Bounding box coordinates\n    classes = output_data[1][0].astype(int)  # Class indices\n    scores = output_data[2][0]  # Confidence scores\n\n    valid_detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            valid_detections.append((int(left), int(right), int(top), int(bottom),\n                                     classes[i], scores[i]))\n\n    return valid_detections\n\ndef compute_map(detections):\n    # Placeholder for mAP computation logic\n    # This function should be implemented based on specific requirements\n    return 0.0\n\n# Read input video\ncap = cv2.VideoCapture(input_path)\nfps = cap.get(cv2.CAP_PROP_FPS)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_frame(frame)\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Get output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])\n    classes = interpreter.get_tensor(output_details[1]['index'])\n    scores = interpreter.get_tensor(output_details[2]['index'])\n\n    # Postprocess the results\n    detections = postprocess([boxes, classes, scores])\n\n    # Draw bounding boxes and labels on the frame\n    for (left, right, top, bottom, class_id, score) in detections:\n        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n        label = f\"{labels[class_id]}: {score:.2f}\"\n        cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\n\n# Compute mAP for the entire video (placeholder)\nmAP = compute_map([])  # Replace [] with actual detection data if needed\n\nprint(f\"Mean Average Precision: {mAP}\")",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219155734_psg_phi4:latest/tmp_20260219155734_psg_phi4:latest.py\", line 25, in <module>\n    height, width, _ = input_shape\nValueError: too many values to unpack (expected 3)\n"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 56.334,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-56-38-564528_chatcmpl-c284f38d-cdd1-488b-a820-8eecc1d8f454",
          "traceId": "29fc120b",
          "type": "GENERATION",
          "name": "29fc_psg_gen_attempt#1",
          "startTime": "2026-02-19T13:56:38.564000+00:00",
          "endTime": "2026-02-19T13:56:49.078000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10514.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-56-49-215360_chatcmpl-4d95158d-0daa-4c68-b095-3ac81d4c2d90",
          "traceId": "29fc120b",
          "type": "GENERATION",
          "name": "29fc_psg_gen_attempt#2",
          "startTime": "2026-02-19T13:56:49.215000+00:00",
          "endTime": "2026-02-19T13:56:59.071000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9856.0,
          "completionTokens": 740,
          "environment": "default",
          "totalTokens": 1300,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-56-59-219674_chatcmpl-b333d7b0-6383-4841-8f6c-3c4b4164eb63",
          "traceId": "29fc120b",
          "type": "GENERATION",
          "name": "29fc_psg_gen_attempt#3",
          "startTime": "2026-02-19T13:56:59.219000+00:00",
          "endTime": "2026-02-19T13:57:11.129000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11910.0,
          "completionTokens": 896,
          "environment": "default",
          "totalTokens": 1525,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-57-11-282255_chatcmpl-3ae7d3a9-6036-443a-a856-c01dd474f778",
          "traceId": "29fc120b",
          "type": "GENERATION",
          "name": "29fc_psg_gen_attempt#4",
          "startTime": "2026-02-19T13:57:11.282000+00:00",
          "endTime": "2026-02-19T13:57:22.751000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11469.0,
          "completionTokens": 863,
          "environment": "default",
          "totalTokens": 1492,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-57-23-110596_chatcmpl-12a06aab-135c-475d-8feb-9cd070bb09b0",
          "traceId": "29fc120b",
          "type": "GENERATION",
          "name": "29fc_psg_gen_attempt#5",
          "startTime": "2026-02-19T13:57:23.110000+00:00",
          "endTime": "2026-02-19T13:57:34.763000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11653.0,
          "completionTokens": 879,
          "environment": "default",
          "totalTokens": 1493,
          "promptTokens": 614,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "32a3656b-357c-4062-8b9b-8be962d78705",
          "traceId": "29fc120b",
          "type": "SPAN",
          "name": "error_29_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-19T13:57:34.898000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219155734_psg_phi4:latest/tmp_20260219155734_psg_phi4:latest.py\", line 25, in <module>\n    height, width, _ = input_shape\nValueError: too many values to unpack (expected 3)\n",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T13:56:39.125Z",
      "environment": "default",
      "updatedAt": "2026-02-19T13:57:40.295Z"
    },
    {
      "id": "5d533d6c",
      "timestamp": "2026-02-19T13:55:14.172000+00:00",
      "name": "5d53_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise ValueError(\"Error opening video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Function to preprocess input image\ndef preprocess_image(image):\n    # Resize and normalize the image\n    input_shape = input_details[0]['shape']\n    resized_image = cv2.resize(image, (input_shape[2], input_shape[1]))\n    normalized_image = np.expand_dims(resized_image, axis=0).astype(np.float32)\n    return normalized_image\n\n# Function to draw bounding boxes and labels\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        # Extract information from the detection\n        ymin, xmin, ymax, xmax, score, class_id = detection\n        if score < confidence_threshold:\n            continue\n        \n        # Scale box to frame dimensions\n        (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                     ymin * frame_height, ymax * frame_height)\n        \n        # Draw rectangle and label on the frame\n        cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n        label = f\"{labels[int(class_id)]}: {score:.2f}\"\n        cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_data = preprocess_image(frame)\n    \n    # Set tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    # Combine results into a single list for easier processing\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            class_id = int(classes[i])\n            score = float(scores[i])\n            detections.append((ymin, xmin, ymax, xmax, score, class_id))\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219155611_psg_phi4:latest/tmp_20260219155611_psg_phi4:latest.py\", line 72, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 57.795,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-55-14-173875_chatcmpl-accac49c-18ac-4dfd-a4c0-b046dffc61b4",
          "traceId": "5d533d6c",
          "type": "GENERATION",
          "name": "5d53_psg_gen_attempt#1",
          "startTime": "2026-02-19T13:55:14.173000+00:00",
          "endTime": "2026-02-19T13:55:24.700000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10527.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-55-24-846233_chatcmpl-5568b734-7a53-40ca-947f-2839485f1cb5",
          "traceId": "5d533d6c",
          "type": "GENERATION",
          "name": "5d53_psg_gen_attempt#2",
          "startTime": "2026-02-19T13:55:24.846000+00:00",
          "endTime": "2026-02-19T13:55:35.208000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10362.0,
          "completionTokens": 779,
          "environment": "default",
          "totalTokens": 1339,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-55-35-384837_chatcmpl-1c0a0568-62f5-45ba-9fbe-c408d15948fc",
          "traceId": "5d533d6c",
          "type": "GENERATION",
          "name": "5d53_psg_gen_attempt#3",
          "startTime": "2026-02-19T13:55:35.384000+00:00",
          "endTime": "2026-02-19T13:55:47.302000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11918.0,
          "completionTokens": 897,
          "environment": "default",
          "totalTokens": 1526,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-55-47-767104_chatcmpl-9a66a687-e7dd-4703-a4f5-9b96092b86c7",
          "traceId": "5d533d6c",
          "type": "GENERATION",
          "name": "5d53_psg_gen_attempt#4",
          "startTime": "2026-02-19T13:55:47.767000+00:00",
          "endTime": "2026-02-19T13:55:59.810000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12043.0,
          "completionTokens": 906,
          "environment": "default",
          "totalTokens": 1535,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-55-59-972926_chatcmpl-8a66aa7d-85ff-403b-87ac-425ba752695f",
          "traceId": "5d533d6c",
          "type": "GENERATION",
          "name": "5d53_psg_gen_attempt#5",
          "startTime": "2026-02-19T13:55:59.972000+00:00",
          "endTime": "2026-02-19T13:56:11.817000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11845.0,
          "completionTokens": 891,
          "environment": "default",
          "totalTokens": 1524,
          "promptTokens": 633,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "b4e09220-c74a-455d-8a3c-33cc46f2f375",
          "traceId": "5d533d6c",
          "type": "SPAN",
          "name": "error_5d_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-19T13:56:11.968000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219155611_psg_phi4:latest/tmp_20260219155611_psg_phi4:latest.py\", line 72, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T13:55:14.733Z",
      "environment": "default",
      "updatedAt": "2026-02-19T13:56:17.588Z"
    },
    {
      "id": "de09a98b",
      "timestamp": "2026-02-19T13:53:28.521000+00:00",
      "name": "de09_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise ValueError(\"Error opening video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Function to preprocess input image\ndef preprocess_image(image):\n    # Resize and normalize the image\n    input_shape = input_details[0]['shape']\n    resized_image = cv2.resize(image, (input_shape[2], input_shape[1]))\n    normalized_image = np.expand_dims(resized_image / 255.0, axis=0).astype(np.float32)\n    return normalized_image\n\n# Function to draw bounding boxes and labels\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        # Extract information from the detection\n        ymin, xmin, ymax, xmax = detection['bbox']\n        class_id = int(detection['class_id'])\n        score = float(detection['score'])\n\n        if score >= confidence_threshold:\n            label = f\"{labels[class_id]}: {score:.2f}\"\n            start_point = (int(xmin * frame.shape[1]), int(ymin * frame.shape[0]))\n            end_point = (int(xmax * frame.shape[1]), int(ymax * frame.shape[0]))\n            color = (255, 0, 0)  # Blue color in BGR\n            thickness = 2\n\n            # Draw rectangle and label on the frame\n            cv2.rectangle(frame, start_point, end_point, color, thickness)\n            cv2.putText(frame, label, (start_point[0], start_point[1] - 10), \n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness)\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_image(frame)\n    \n    # Set tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.uint8))\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            detection = {\n                'bbox': (ymin, xmin, ymax, xmax),\n                'class_id': int(classes[i]),\n                'score': float(scores[i])\n            }\n            detections.append(detection)\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 45.353,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-53-28-522923_chatcmpl-dab81a8e-8dce-4652-bac2-b8ce9cb87479",
          "traceId": "de09a98b",
          "type": "GENERATION",
          "name": "de09_psg_gen_attempt#1",
          "startTime": "2026-02-19T13:53:28.522000+00:00",
          "endTime": "2026-02-19T13:53:39.195000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10673.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-53-39-346959_chatcmpl-c838847d-1f11-4f01-9b2d-b2a91644e5b3",
          "traceId": "de09a98b",
          "type": "GENERATION",
          "name": "de09_psg_gen_attempt#2",
          "startTime": "2026-02-19T13:53:39.346000+00:00",
          "endTime": "2026-02-19T13:53:49.402000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10056.0,
          "completionTokens": 755,
          "environment": "default",
          "totalTokens": 1315,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-53-49-572717_chatcmpl-5515fc41-0bce-472f-828b-37fe03ca5edd",
          "traceId": "de09a98b",
          "type": "GENERATION",
          "name": "de09_psg_gen_attempt#3",
          "startTime": "2026-02-19T13:53:49.572000+00:00",
          "endTime": "2026-02-19T13:54:01.480000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11908.0,
          "completionTokens": 896,
          "environment": "default",
          "totalTokens": 1525,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-54-01-641539_chatcmpl-2997078f-005d-43a6-8e77-66bd3ec32567",
          "traceId": "de09a98b",
          "type": "GENERATION",
          "name": "de09_psg_gen_attempt#4",
          "startTime": "2026-02-19T13:54:01.641000+00:00",
          "endTime": "2026-02-19T13:54:13.875000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12234.0,
          "completionTokens": 920,
          "environment": "default",
          "totalTokens": 1549,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T13:53:29.079Z",
      "environment": "default",
      "updatedAt": "2026-02-19T13:54:53.291Z"
    },
    {
      "id": "9b461d91",
      "timestamp": "2026-02-19T13:51:43.113000+00:00",
      "name": "9b46_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise ValueError(\"Error opening video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Function to preprocess input image\ndef preprocess_image(image):\n    # Resize and normalize the image\n    input_shape = input_details[0]['shape']\n    resized_image = cv2.resize(image, (input_shape[2], input_shape[1]))\n    normalized_image = np.expand_dims(resized_image / 255.0, axis=0).astype(np.float32)\n    return normalized_image\n\n# Function to draw bounding boxes and labels\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        # Extract information from the detection\n        ymin, xmin, ymax, xmax = detection['bbox']\n        class_id = int(detection['class_id'])\n        score = float(detection['score'])\n\n        if score >= confidence_threshold:\n            label = f\"{labels[class_id]}: {score:.2f}\"\n            start_point = (int(xmin * frame.shape[1]), int(ymin * frame.shape[0]))\n            end_point = (int(xmax * frame.shape[1]), int(ymax * frame.shape[0]))\n            color = (255, 0, 0)  # Blue color in BGR\n            thickness = 2\n\n            # Draw rectangle and label on the frame\n            cv2.rectangle(frame, start_point, end_point, color, thickness)\n            cv2.putText(frame, label, (start_point[0], start_point[1] - 10), \n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness)\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_image(frame)\n    \n    # Set tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.uint8))\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence score\n\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            detection = {\n                'bbox': (ymin, xmin, ymax, xmax),\n                'class_id': int(classes[i]),\n                'score': float(scores[i])\n            }\n            detections.append(detection)\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 46.144,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-51-43-115487_chatcmpl-266f146e-51f9-4b60-beed-eb3fc21b6e73",
          "traceId": "9b461d91",
          "type": "GENERATION",
          "name": "9b46_psg_gen_attempt#1",
          "startTime": "2026-02-19T13:51:43.115000+00:00",
          "endTime": "2026-02-19T13:51:53.680000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10565.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-51-53-836289_chatcmpl-6ffb1565-95ea-40af-9463-ff791a1ab077",
          "traceId": "9b461d91",
          "type": "GENERATION",
          "name": "9b46_psg_gen_attempt#2",
          "startTime": "2026-02-19T13:51:53.836000+00:00",
          "endTime": "2026-02-19T13:52:05.387000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11551.0,
          "completionTokens": 868,
          "environment": "default",
          "totalTokens": 1428,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-52-05-555792_chatcmpl-ae654ee0-d2b3-47c0-8e8c-340a7078a195",
          "traceId": "9b461d91",
          "type": "GENERATION",
          "name": "9b46_psg_gen_attempt#3",
          "startTime": "2026-02-19T13:52:05.555000+00:00",
          "endTime": "2026-02-19T13:52:16.902000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11347.0,
          "completionTokens": 854,
          "environment": "default",
          "totalTokens": 1483,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-52-17-163004_chatcmpl-9cea53fb-76de-4789-9480-5e5ba28ff2b9",
          "traceId": "9b461d91",
          "type": "GENERATION",
          "name": "9b46_psg_gen_attempt#4",
          "startTime": "2026-02-19T13:52:17.163000+00:00",
          "endTime": "2026-02-19T13:52:29.259000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12096.0,
          "completionTokens": 910,
          "environment": "default",
          "totalTokens": 1539,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T13:51:43.672Z",
      "environment": "default",
      "updatedAt": "2026-02-19T13:53:08.307Z"
    },
    {
      "id": "7fcb2c14",
      "timestamp": "2026-02-19T13:49:45.234000+00:00",
      "name": "7fcb_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise ValueError(\"Error opening video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Function to preprocess input image\ndef preprocess_image(image):\n    # Resize and normalize the image\n    input_shape = input_details[0]['shape']\n    resized_image = cv2.resize(image, (input_shape[2], input_shape[1]))\n    normalized_image = np.expand_dims(resized_image / 255.0, axis=0).astype(np.float32)\n    return normalized_image\n\n# Function to draw bounding boxes and labels\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        # Extract information from the detection\n        ymin, xmin, ymax, xmax = detection['bbox']\n        class_id = int(detection['class_id'])\n        score = float(detection['score'])\n\n        if score >= confidence_threshold:\n            label = labels[class_id]\n            left, right, top, bottom = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                        ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            # Draw rectangle and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            text = f'{label}: {score:.2f}'\n            cv2.putText(frame, text, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_data = preprocess_image(frame)\n    \n    # Set tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.uint8))\n    interpreter.invoke()\n\n    # Extract output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    # Prepare detections list\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            detection = {\n                'bbox': (ymin, xmin, ymax, xmax),\n                'class_id': int(classes[i]),\n                'score': float(scores[i])\n            }\n            detections.append(detection)\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the frame with detections to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 57.563,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-49-45-236265_chatcmpl-368196b1-eddf-4757-b06a-b0a1656ad870",
          "traceId": "7fcb2c14",
          "type": "GENERATION",
          "name": "7fcb_psg_gen_attempt#1",
          "startTime": "2026-02-19T13:49:45.236000+00:00",
          "endTime": "2026-02-19T13:49:55.754000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10518.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-49-55-906194_chatcmpl-593463ba-96c4-4684-8cfc-20b3efdf130e",
          "traceId": "7fcb2c14",
          "type": "GENERATION",
          "name": "7fcb_psg_gen_attempt#2",
          "startTime": "2026-02-19T13:49:55.906000+00:00",
          "endTime": "2026-02-19T13:50:06.079000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10173.0,
          "completionTokens": 764,
          "environment": "default",
          "totalTokens": 1324,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-50-06-234520_chatcmpl-c68918fb-06c0-4ac8-bc12-1a8dc3a6f297",
          "traceId": "7fcb2c14",
          "type": "GENERATION",
          "name": "7fcb_psg_gen_attempt#3",
          "startTime": "2026-02-19T13:50:06.234000+00:00",
          "endTime": "2026-02-19T13:50:18.263000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12029.0,
          "completionTokens": 905,
          "environment": "default",
          "totalTokens": 1534,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-50-18-417932_chatcmpl-5ac41886-8a4b-4bab-a010-521fc7e8b895",
          "traceId": "7fcb2c14",
          "type": "GENERATION",
          "name": "7fcb_psg_gen_attempt#4",
          "startTime": "2026-02-19T13:50:18.417000+00:00",
          "endTime": "2026-02-19T13:50:30.317000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11900.0,
          "completionTokens": 895,
          "environment": "default",
          "totalTokens": 1528,
          "promptTokens": 633,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-50-30-473506_chatcmpl-3e55a23e-0dea-46ad-9d53-d66d48f3a71c",
          "traceId": "7fcb2c14",
          "type": "GENERATION",
          "name": "7fcb_psg_gen_attempt#5",
          "startTime": "2026-02-19T13:50:30.473000+00:00",
          "endTime": "2026-02-19T13:50:42.799000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12326.0,
          "completionTokens": 927,
          "environment": "default",
          "totalTokens": 1556,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T13:49:45.791Z",
      "environment": "default",
      "updatedAt": "2026-02-19T13:51:22.024Z"
    },
    {
      "id": "6592e8ec",
      "timestamp": "2026-02-19T13:48:12.690000+00:00",
      "name": "6592_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise ValueError(\"Error opening video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Function to preprocess input image\ndef preprocess_image(image):\n    # Resize and normalize the image\n    input_shape = input_details[0]['shape']\n    resized_image = cv2.resize(image, (input_shape[2], input_shape[1]))\n    normalized_image = np.expand_dims(resized_image / 255.0, axis=0).astype(np.float32)\n    return normalized_image\n\n# Function to draw bounding boxes and labels\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        # Extract information from the detection\n        ymin, xmin, ymax, xmax = detection['bbox']\n        class_id = int(detection['class_id'])\n        score = float(detection['score'])\n\n        if score >= confidence_threshold:\n            label = labels[class_id]\n            start_point = (int(xmin * frame.shape[1]), int(ymin * frame.shape[0]))\n            end_point = (int(xmax * frame.shape[1]), int(ymax * frame.shape[0]))\n\n            # Draw rectangle and label\n            cv2.rectangle(frame, start_point, end_point, (255, 0, 0), 2)\n            text = f\"{label}: {score:.2f}\"\n            cv2.putText(frame, text, (start_point[0], start_point[1] - 10), \n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_data = preprocess_image(frame)\n    \n    # Set tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.uint8))\n    interpreter.invoke()\n\n    # Extract output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence score\n\n    # Prepare detections list\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            detection = {\n                'bbox': (ymin, xmin, ymax, xmax),\n                'class_id': int(classes[i]),\n                'score': float(scores[i])\n            }\n            detections.append(detection)\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 32.63,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-48-12-691326_chatcmpl-46c076ed-e908-414c-8c6f-2b08ddef1883",
          "traceId": "6592e8ec",
          "type": "GENERATION",
          "name": "6592_psg_gen_attempt#1",
          "startTime": "2026-02-19T13:48:12.691000+00:00",
          "endTime": "2026-02-19T13:48:23.385000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10694.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-48-23-530681_chatcmpl-584baeee-258e-44e8-b07b-1ddc74d5ea5b",
          "traceId": "6592e8ec",
          "type": "GENERATION",
          "name": "6592_psg_gen_attempt#2",
          "startTime": "2026-02-19T13:48:23.530000+00:00",
          "endTime": "2026-02-19T13:48:33.107000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9577.0,
          "completionTokens": 719,
          "environment": "default",
          "totalTokens": 1279,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-48-33-259488_chatcmpl-75b11f23-2949-4fe2-8517-6782272d4e3a",
          "traceId": "6592e8ec",
          "type": "GENERATION",
          "name": "6592_psg_gen_attempt#3",
          "startTime": "2026-02-19T13:48:33.259000+00:00",
          "endTime": "2026-02-19T13:48:45.321000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12062.0,
          "completionTokens": 907,
          "environment": "default",
          "totalTokens": 1536,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2026-02-19T13:48:13.246Z",
      "environment": "default",
      "updatedAt": "2026-02-19T13:49:24.402Z"
    },
    {
      "id": "2a68f524",
      "timestamp": "2026-02-19T13:46:50.264000+00:00",
      "name": "2a68_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise ValueError(\"Error opening video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Function to preprocess input image\ndef preprocess_image(image):\n    # Resize and normalize the image\n    input_shape = input_details[0]['shape']\n    resized_image = cv2.resize(image, (input_shape[2], input_shape[1]))\n    normalized_image = resized_image / 255.0\n    return np.expand_dims(normalized_image, axis=0).astype(np.float32)\n\n# Function to draw bounding boxes and labels on the image\ndef draw_boxes(image, detections):\n    for detection in detections:\n        # Extract information from the detection\n        ymin, xmin, ymax, xmax = detection['bbox']\n        class_id = int(detection['class_id'])\n        score = float(detection['score'])\n\n        if score >= confidence_threshold:\n            label = labels[class_id]\n            cv2.rectangle(image, (int(xmin * frame_width), int(ymin * frame_height)),\n                          (int(xmax * frame_width), int(ymax * frame_height)), (0, 255, 0), 2)\n            text = f\"{label}: {score:.2f}\"\n            cv2.putText(image, text, (int(xmin * frame_width), int((ymin - 10) * frame_height)),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_data = preprocess_image(frame)\n    \n    # Set the tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            detection = {\n                'bbox': (ymin, xmin, ymax, xmax),\n                'class_id': int(classes[i]),\n                'score': float(scores[i])\n            }\n            detections.append(detection)\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219154746_psg_phi4:latest/tmp_20260219154746_psg_phi4:latest.py\", line 71, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 56.489,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-46-50-266134_chatcmpl-54b9c86b-514e-4de7-989d-2b76dd5c435d",
          "traceId": "2a68f524",
          "type": "GENERATION",
          "name": "2a68_psg_gen_attempt#1",
          "startTime": "2026-02-19T13:46:50.266000+00:00",
          "endTime": "2026-02-19T13:47:00.831000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10565.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-47-00-978305_chatcmpl-20bd8458-248e-45f5-af18-e49f39ff761c",
          "traceId": "2a68f524",
          "type": "GENERATION",
          "name": "2a68_psg_gen_attempt#2",
          "startTime": "2026-02-19T13:47:00.978000+00:00",
          "endTime": "2026-02-19T13:47:10.188000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9210.0,
          "completionTokens": 691,
          "environment": "default",
          "totalTokens": 1251,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-47-10-344656_chatcmpl-96fff676-bad2-42d8-a9a3-8112ae361885",
          "traceId": "2a68f524",
          "type": "GENERATION",
          "name": "2a68_psg_gen_attempt#3",
          "startTime": "2026-02-19T13:47:10.344000+00:00",
          "endTime": "2026-02-19T13:47:22.255000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11911.0,
          "completionTokens": 896,
          "environment": "default",
          "totalTokens": 1525,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-47-22-412769_chatcmpl-3f02c600-9877-4b93-9d94-937128bdc35c",
          "traceId": "2a68f524",
          "type": "GENERATION",
          "name": "2a68_psg_gen_attempt#4",
          "startTime": "2026-02-19T13:47:22.412000+00:00",
          "endTime": "2026-02-19T13:47:34.471000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12059.0,
          "completionTokens": 907,
          "environment": "default",
          "totalTokens": 1536,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-47-34-630727_chatcmpl-034f03e7-84f0-48b9-8f34-6e9ba1246ed9",
          "traceId": "2a68f524",
          "type": "GENERATION",
          "name": "2a68_psg_gen_attempt#5",
          "startTime": "2026-02-19T13:47:34.630000+00:00",
          "endTime": "2026-02-19T13:47:46.469000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11839.0,
          "completionTokens": 890,
          "environment": "default",
          "totalTokens": 1523,
          "promptTokens": 633,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "b8557203-92cd-4086-a54f-c28f78499190",
          "traceId": "2a68f524",
          "type": "SPAN",
          "name": "error_2a_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-19T13:47:46.755000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219154746_psg_phi4:latest/tmp_20260219154746_psg_phi4:latest.py\", line 71, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T13:46:50.821Z",
      "environment": "default",
      "updatedAt": "2026-02-19T13:47:51.964Z"
    },
    {
      "id": "877835a3",
      "timestamp": "2026-02-19T13:45:26.839000+00:00",
      "name": "8778_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Function to preprocess input image\ndef preprocess_image(frame):\n    # Resize and normalize the image\n    input_size = input_details[0]['shape'][1:3]\n    resized_frame = cv2.resize(frame, input_size)\n    normalized_frame = np.expand_dims(resized_frame / 255.0, axis=0).astype(np.float32)\n    return normalized_frame\n\n# Function to draw bounding boxes and labels\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        # Extract information from the detection\n        ymin, xmin, ymax, xmax = detection['bbox']\n        class_id = int(detection['class_id'])\n        score = float(detection['score'])\n\n        if score >= confidence_threshold:\n            label = labels[class_id]\n            left, right, top, bottom = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                        ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            # Draw rectangle and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            text = f'{label}: {score:.2f}'\n            cv2.putText(frame, text, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the input image\n    input_data = preprocess_image(frame)\n    \n    # Set the tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n    interpreter.invoke()\n\n    # Extract output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    # Prepare detections for drawing\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            detections.append({\n                'bbox': (ymin, xmin, ymax, xmax),\n                'class_id': int(classes[i]),\n                'score': float(scores[i])\n            })\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219154623_psg_phi4:latest/tmp_20260219154623_psg_phi4:latest.py\", line 70, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 56.821,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-45-26-840331_chatcmpl-9eec7521-6d2d-4b80-b285-96f4cc7c455d",
          "traceId": "877835a3",
          "type": "GENERATION",
          "name": "8778_psg_gen_attempt#1",
          "startTime": "2026-02-19T13:45:26.840000+00:00",
          "endTime": "2026-02-19T13:45:37.358000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10518.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-45-37-497634_chatcmpl-518215b1-6624-4585-9179-9e45e6932bed",
          "traceId": "877835a3",
          "type": "GENERATION",
          "name": "8778_psg_gen_attempt#2",
          "startTime": "2026-02-19T13:45:37.497000+00:00",
          "endTime": "2026-02-19T13:45:47.399000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9902.0,
          "completionTokens": 743,
          "environment": "default",
          "totalTokens": 1303,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-45-47-810111_chatcmpl-5ce31433-7ca6-43ce-96a5-7ee15c7e491f",
          "traceId": "877835a3",
          "type": "GENERATION",
          "name": "8778_psg_gen_attempt#3",
          "startTime": "2026-02-19T13:45:47.810000+00:00",
          "endTime": "2026-02-19T13:45:59.970000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12160.0,
          "completionTokens": 915,
          "environment": "default",
          "totalTokens": 1544,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-46-00-127952_chatcmpl-a5352294-1485-4901-97fc-5162d9e5d002",
          "traceId": "877835a3",
          "type": "GENERATION",
          "name": "8778_psg_gen_attempt#4",
          "startTime": "2026-02-19T13:46:00.127000+00:00",
          "endTime": "2026-02-19T13:46:11.477000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11350.0,
          "completionTokens": 854,
          "environment": "default",
          "totalTokens": 1483,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-46-11-639328_chatcmpl-c6bbd1ae-00df-48d1-a41a-fef38eccffbe",
          "traceId": "877835a3",
          "type": "GENERATION",
          "name": "8778_psg_gen_attempt#5",
          "startTime": "2026-02-19T13:46:11.639000+00:00",
          "endTime": "2026-02-19T13:46:23.509000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11870.0,
          "completionTokens": 893,
          "environment": "default",
          "totalTokens": 1522,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "c9e3a247-6149-4581-b69b-035f799c3fbe",
          "traceId": "877835a3",
          "type": "SPAN",
          "name": "error_87_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-19T13:46:23.661000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219154623_psg_phi4:latest/tmp_20260219154623_psg_phi4:latest.py\", line 70, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T13:45:27.393Z",
      "environment": "default",
      "updatedAt": "2026-02-19T13:46:29.358Z"
    },
    {
      "id": "eb94cbe6",
      "timestamp": "2026-02-19T13:44:04.446000+00:00",
      "name": "eb94_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef preprocess_frame(frame):\n    # Resize and normalize the image\n    input_size = input_details[0]['shape'][1:3]\n    frame_resized = cv2.resize(frame, input_size)\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    input_data = (input_data / 127.5) - 1.0\n    return input_data\n\ndef postprocess(output_data):\n    # Extract boxes, classes, and scores from the output data\n    num_detections = int(output_data[0][0])\n    detection_boxes = output_data[0][1:num_detections * 4 + 1].reshape(num_detections, 4)\n    detection_classes = output_data[0][num_detections * 4 + 1:num_detections * 5 + 1]\n    detection_scores = output_data[0][num_detections * 5 + 1:]\n\n    # Filter out detections below the confidence threshold\n    for i in range(num_detections):\n        if detection_scores[i] >= confidence_threshold:\n            yield (detection_boxes[i], int(detection_classes[i]), detection_scores[i])\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_frame(frame)\n\n    # Set the tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Get output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Postprocess the results and draw on frame\n    for box, class_id, score in postprocess([boxes, classes, scores]):\n        ymin, xmin, ymax, xmax = box\n        (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                      ymin * frame_height, ymax * frame_height)\n        \n        # Draw rectangle and label on the frame\n        cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n        label = f\"{labels[int(class_id)]}: {score:.2f}\"\n        cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219154459_psg_phi4:latest/tmp_20260219154459_psg_phi4:latest.py\", line 63, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 55.481,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-44-04-447973_chatcmpl-a9896616-746d-45b2-b4c6-e269645c3351",
          "traceId": "eb94cbe6",
          "type": "GENERATION",
          "name": "eb94_psg_gen_attempt#1",
          "startTime": "2026-02-19T13:44:04.447000+00:00",
          "endTime": "2026-02-19T13:44:14.969000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10522.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-44-15-110258_chatcmpl-dcafbd10-c076-4225-be7c-f533bcf6117a",
          "traceId": "eb94cbe6",
          "type": "GENERATION",
          "name": "eb94_psg_gen_attempt#2",
          "startTime": "2026-02-19T13:44:15.110000+00:00",
          "endTime": "2026-02-19T13:44:24.503000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9393.0,
          "completionTokens": 705,
          "environment": "default",
          "totalTokens": 1265,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-44-24-669522_chatcmpl-f5513ada-3a26-4664-9e34-842ea7794398",
          "traceId": "eb94cbe6",
          "type": "GENERATION",
          "name": "eb94_psg_gen_attempt#3",
          "startTime": "2026-02-19T13:44:24.669000+00:00",
          "endTime": "2026-02-19T13:44:36.017000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11348.0,
          "completionTokens": 854,
          "environment": "default",
          "totalTokens": 1483,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-44-36-171835_chatcmpl-211502db-a236-47dd-b94e-eec83e318b29",
          "traceId": "eb94cbe6",
          "type": "GENERATION",
          "name": "eb94_psg_gen_attempt#4",
          "startTime": "2026-02-19T13:44:36.171000+00:00",
          "endTime": "2026-02-19T13:44:47.782000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11611.0,
          "completionTokens": 873,
          "environment": "default",
          "totalTokens": 1502,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-44-48-015542_chatcmpl-352f3261-6e8a-4837-bb4f-87dcf1c28485",
          "traceId": "eb94cbe6",
          "type": "GENERATION",
          "name": "eb94_psg_gen_attempt#5",
          "startTime": "2026-02-19T13:44:48.015000+00:00",
          "endTime": "2026-02-19T13:44:59.770000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11755.0,
          "completionTokens": 884,
          "environment": "default",
          "totalTokens": 1513,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "9c8a88f0-57cf-4373-9220-1e3d6085119c",
          "traceId": "eb94cbe6",
          "type": "SPAN",
          "name": "error_eb_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-19T13:44:59.928000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219154459_psg_phi4:latest/tmp_20260219154459_psg_phi4:latest.py\", line 63, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T13:44:05.000Z",
      "environment": "default",
      "updatedAt": "2026-02-19T13:45:05.854Z"
    },
    {
      "id": "f37d508f",
      "timestamp": "2026-02-19T13:42:31.941000+00:00",
      "name": "f37d_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef preprocess_frame(frame):\n    # Resize and normalize the image\n    input_size = input_details[0]['shape'][1:3]\n    frame_resized = cv2.resize(frame, input_size)\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    input_data = (input_data / 127.5) - 1.0\n    return input_data\n\ndef postprocess(output_data):\n    # Extract boxes, classes, and scores from the output data\n    num_detections = int(output_data[0][0])\n    detection_boxes = output_data[0][1:num_detections * 4 + 1].reshape(num_detections, 4)\n    detection_classes = output_data[0][num_detections * 4 + 1:num_detections * 5 + 1]\n    detection_scores = output_data[0][num_detections * 5 + 1:]\n\n    detections = []\n    for i in range(num_detections):\n        if detection_scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = detection_boxes[i]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n            detections.append((int(left), int(right), int(top), int(bottom),\n                               labels[int(detection_classes[i])], float(detection_scores[i])))\n    return detections\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_frame(frame)\n\n    # Set the tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Get output data\n    output_data = [interpreter.get_tensor(output['index']) for output in output_details]\n\n    # Postprocess the results\n    detections = postprocess(output_data)\n\n    # Draw detection boxes and labels on the frame\n    for (left, right, top, bottom, label, score) in detections:\n        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n        text = f\"{label}: {score:.2f}\"\n        cv2.putText(frame, text, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219154338_psg_phi4:latest/tmp_20260219154338_psg_phi4:latest.py\", line 68, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_29a1_psg_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 66.477,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-42-31-943314_chatcmpl-1bbd7fe5-2139-4176-a077-aab65f98cd51",
          "traceId": "f37d508f",
          "type": "GENERATION",
          "name": "f37d_psg_gen_attempt#1",
          "startTime": "2026-02-19T13:42:31.943000+00:00",
          "endTime": "2026-02-19T13:42:53.443000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21500.0,
          "completionTokens": 793,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 417,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-42-53-691550_chatcmpl-3e9528d9-e7e2-473b-8617-1294d8082ddd",
          "traceId": "f37d508f",
          "type": "GENERATION",
          "name": "f37d_psg_gen_attempt#2",
          "startTime": "2026-02-19T13:42:53.691000+00:00",
          "endTime": "2026-02-19T13:43:02.649000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 8958.0,
          "completionTokens": 672,
          "environment": "default",
          "totalTokens": 1232,
          "promptTokens": 560,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-43-02-810252_chatcmpl-9e0296c3-c7cd-436c-a01a-b040082504ab",
          "traceId": "f37d508f",
          "type": "GENERATION",
          "name": "f37d_psg_gen_attempt#3",
          "startTime": "2026-02-19T13:43:02.810000+00:00",
          "endTime": "2026-02-19T13:43:14.776000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11966.0,
          "completionTokens": 900,
          "environment": "default",
          "totalTokens": 1529,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-43-14-933524_chatcmpl-528e7b67-47d8-4280-b0d4-72abd281b1b1",
          "traceId": "f37d508f",
          "type": "GENERATION",
          "name": "f37d_psg_gen_attempt#4",
          "startTime": "2026-02-19T13:43:14.933000+00:00",
          "endTime": "2026-02-19T13:43:26.756000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11823.0,
          "completionTokens": 889,
          "environment": "default",
          "totalTokens": 1522,
          "promptTokens": 633,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-43-26-919908_chatcmpl-e5b4d1e5-3e70-4e41-9d62-f5f33264c67b",
          "traceId": "f37d508f",
          "type": "GENERATION",
          "name": "f37d_psg_gen_attempt#5",
          "startTime": "2026-02-19T13:43:26.919000+00:00",
          "endTime": "2026-02-19T13:43:38.269000+00:00",
          "model": "phi4:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11350.0,
          "completionTokens": 854,
          "environment": "default",
          "totalTokens": 1483,
          "promptTokens": 629,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "f7c9b23c-f07d-4a5f-a68f-e715de5abff1",
          "traceId": "f37d508f",
          "type": "SPAN",
          "name": "error_f3_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-19T13:43:38.420000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260219154338_psg_phi4:latest/tmp_20260219154338_psg_phi4:latest.py\", line 68, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2026-02-19T13:42:32.496Z",
      "environment": "default",
      "updatedAt": "2026-02-19T13:43:43.577Z"
    }
  ],
  "meta": {
    "total_items": 30
  }
}