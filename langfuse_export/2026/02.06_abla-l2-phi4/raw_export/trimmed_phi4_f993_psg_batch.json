{
  "data": [
    {
      "id": "ecb04fee",
      "timestamp": "2026-02-09T16:00:34.986000+00:00",
      "name": "ecb0_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\n\n# Configuration Parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels from label map\ndef load_labels(path):\n    with open(path, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\n# Setup TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n_, height, width, _ = input_details[0]['shape']\n\n# Load labels\nlabels = load_labels(label_path)\n\n# Open video capture\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n# Function to draw bounding boxes on the image\ndef draw_boxes(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          (0, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n# Process video\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing: Resize and normalize the input frame\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    # Set model input\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Run inference\n    interpreter.invoke()\n\n    # Extract output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence score\n\n    # Draw bounding boxes on the frame\n    draw_boxes(frame, boxes, classes, scores)\n\n    # Write the frame with detections to the output video file\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\n\nprint(\"Object detection completed and saved at:\", output_path)"
      },
      "session_id": "phi4_f993_psg_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 10.011,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-18-00-34-987107_chatcmpl-033794ef-9017-4ca0-ad47-b55ce81da1db",
          "traceId": "ecb04fee",
          "type": "GENERATION",
          "name": "ecb0_psg_gen_attempt#1",
          "startTime": "2026-02-09T16:00:34.987000+00:00",
          "endTime": "2026-02-09T16:00:44.998000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10011.0,
          "completionTokens": 743,
          "totalTokens": 1160,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-09T16:00:56.665Z",
      "createdAt": "2026-02-09T16:00:35.544Z",
      "environment": "default"
    },
    {
      "id": "c6871f05",
      "timestamp": "2026-02-09T15:59:37.475000+00:00",
      "name": "c687_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\n\n# CONFIGURATION PARAMETERS\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\nlabels = load_labels(label_path)\n\n# Setup TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Input shape and data type\ninput_shape = input_details[0]['shape']\ninput_data_type = input_details[0]['dtype']\n\n# Read video\ncap = cv2.VideoCapture(input_path)\n\nif not cap.isOpened():\n    raise IOError(\"Error opening video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing: resize and normalize input image\n    input_image = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_image = np.expand_dims(input_image, axis=0)\n    \n    # Convert to UINT8\n    input_image = np.uint8(input_image)\n\n    # Set tensor\n    interpreter.set_tensor(input_details[0]['index'], input_image)\n\n    # Inference\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    height, width, _ = frame.shape\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\n    # Output handling\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "phi4_f993_psg_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 24.512,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-59-37-476800_chatcmpl-62fa7f61-ae7c-4532-b666-66f8da13f523",
          "traceId": "c6871f05",
          "type": "GENERATION",
          "name": "c687_psg_gen_attempt#1",
          "startTime": "2026-02-09T15:59:37.476000+00:00",
          "endTime": "2026-02-09T15:59:51.696000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14220.0,
          "completionTokens": 1058,
          "totalTokens": 1475,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-59-51-861578_chatcmpl-92beaf79-9479-4cf5-9214-c89baee0d0ce",
          "traceId": "c6871f05",
          "type": "GENERATION",
          "name": "c687_psg_gen_attempt#2",
          "startTime": "2026-02-09T15:59:51.861000+00:00",
          "endTime": "2026-02-09T16:00:01.988000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10127.0,
          "completionTokens": 748,
          "totalTokens": 1375,
          "promptTokens": 627,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-09T16:00:14.700Z",
      "createdAt": "2026-02-09T15:59:38.032Z",
      "environment": "default"
    },
    {
      "id": "915e730c",
      "timestamp": "2026-02-09T15:58:14.957000+00:00",
      "name": "915e_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\nheight, width, channel = input_shape[1], input_shape[2], input_shape[3]\n\n# Input video capture and output setup\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    \n    if not ret:\n        break\n\n    # Preprocessing\n    image = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(image, axis=0).astype(np.uint8)\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Get detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n            \n            # Draw bounding box\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n\n            # Draw label\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\n# Note: Computation of mAP is not included in this script as it typically requires a dataset with ground truth annotations."
      },
      "session_id": "phi4_f993_psg_batch",
      "metadata": {
        "num_run": 10
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 49.863,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-58-14-959269_chatcmpl-cca08726-5ad1-4113-87d0-dc9ba05cfd62",
          "traceId": "915e730c",
          "type": "GENERATION",
          "name": "915e_psg_gen_attempt#1",
          "startTime": "2026-02-09T15:58:14.959000+00:00",
          "endTime": "2026-02-09T15:58:25.273000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10314.0,
          "completionTokens": 783,
          "totalTokens": 1200,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-58-25-437514_chatcmpl-00a35e3c-137c-4fef-8f87-45e7dd5073d9",
          "traceId": "915e730c",
          "type": "GENERATION",
          "name": "915e_psg_gen_attempt#2",
          "startTime": "2026-02-09T15:58:25.437000+00:00",
          "endTime": "2026-02-09T15:58:37.684000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12247.0,
          "completionTokens": 903,
          "totalTokens": 1599,
          "promptTokens": 696,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-58-40-955343_chatcmpl-7e96ff00-04a2-4919-a967-0c55d86811c6",
          "traceId": "915e730c",
          "type": "GENERATION",
          "name": "915e_psg_gen_attempt#3",
          "startTime": "2026-02-09T15:58:40.955000+00:00",
          "endTime": "2026-02-09T15:58:53.329000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12374.0,
          "completionTokens": 926,
          "totalTokens": 1484,
          "promptTokens": 558,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-58-53-486181_chatcmpl-118f9230-5efd-4a35-ab2f-3e7ce568465d",
          "traceId": "915e730c",
          "type": "GENERATION",
          "name": "915e_psg_gen_attempt#4",
          "startTime": "2026-02-09T15:58:53.486000+00:00",
          "endTime": "2026-02-09T15:59:04.822000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11336.0,
          "completionTokens": 833,
          "totalTokens": 1460,
          "promptTokens": 627,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-09T15:59:16.680Z",
      "createdAt": "2026-02-09T15:58:15.514Z",
      "environment": "default"
    },
    {
      "id": "866a2123",
      "timestamp": "2026-02-09T15:57:05.514000+00:00",
      "name": "866a_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport time\nimport numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\ninput_shape = input_details[0]['shape']\n\n# Video processing\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef preprocess_frame(frame):\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\ndef postprocess_output(interpreter, frame):\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = f'{labels[int(classes[i])]}: {int(scores[i]*100)}%'\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, label, (int(left), int(top)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    return frame\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    # Preprocessing\n    input_data = preprocess_frame(frame)\n    \n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    start_time = time.time()\n    interpreter.invoke()\n    inference_time = time.time() - start_time\n    \n    # Post-processing and drawing results on frame\n    output_frame = postprocess_output(interpreter, frame)\n    \n    # Write the frame with detection boxes to output video\n    out.write(output_frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Video processing completed. Output saved at:\", output_path)"
      },
      "session_id": "phi4_f993_psg_batch",
      "metadata": {
        "num_run": 9
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 10.239,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-57-05-517251_chatcmpl-575755ab-10bd-4755-a521-0a903bcc91bb",
          "traceId": "866a2123",
          "type": "GENERATION",
          "name": "866a_psg_gen_attempt#1",
          "startTime": "2026-02-09T15:57:05.517000+00:00",
          "endTime": "2026-02-09T15:57:15.756000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10239.0,
          "completionTokens": 764,
          "totalTokens": 1181,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-09T15:57:54.360Z",
      "createdAt": "2026-02-09T15:57:06.070Z",
      "environment": "default"
    },
    {
      "id": "0fadc19b",
      "timestamp": "2026-02-09T15:56:09.357000+00:00",
      "name": "0fad_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\n\n# CONFIGURATION PARAMETERS\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Setup TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\nheight, width, channels = input_shape[1], input_shape[2], input_shape[3]\n\n# Open video files\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\ndef preprocess_input(image):\n    # Resize and normalize image\n    image_resized = cv2.resize(image, (width, height))\n    input_data = np.expand_dims(image_resized, axis=0)\n    input_data = input_data / 255.0  # Normalize to [0,1]\n    return input_data.astype(np.uint8)  # Convert to UINT8\n\ndef postprocess_output(output_data):\n    boxes = output_data[0][0]  # Bounding box coordinates\n    classes = output_data[1][0]  # Class indices\n    scores = output_data[2][0]  # Confidence scores\n    \n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            class_id = int(classes[i])\n            box_coordinates = (\n                int(xmin * cap.get(3)),\n                int(ymin * cap.get(4)),\n                int((xmax - xmin) * cap.get(3)),\n                int((ymax - ymin) * cap.get(4))\n            )\n            detections.append((class_id, scores[i], box_coordinates))\n    return detections\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    # Preprocess the input\n    input_data = preprocess_input(frame)\n    \n    # Set tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    \n    # Get output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])\n    classes = interpreter.get_tensor(output_details[1]['index'])\n    scores = interpreter.get_tensor(output_details[2]['index'])\n    \n    detections = postprocess_output((boxes, classes, scores))\n    \n    # Draw bounding boxes and labels on the frame\n    for class_id, score, (x, y, w, h) in detections:\n        label = f\"{labels[class_id]}: {score:.2f}\"\n        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n    \n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()"
      },
      "session_id": "phi4_f993_psg_batch",
      "metadata": {
        "num_run": 8
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 23.337,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-56-09-359250_chatcmpl-af04182e-eb87-434b-8120-99a0a94542aa",
          "traceId": "0fadc19b",
          "type": "GENERATION",
          "name": "0fad_psg_gen_attempt#1",
          "startTime": "2026-02-09T15:56:09.359000+00:00",
          "endTime": "2026-02-09T15:56:19.547000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10188.0,
          "completionTokens": 771,
          "totalTokens": 1188,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-56-19-752340_chatcmpl-83812109-f715-436f-a45f-fc70b101d404",
          "traceId": "0fadc19b",
          "type": "GENERATION",
          "name": "0fad_psg_gen_attempt#2",
          "startTime": "2026-02-09T15:56:19.752000+00:00",
          "endTime": "2026-02-09T15:56:32.696000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12944.0,
          "completionTokens": 959,
          "totalTokens": 1586,
          "promptTokens": 627,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-09T15:56:44.083Z",
      "createdAt": "2026-02-09T15:56:09.913Z",
      "environment": "default"
    },
    {
      "id": "6e71952b",
      "timestamp": "2026-02-09T15:54:58.903000+00:00",
      "name": "6e71_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport time\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# CONFIGURATION PARAMETERS\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\ndef load_labels(path):\n    with open(path, 'r') as f:\n        return {i: line.strip() for i, line in enumerate(f.readlines())}\n\ndef preprocess_frame(frame, input_size):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_size, input_size))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\ndef draw_detections(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          color=(0, 255, 0), thickness=2)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\ndef main():\n    # Load TFLite model and allocate tensors\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    input_size = input_details[0]['shape'][2]\n    video_capture = cv2.VideoCapture(input_path)\n\n    # Define the codec and create VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(video_capture.get(3)), int(video_capture.get(4))))\n\n    while video_capture.isOpened():\n        ret, frame = video_capture.read()\n        if not ret:\n            break\n\n        # Preprocess the frame\n        input_data = preprocess_frame(frame, input_size)\n\n        # Run inference\n        interpreter.set_tensor(input_details[0]['index'], input_data)\n        start_time = time.time()\n        interpreter.invoke()\n        end_time = time.time()\n\n        # Retrieve detection results\n        boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n        classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n        scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n        # Draw detections on the frame\n        draw_detections(frame, boxes, classes, scores)\n\n        # Write the processed frame to output video\n        out.write(frame)\n\n    # Release resources\n    video_capture.release()\n    out.release()\n\nif __name__ == \"__main__\":\n    main()"
      },
      "session_id": "phi4_f993_psg_batch",
      "metadata": {
        "num_run": 7
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 11.256,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-54-58-903840_chatcmpl-940a501d-5164-4ea3-b7dd-02fb45389e3c",
          "traceId": "6e71952b",
          "type": "GENERATION",
          "name": "6e71_psg_gen_attempt#1",
          "startTime": "2026-02-09T15:54:58.903000+00:00",
          "endTime": "2026-02-09T15:55:10.159000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11256.0,
          "completionTokens": 842,
          "totalTokens": 1259,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-09T15:55:48.665Z",
      "createdAt": "2026-02-09T15:54:59.457Z",
      "environment": "default"
    },
    {
      "id": "d96a0ab4",
      "timestamp": "2026-02-09T15:53:23.352000+00:00",
      "name": "d96a_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Get input shape and pre-processing details\ninput_shape = input_details[0]['shape']\ninput_scale, input_zero_point = input_details[0]['quantization']\n\ndef preprocess_frame(frame):\n    \"\"\"Preprocess the frame for inference.\"\"\"\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    \n    if input_scale != 0:\n        input_data = input_data / input_scale + input_zero_point\n    return input_data.astype(input_details[0]['dtype'])\n\n# Read input video\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Prepare output video writer\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_data = preprocess_frame(frame)\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n            class_id = int(classes[i])\n            label = f\"{labels[class_id]}: {scores[i]:.2f}\"\n\n            # Draw bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\n\nprint(\"Object detection completed and results saved to:\", output_path)"
      },
      "session_id": "phi4_f993_psg_batch",
      "metadata": {
        "num_run": 6
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 34.188,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-53-23-353376_chatcmpl-6aa45c02-47f8-4a32-bfe3-ebda185c1fcc",
          "traceId": "d96a0ab4",
          "type": "GENERATION",
          "name": "d96a_psg_gen_attempt#1",
          "startTime": "2026-02-09T15:53:23.353000+00:00",
          "endTime": "2026-02-09T15:53:34.770000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11417.0,
          "completionTokens": 844,
          "totalTokens": 1261,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-53-34-932247_chatcmpl-a1cf3b92-b78e-49a0-8617-33cf910ed4f5",
          "traceId": "d96a0ab4",
          "type": "GENERATION",
          "name": "d96a_psg_gen_attempt#2",
          "startTime": "2026-02-09T15:53:34.932000+00:00",
          "endTime": "2026-02-09T15:53:44.321000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9389.0,
          "completionTokens": 696,
          "totalTokens": 1239,
          "promptTokens": 543,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-53-44-699558_chatcmpl-30a7f5b2-089a-4334-a766-2c7169e58040",
          "traceId": "d96a0ab4",
          "type": "GENERATION",
          "name": "d96a_psg_gen_attempt#3",
          "startTime": "2026-02-09T15:53:44.699000+00:00",
          "endTime": "2026-02-09T15:53:57.541000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12842.0,
          "completionTokens": 960,
          "totalTokens": 1552,
          "promptTokens": 592,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-09T15:54:38.095Z",
      "createdAt": "2026-02-09T15:53:23.906Z",
      "environment": "default"
    },
    {
      "id": "0d533951",
      "timestamp": "2026-02-09T15:51:37.661000+00:00",
      "name": "0d53_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration Parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the interpreter and allocate tensors\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Function to preprocess the input image\ndef preprocess_image(frame):\n    # Resize and normalize the frame\n    img = cv2.resize(frame, (300, 300))\n    img = np.expand_dims(img, axis=0)\n    img = img.astype(np.float32)\n    img = img / 255.0  # Normalize to [0,1]\n    return img.astype(np.uint8)  # Convert to UINT8 as expected by the model\n\n# Function to draw bounding boxes and labels\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        # Extract information from the detection\n        ymin, xmin, ymax, xmax = detection[0:4]\n        score = detection[2]\n        class_id = int(detection[1])\n\n        if score >= confidence_threshold:\n            # Convert normalized coordinates to pixel values\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            # Draw rectangle and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (255, 0, 0), 2)\n            label = f\"{labels[class_id]}: {score:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image for model input\n    input_data = preprocess_image(frame)\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Run inference\n    interpreter.invoke()\n\n    # Get detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]   # Confidence of detected objects\n\n    # Combine results into a single list for easier processing\n    detections = np.column_stack((boxes, classes, scores))\n\n    # Draw bounding boxes and labels on the frame\n    draw_boxes(frame, detections)\n\n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "phi4_f993_psg_batch",
      "metadata": {
        "num_run": 5
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 47.854,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-51-37-661906_chatcmpl-431a47d9-e284-4d9c-a163-9fa8dbe991bb",
          "traceId": "0d533951",
          "type": "GENERATION",
          "name": "0d53_psg_gen_attempt#1",
          "startTime": "2026-02-09T15:51:37.661000+00:00",
          "endTime": "2026-02-09T15:51:49.167000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11506.0,
          "completionTokens": 858,
          "totalTokens": 1275,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-51-49-326297_chatcmpl-f801225f-4ddc-463e-bce7-1827bd998454",
          "traceId": "0d533951",
          "type": "GENERATION",
          "name": "0d53_psg_gen_attempt#2",
          "startTime": "2026-02-09T15:51:49.326000+00:00",
          "endTime": "2026-02-09T15:52:01.812000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12486.0,
          "completionTokens": 927,
          "totalTokens": 1554,
          "promptTokens": 627,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-52-02-094426_chatcmpl-f2e6491c-6aab-4b6e-9e78-d6a282cf7f0b",
          "traceId": "0d533951",
          "type": "GENERATION",
          "name": "0d53_psg_gen_attempt#3",
          "startTime": "2026-02-09T15:52:02.094000+00:00",
          "endTime": "2026-02-09T15:52:11.929000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9835.0,
          "completionTokens": 741,
          "totalTokens": 1298,
          "promptTokens": 557,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-52-12-112291_chatcmpl-1f1987ba-404b-423d-8904-f6cabf90c5f4",
          "traceId": "0d533951",
          "type": "GENERATION",
          "name": "0d53_psg_gen_attempt#4",
          "startTime": "2026-02-09T15:52:12.112000+00:00",
          "endTime": "2026-02-09T15:52:25.515000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13403.0,
          "completionTokens": 992,
          "totalTokens": 1618,
          "promptTokens": 626,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-09T15:53:03.917Z",
      "createdAt": "2026-02-09T15:51:38.216Z",
      "environment": "default"
    },
    {
      "id": "6c6b5641",
      "timestamp": "2026-02-09T15:50:06.154000+00:00",
      "name": "6c6b_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport os\n\nfrom tflite_runtime.interpreter import Interpreter\n\ndef load_labels(label_path):\n    with open(label_path, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\ndef preprocess_input(image, input_size):\n    image = cv2.resize(image, (input_size[1], input_size[0]))\n    image = np.expand_dims(image, axis=0)\n    image = image.astype(np.uint8)  # Ensure the data type is UINT8\n    return image\n\ndef draw_detections(frame, detections, labels, threshold):\n    height, width, _ = frame.shape\n    for detection in detections[0][0]:\n        score = detection[2]\n        if score > threshold:\n            bbox = detection[3:7] * np.array([width, height, width, height])\n            left, top, right, bottom = bbox.astype(int)\n            class_id = int(detection[1])\n            label = labels[class_id]\n\n            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n            text = f\"{label}: {score:.2f}\"\n            cv2.putText(frame, text, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\ndef main():\n    # Configuration\n    model_path = \"models/ssd-mobilenet_v1/detect.tflite\"\n    label_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\n    input_path = \"data/object_detection/sheeps.mp4\"\n    output_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\n    confidence_threshold = 0.5\n\n    # Load labels\n    labels = load_labels(label_path)\n\n    # Initialize TFLite interpreter\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n\n    # Get input and output details\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    _, height, width, _ = input_details[0]['shape']\n\n    # Open video files\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocess input\n        input_data = preprocess_input(frame, (height, width))\n\n        # Run inference\n        interpreter.set_tensor(input_details[0]['index'], input_data)\n        interpreter.invoke()\n\n        # Get detections\n        detections = [interpreter.get_tensor(output['index']) for output in output_details]\n\n        # Draw detections on the frame\n        draw_detections(frame, detections, labels, confidence_threshold)\n\n        # Write the frame with detections\n        out.write(frame)\n\n    cap.release()\n    out.release()\n    cv2.destroyAllWindows()\n\nif __name__ == \"__main__\":\n    main()"
      },
      "session_id": "phi4_f993_psg_batch",
      "metadata": {
        "num_run": 4
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 33.338,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-50-06-155340_chatcmpl-30eeb68c-ae13-4a18-8c1a-9fe88d81bf36",
          "traceId": "6c6b5641",
          "type": "GENERATION",
          "name": "6c6b_psg_gen_attempt#1",
          "startTime": "2026-02-09T15:50:06.155000+00:00",
          "endTime": "2026-02-09T15:50:17.489000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11334.0,
          "completionTokens": 847,
          "totalTokens": 1264,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-50-17-652141_chatcmpl-437e4730-b516-4f74-b889-a005731b7c29",
          "traceId": "6c6b5641",
          "type": "GENERATION",
          "name": "6c6b_psg_gen_attempt#2",
          "startTime": "2026-02-09T15:50:17.652000+00:00",
          "endTime": "2026-02-09T15:50:27.839000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10187.0,
          "completionTokens": 750,
          "totalTokens": 1450,
          "promptTokens": 700,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-50-28-005271_chatcmpl-c97d97bd-b7b1-4fee-9bda-909431e88271",
          "traceId": "6c6b5641",
          "type": "GENERATION",
          "name": "6c6b_psg_gen_attempt#3",
          "startTime": "2026-02-09T15:50:28.005000+00:00",
          "endTime": "2026-02-09T15:50:39.493000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11488.0,
          "completionTokens": 855,
          "totalTokens": 1541,
          "promptTokens": 686,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-09T15:51:17.389Z",
      "createdAt": "2026-02-09T15:50:06.709Z",
      "environment": "default"
    },
    {
      "id": "c8641777",
      "timestamp": "2026-02-09T15:48:38.856000+00:00",
      "name": "c864_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\n\n# Configuration Parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\ndef load_labels(label_path):\n    with open(label_path, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\ndef main():\n    # Load labels\n    labels = load_labels(label_path)\n\n    # Initialize the TFLite interpreter\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n\n    # Get input and output details\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    # Open video files\n    cap = cv2.VideoCapture(input_path)\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocessing\n        input_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        input_frame_resized = cv2.resize(input_frame, (input_details[0]['shape'][2], input_details[0]['shape'][1]))\n        input_frame_normalized = np.expand_dims(input_frame_resized / 127.5 - 1.0, axis=0).astype(np.float32)\n\n        # Convert to UINT8\n        input_frame_uint8 = (input_frame_normalized * 255).astype(np.uint8)\n\n        # Set the tensor\n        interpreter.set_tensor(input_details[0]['index'], input_frame_uint8)\n\n        # Run inference\n        interpreter.invoke()\n\n        # Postprocessing\n        for idx, output in enumerate(output_details):\n            output_data = interpreter.get_tensor(output['index'])\n            if idx == 0:\n                boxes = output_data[0]\n            elif idx == 1:\n                classes = output_data[0].astype(np.int64)\n            elif idx == 2:\n                scores = output_data[0]\n\n        for i in range(scores.shape[1]):\n            if scores[0, i] > confidence_threshold:\n                class_id = int(classes[0, i])\n                score = scores[0, i]\n                box = boxes[0, i]\n\n                # Scale box to original frame dimensions\n                ymin, xmin, ymax, xmax = box\n                (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n                left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n\n                # Draw bounding box and label on the frame\n                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n                label = f'{labels[class_id]}: {score:.2f}'\n                cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\n        # Write the frame with detections\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == \"__main__\":\n    main()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260209174938_psg_phi4:latest/tmp_20260209174938_psg_phi4:latest.py\", line 88, in <module>\n    main()\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260209174938_psg_phi4:latest/tmp_20260209174938_psg_phi4:latest.py\", line 65, in main\n    for i in range(scores.shape[1]):\nIndexError: tuple index out of range\n"
      },
      "session_id": "phi4_f993_psg_batch",
      "metadata": {
        "num_run": 3
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 60.059,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-48-38-857372_chatcmpl-aa32fe86-10c8-49b8-8356-8d5e40d6844b",
          "traceId": "c8641777",
          "type": "GENERATION",
          "name": "c864_psg_gen_attempt#1",
          "startTime": "2026-02-09T15:48:38.857000+00:00",
          "endTime": "2026-02-09T15:48:49.157000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10300.0,
          "completionTokens": 771,
          "totalTokens": 1188,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-48-49-325407_chatcmpl-759b72bb-67cb-42ab-b749-f00adc77ffc0",
          "traceId": "c8641777",
          "type": "GENERATION",
          "name": "c864_psg_gen_attempt#2",
          "startTime": "2026-02-09T15:48:49.325000+00:00",
          "endTime": "2026-02-09T15:49:00.994000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11669.0,
          "completionTokens": 861,
          "totalTokens": 1555,
          "promptTokens": 694,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-49-01-163480_chatcmpl-c13e88d0-aeff-40dd-952c-965cd67b0351",
          "traceId": "c8641777",
          "type": "GENERATION",
          "name": "c864_psg_gen_attempt#3",
          "startTime": "2026-02-09T15:49:01.163000+00:00",
          "endTime": "2026-02-09T15:49:14+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12837.0,
          "completionTokens": 948,
          "totalTokens": 1704,
          "promptTokens": 756,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-49-14-177789_chatcmpl-916f6bfa-8bf6-44b5-9623-44189acf50e1",
          "traceId": "c8641777",
          "type": "GENERATION",
          "name": "c864_psg_gen_attempt#4",
          "startTime": "2026-02-09T15:49:14.177000+00:00",
          "endTime": "2026-02-09T15:49:26.343000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12166.0,
          "completionTokens": 907,
          "totalTokens": 1590,
          "promptTokens": 683,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-49-26-516731_chatcmpl-9f945d26-b200-4fb9-bbd4-e32c8a22f0a8",
          "traceId": "c8641777",
          "type": "GENERATION",
          "name": "c864_psg_gen_attempt#5",
          "startTime": "2026-02-09T15:49:26.516000+00:00",
          "endTime": "2026-02-09T15:49:38.709000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12193.0,
          "completionTokens": 908,
          "totalTokens": 1595,
          "promptTokens": 687,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "63d273ac-11c9-4e24-a853-35b3006664c5",
          "traceId": "c8641777",
          "type": "SPAN",
          "name": "error_c8_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-09T15:49:38.916000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260209174938_psg_phi4:latest/tmp_20260209174938_psg_phi4:latest.py\", line 88, in <module>\n    main()\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260209174938_psg_phi4:latest/tmp_20260209174938_psg_phi4:latest.py\", line 65, in main\n    for i in range(scores.shape[1]):\nIndexError: tuple index out of range\n",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-09T15:49:44.556Z",
      "createdAt": "2026-02-09T15:48:39.410Z",
      "environment": "default"
    },
    {
      "id": "a99b1258",
      "timestamp": "2026-02-09T15:47:43.394000+00:00",
      "name": "a99b_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\n\n# Configuration Parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\nheight, width = input_shape[1], input_shape[2]\n\n# Open video files\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the input image\n    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    resized_img = cv2.resize(img_rgb, (width, height))\n    input_data = np.expand_dims(resized_img, axis=0).astype(np.uint8)\n\n    # Perform inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence\n\n    # Loop over all detections and draw detection boxes with labels\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            # Draw rectangle and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            object_name = labels[int(classes[i])] if int(classes[i]) < len(labels) else 'N/A'\n            label = f\"{object_name}: {int(scores[i] * 100)}%\"\n            cv2.putText(frame, label, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (10, 255, 0), 1)\n\n    # Write the frame with boxes\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Object detection completed and video saved at:\", output_path)"
      },
      "session_id": "phi4_f993_psg_batch",
      "metadata": {
        "num_run": 2
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 22.784,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-47-43-395443_chatcmpl-fdff62cb-9e9d-40e3-a0af-563dfda36416",
          "traceId": "a99b1258",
          "type": "GENERATION",
          "name": "a99b_psg_gen_attempt#1",
          "startTime": "2026-02-09T15:47:43.395000+00:00",
          "endTime": "2026-02-09T15:47:54.262000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10867.0,
          "completionTokens": 815,
          "totalTokens": 1232,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-47-54-456415_chatcmpl-83d79310-e022-4b12-aad4-9b7bbc5d00e1",
          "traceId": "a99b1258",
          "type": "GENERATION",
          "name": "a99b_psg_gen_attempt#2",
          "startTime": "2026-02-09T15:47:54.456000+00:00",
          "endTime": "2026-02-09T15:48:06.179000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11723.0,
          "completionTokens": 869,
          "totalTokens": 1496,
          "promptTokens": 627,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-09T15:48:18.106Z",
      "createdAt": "2026-02-09T15:47:43.948Z",
      "environment": "default"
    },
    {
      "id": "ade6233e",
      "timestamp": "2026-02-09T15:45:49.324000+00:00",
      "name": "ade6_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport time\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration Parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video capture and output setup\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    print(\"Error: Could not open video.\")\n    exit()\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\ndef preprocess_frame(frame):\n    # Resize the frame to match model input size\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    \n    # Normalize and convert to UINT8\n    frame_normalized = frame_resized / 255.0\n    frame_uint8 = (frame_normalized * 255).astype(np.uint8)\n    \n    return np.expand_dims(frame_uint8, axis=0)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the input frame\n    input_data = preprocess_frame(frame)\n\n    # Set model input tensor\n    interpreter.set_tensor(input_index, input_data)\n\n    # Run inference\n    start_time = time.time()\n    interpreter.invoke()\n    elapsed_ms = (time.time() - start_time) * 1000\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0] # Confidence of detected objects\n\n    frame_height, frame_width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i] * 100))\n            \n            # Draw bounding box and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write frame to output video\n    out.write(frame)\n    print(f\"Frame processed in {elapsed_ms:.2f} ms\")\n\ncap.release()\nout.release()\n\nprint(\"Processing complete.\")"
      },
      "session_id": "phi4_f993_psg_batch",
      "metadata": {
        "num_run": 1
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 53.692,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-17-45-49-325317_chatcmpl-5f5d27f5-1948-4bf3-ba92-3494d784b90e",
          "traceId": "ade6233e",
          "type": "GENERATION",
          "name": "ade6_psg_gen_attempt#1",
          "startTime": "2026-02-09T15:45:49.325000+00:00",
          "endTime": "2026-02-09T15:46:16+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26675.0,
          "completionTokens": 965,
          "totalTokens": 1382,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-46-16-354278_chatcmpl-bf6dc5de-ebab-42c1-8a9d-b5e23fca6185",
          "traceId": "ade6233e",
          "type": "GENERATION",
          "name": "ade6_psg_gen_attempt#2",
          "startTime": "2026-02-09T15:46:16.354000+00:00",
          "endTime": "2026-02-09T15:46:29.560000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13206.0,
          "completionTokens": 987,
          "totalTokens": 1530,
          "promptTokens": 543,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-17-46-29-721073_chatcmpl-d3efb75b-aa50-4b4d-bf0a-d66ba8660bad",
          "traceId": "ade6233e",
          "type": "GENERATION",
          "name": "ade6_psg_gen_attempt#3",
          "startTime": "2026-02-09T15:46:29.721000+00:00",
          "endTime": "2026-02-09T15:46:43.017000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13296.0,
          "completionTokens": 993,
          "totalTokens": 1619,
          "promptTokens": 626,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-09T15:47:22.394Z",
      "createdAt": "2026-02-09T15:45:50.037Z",
      "environment": "default"
    }
  ],
  "meta": {
    "total_items": 13
  }
}