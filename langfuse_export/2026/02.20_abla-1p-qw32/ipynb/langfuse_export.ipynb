{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "session_id_list = [\n",
    "     \"qwen2.5-coder:32b_0d8f_psg_batch\",\n",
    "     \"qwen2.5-coder:32b_0d8f_tpusg_batch\",\n",
    "     \"qwen2.5-coder:32b_0d8f_sg_batch\"\n",
    "     \n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session qwen2.5-coder:32b_0d8f_psg_batch...\n",
      "Fetching observation data for time-00-18-51-788939_chatcmpl-c7adb18b-78cb-48a8-98a0-389aa5fbb263...\n",
      "Fetching observation data for time-00-19-13-691765_chatcmpl-58ff806f-2965-4a23-9c71-5bbed375f785...\n",
      "Fetching observation data for time-00-17-07-426742_chatcmpl-f1ec2662-cd79-41c6-bb39-69cf9aa572af...\n",
      "Fetching observation data for time-00-17-29-511491_chatcmpl-b9526eb6-7a7d-4a0b-9aa2-3383f393918e...\n",
      "Fetching observation data for time-00-15-03-724041_chatcmpl-6ff5e937-fc83-4750-aa19-f88c60b15871...\n",
      "Fetching observation data for time-00-15-25-731781_chatcmpl-09915d59-2db1-4114-829d-b4a0f5d45a4a...\n",
      "Fetching observation data for time-00-15-47-783770_chatcmpl-65a6d7be-0c4a-47e9-90e3-401dd3e13658...\n",
      "Fetching observation data for time-00-13-44-329096_chatcmpl-0d350305-10c9-4b98-a104-1cf84995df7b...\n",
      "Fetching observation data for time-00-12-24-958450_chatcmpl-79de57dc-e49b-4b45-a57f-acf6cb7e47e8...\n",
      "Fetching observation data for time-00-10-43-407118_chatcmpl-abb630e5-16a3-4c82-8603-9f55bc5f6a8b...\n",
      "Fetching observation data for time-00-11-05-897233_chatcmpl-3674bda9-58c0-43a6-9b1d-994d8211c575...\n",
      "Fetching observation data for time-00-08-38-917393_chatcmpl-431546be-5ad1-45ab-be73-e4c751e3ee50...\n",
      "Fetching observation data for time-00-09-00-996418_chatcmpl-fa8fa2ad-1d6f-469c-ba75-a1ef86059aff...\n",
      "Fetching observation data for time-00-09-22-529957_chatcmpl-b4c9daec-a37b-4f9e-9f2a-0e64e92c6ede...\n",
      "Fetching observation data for time-00-07-19-567693_chatcmpl-5fee9223-2617-4f45-9381-ead7b76e7d83...\n",
      "Fetching observation data for time-00-05-38-136021_chatcmpl-eabe7106-a3a7-4abb-a31d-54c52365b36f...\n",
      "Fetching observation data for time-00-06-00-231983_chatcmpl-65b0ee1f-b7b3-4483-8967-55ca40d49582...\n",
      "Fetching observation data for time-00-03-54-734105_chatcmpl-0d332fef-d013-48cb-a99a-94717eefd36b...\n",
      "Fetching observation data for time-00-04-16-816217_chatcmpl-c435b675-a6e3-42bf-955b-cb81e5ba1632...\n",
      "Fetching observation data for time-00-01-39-259482_chatcmpl-87efbdb3-5563-4dd7-a0a1-6365381e6773...\n",
      "Fetching observation data for time-00-02-01-909237_chatcmpl-1bb1f3d8-b98b-453a-af88-5bf4f7f24b9d...\n",
      "Fetching observation data for time-00-02-23-730714_chatcmpl-7c2c17f9-42ce-4116-9710-22a3c3160fa1...\n",
      "Fetching observation data for time-00-02-45-735432_chatcmpl-895176cc-9451-4db7-ad12-0873f2fe2e38...\n",
      "Fetching observation data for time-00-03-07-792527_chatcmpl-af5d9cbb-ccf0-44b1-abe5-a30d0c58cf80...\n",
      "Fetching observation data for 28eb2582-6ee7-416f-a316-6e374e05389e...\n",
      "Fetching observation data for time-00-00-15-349676_chatcmpl-3c7110df-8c6d-4334-9bc2-6e0d0bdb7cc8...\n",
      "Fetching observation data for time-23-59-53-414770_chatcmpl-783e6a5e-cc73-432f-a970-a92b579783c9...\n",
      "Fetching observation data for time-23-58-08-741618_chatcmpl-26bb0393-97bb-42ec-aace-b4e877aa81e4...\n",
      "Fetching observation data for time-23-58-32-154392_chatcmpl-c95dc3e2-0eb6-4176-87ef-b7880a6937e1...\n",
      "Fetching observation data for time-23-56-16-845203_chatcmpl-737c2036-fd12-4450-b067-d62313729530...\n",
      "Fetching observation data for time-23-56-33-960587_chatcmpl-cb2ca0f6-a2dd-4917-a81d-a26bc363539b...\n",
      "Fetching observation data for time-23-56-50-910860_chatcmpl-eb83463e-1244-4118-92b0-e8e82962f987...\n",
      "Fetching observation data for time-23-57-07-847223_chatcmpl-1ece63c0-92eb-4112-9116-92886f675300...\n",
      "Fetching observation data for time-23-57-24-712278_chatcmpl-78c147fb-5fec-441d-a38e-c821dddfa3c1...\n",
      "Fetching observation data for cdba1ed8-59b8-4796-9ce9-fada1abf6e68...\n",
      "Fetching observation data for time-23-54-25-352818_chatcmpl-653b4425-1467-47ca-84d8-1c0bca099c2c...\n",
      "Fetching observation data for time-23-54-42-363336_chatcmpl-dc51f1e7-6e14-4f1b-aedc-1312332e2dac...\n",
      "Fetching observation data for time-23-54-59-327059_chatcmpl-0086c45c-c4f9-4c30-bfb0-999f15954060...\n",
      "Fetching observation data for time-23-55-16-352535_chatcmpl-cbdd3b2f-a26a-47ec-9e5d-77f6d2b95298...\n",
      "Fetching observation data for time-23-55-33-269345_chatcmpl-8df1dcf3-0e41-4a0a-be76-2ec4a5028276...\n",
      "Fetching observation data for db53d75d-8de7-4c19-a6c5-f5b4da1f30d9...\n",
      "Fetching observation data for time-23-52-33-781458_chatcmpl-48ca8f99-cf58-43f7-b76f-bb359f10f28a...\n",
      "Fetching observation data for time-23-52-50-762470_chatcmpl-e306750a-8474-410a-82d7-a27925cdf8fc...\n",
      "Fetching observation data for time-23-53-07-668097_chatcmpl-13e389b8-2fe4-4390-b9e3-c9b0b4e13962...\n",
      "Fetching observation data for time-23-53-24-685267_chatcmpl-e137a9b2-0dc6-419a-9105-895e5cb5bc7c...\n",
      "Fetching observation data for time-23-53-41-647680_chatcmpl-497a5e89-7e4a-42af-a2ad-e70cab6fb2ff...\n",
      "Fetching observation data for b96e88cb-0bd4-4254-a060-7aa13148de03...\n",
      "Fetching observation data for time-23-50-42-414140_chatcmpl-c6dc73d6-9ee5-4d51-8daa-15d3ea20afb3...\n",
      "Fetching observation data for time-23-50-59-555627_chatcmpl-cc36b894-8e48-4cee-bbc5-a06c64990c1e...\n",
      "Fetching observation data for time-23-51-16-426305_chatcmpl-20de5ffc-cba8-40a2-94b0-b6efbf3e6dd1...\n",
      "Fetching observation data for time-23-51-33-598162_chatcmpl-08d07e55-f119-4eea-a5d6-30ec873de79e...\n",
      "Fetching observation data for time-23-51-50-586845_chatcmpl-a44e2571-923e-43b1-b692-07229c170d88...\n",
      "Fetching observation data for 533105ff-74b6-4e56-b136-31ff7850122f...\n",
      "Fetching observation data for time-23-48-51-024829_chatcmpl-db57b1b2-11bb-436b-ba61-c190ad402269...\n",
      "Fetching observation data for time-23-49-08-015062_chatcmpl-a664877f-8f04-46d6-b5cb-b82784cd8770...\n",
      "Fetching observation data for time-23-49-25-351965_chatcmpl-aa758067-38ce-4a66-831f-aa9042442cc7...\n",
      "Fetching observation data for time-23-49-42-235653_chatcmpl-aa1f3cec-336f-4f02-9bad-79825745e7c9...\n",
      "Fetching observation data for time-23-49-59-501597_chatcmpl-61f23766-48eb-4dca-9f84-11dbd2992508...\n",
      "Fetching observation data for 1296b6d1-968c-4f8c-a562-3cf5dfc411d3...\n",
      "Fetching observation data for time-23-46-59-570656_chatcmpl-b454b5ac-4e16-4a9e-9732-6ed8f0e40398...\n",
      "Fetching observation data for time-23-47-16-543564_chatcmpl-c7a6b62e-aaa9-47b1-9058-3bc84ff9898e...\n",
      "Fetching observation data for time-23-47-33-476745_chatcmpl-7aeb29aa-f549-4a67-8e5e-510e0035a5e3...\n",
      "Fetching observation data for time-23-47-50-414276_chatcmpl-1ac845b1-20f0-479f-b17d-826e674a331d...\n",
      "Fetching observation data for time-23-48-07-326517_chatcmpl-05d610f5-92bf-410e-afad-5396177410ba...\n",
      "Fetching observation data for 891ab3a1-cda3-46cc-8778-56d4f400943a...\n",
      "Fetching observation data for time-23-45-07-281507_chatcmpl-87f6c790-de32-4da7-996f-0211a181576a...\n",
      "Fetching observation data for time-23-45-24-300132_chatcmpl-62b820ae-769e-45c0-8161-c5b96dd0f57b...\n",
      "Fetching observation data for time-23-45-41-174127_chatcmpl-4bdc3e28-4595-49d9-99b6-404eababe6d7...\n",
      "Fetching observation data for time-23-45-58-159120_chatcmpl-db90c3a7-31a1-47b0-aa69-cca5eb263f8b...\n",
      "Fetching observation data for time-23-46-15-029108_chatcmpl-0f052f17-53ab-431c-8da4-935a244cf879...\n",
      "Fetching observation data for 0c37449c-5bde-4560-8911-2d5a087f4d29...\n",
      "Fetching observation data for time-23-43-14-629450_chatcmpl-73e4e8c8-793b-4daa-8c38-60eb5cd2a649...\n",
      "Fetching observation data for time-23-43-32-074956_chatcmpl-0951339c-3a58-4b9f-9404-fbfe4e79fdd6...\n",
      "Fetching observation data for time-23-43-49-125232_chatcmpl-44d1e669-410b-49a5-9726-dde056f583a4...\n",
      "Fetching observation data for time-23-44-06-081939_chatcmpl-986e8a30-dabb-4239-8617-01fd9255e510...\n",
      "Fetching observation data for time-23-44-23-071606_chatcmpl-a35c87c7-c9e7-4f32-afcf-26c3730104fa...\n",
      "Fetching observation data for 83444241-33cf-49b5-995b-d26d9932a234...\n",
      "Fetching observation data for time-23-41-23-180742_chatcmpl-40b23386-1f12-430e-b920-4edde6f910aa...\n",
      "Fetching observation data for time-23-41-40-525544_chatcmpl-bafb9789-26ed-4b6b-ad67-963f61b6cb9c...\n",
      "Fetching observation data for time-23-41-57-463454_chatcmpl-54b2c1af-1d41-4273-98d3-0b71718e4b68...\n",
      "Fetching observation data for time-23-42-14-361129_chatcmpl-0c8ac9ae-69b6-470a-ab9c-51e681f22bdd...\n",
      "Fetching observation data for time-23-42-31-259677_chatcmpl-aaed4580-e35b-4a04-88a1-891d03ed38b8...\n",
      "Fetching observation data for 64908855-dde9-4455-9925-c13115f574f2...\n",
      "Fetching observation data for time-23-39-31-548205_chatcmpl-234cbab4-be0b-4ce7-803d-1ad160eed21f...\n",
      "Fetching observation data for time-23-39-49-059330_chatcmpl-df727d9c-42bc-4a0b-b4bb-e665c23561c1...\n",
      "Fetching observation data for time-23-40-05-952751_chatcmpl-0a140540-5a39-4899-8016-b71c570e2f55...\n",
      "Fetching observation data for time-23-40-23-059074_chatcmpl-79679e13-3a88-48e8-8d7d-9d9b5cd373a5...\n",
      "Fetching observation data for time-23-40-39-949629_chatcmpl-5673a3b7-5fae-4414-8ba2-eb042d787909...\n",
      "Fetching observation data for 2663d1ae-f6e7-4ba4-877e-85dd1f057a3e...\n",
      "Fetching observation data for time-23-37-39-615387_chatcmpl-60a23b08-6e08-46d0-9a3b-3a0562b13151...\n",
      "Fetching observation data for time-23-37-56-640002_chatcmpl-8d2a0ebf-76da-4fd3-8d7e-72c54c96f2a5...\n",
      "Fetching observation data for time-23-38-13-516849_chatcmpl-25ae5bcc-ecd4-4c06-95d8-c15c203fbb78...\n",
      "Fetching observation data for time-23-38-30-392686_chatcmpl-067064f3-4291-45a8-98b6-f4adefd9cfb3...\n",
      "Fetching observation data for time-23-38-47-310790_chatcmpl-28a9fb28-62f9-46e8-9b3f-b9fd3415dc39...\n",
      "Fetching observation data for 71152293-4180-44f0-b59d-8699799ea371...\n",
      "Fetching observation data for time-23-35-47-416007_chatcmpl-0f9c935b-14aa-4227-8d24-213bbf5d5825...\n",
      "Fetching observation data for time-23-36-04-381790_chatcmpl-bfb6a70f-24d4-4cf8-af08-d036d5003896...\n",
      "Fetching observation data for time-23-36-21-323782_chatcmpl-f939e0b2-87d3-4d02-8239-f65238803e15...\n",
      "Fetching observation data for time-23-36-38-210164_chatcmpl-5dea0aa5-b2a3-4900-b1c3-f5c5673db24a...\n",
      "Fetching observation data for time-23-36-55-139580_chatcmpl-03e9fcfc-adbd-4116-8614-caee4ff6fd34...\n",
      "Fetching observation data for 8cdfcb40-8eaf-4e7b-9b79-6cc60079f843...\n",
      "Fetching observation data for time-23-33-55-841217_chatcmpl-071b2674-01aa-4eef-b5e4-39fe3618caab...\n",
      "Fetching observation data for time-23-34-12-860834_chatcmpl-4bba199f-b8a2-4180-98f5-3f8c4edd3aff...\n",
      "Fetching observation data for time-23-34-29-801712_chatcmpl-fdc5614b-30fd-4018-adcf-70a68fdaa616...\n",
      "Fetching observation data for time-23-34-46-774676_chatcmpl-54bd8a93-cfb9-48e0-bfc6-70934e9a9512...\n",
      "Fetching observation data for time-23-35-03-761243_chatcmpl-4458feac-7ebf-4fb8-a344-7506410963a4...\n",
      "Fetching observation data for 9fab05e0-2547-4236-ade4-df85a2b984ae...\n",
      "Fetching observation data for time-23-32-04-432944_chatcmpl-c341f514-440c-422c-8c6a-21f4d3d6626b...\n",
      "Fetching observation data for time-23-32-21-818741_chatcmpl-7517b595-9974-4b16-a8e1-d3d01ab0b904...\n",
      "Fetching observation data for time-23-32-38-860502_chatcmpl-b5ad51e7-2f3a-45e1-a1a1-6e2f38ffd05f...\n",
      "Fetching observation data for time-23-32-55-950547_chatcmpl-484d75e6-e5c2-4394-aa39-515b157a44b0...\n",
      "Fetching observation data for time-23-33-12-904693_chatcmpl-2daa38a5-9b46-4033-9993-e7d08deb32c8...\n",
      "Fetching observation data for fe1ff47d-d42e-4db1-84fe-8997d896658e...\n",
      "Fetching observation data for time-23-30-12-371678_chatcmpl-a58db01f-9996-47ac-83c6-c462cd35c9f3...\n",
      "Fetching observation data for time-23-30-29-424541_chatcmpl-173d0223-35a5-49c7-9646-82446be2e5b5...\n",
      "Fetching observation data for time-23-30-46-360477_chatcmpl-82ebf5da-cd22-4966-9caa-ff3b9eaeec36...\n",
      "Fetching observation data for time-23-31-03-253363_chatcmpl-7c72e9c9-66c7-4db7-b242-681c617352d0...\n",
      "Fetching observation data for time-23-31-20-285962_chatcmpl-b3d33b7e-2329-4c0b-9543-c8da5ce67946...\n",
      "Fetching observation data for e0f8aa71-ae27-4bc0-93ab-aae752327c26...\n",
      "Fetching observation data for time-23-28-20-695504_chatcmpl-4af7c81e-647e-4217-aa21-93fcfe4e4470...\n",
      "Fetching observation data for time-23-28-38-257565_chatcmpl-74d58bd2-0eb4-493f-8de1-4585bcec2b0b...\n",
      "Fetching observation data for time-23-28-55-202269_chatcmpl-8d3879c4-eb02-4bba-b499-097a7fb59df8...\n",
      "Fetching observation data for time-23-29-12-169244_chatcmpl-4b2e9e1c-b9bd-4df1-bcc4-df04a92a2d3d...\n",
      "Fetching observation data for time-23-29-29-184536_chatcmpl-deef65ed-806f-45d4-85b9-8d7bcfb08a8a...\n",
      "Fetching observation data for acac7733-76da-4c5b-9bc9-0e2c7900242d...\n",
      "Fetching observation data for time-23-25-59-253482_chatcmpl-072f8ecb-807a-40cc-9a02-59ac36fa7d6c...\n",
      "Fetching observation data for time-23-26-46-138049_chatcmpl-e3cbaeed-6c09-4318-a2db-38f0b383c2a3...\n",
      "Fetching observation data for time-23-27-03-317354_chatcmpl-19d57f80-f386-49ce-9b9d-088b486c3567...\n",
      "Fetching observation data for time-23-27-20-251638_chatcmpl-4139af1f-e3e1-4bbe-acff-da51ef37bbec...\n",
      "Fetching observation data for time-23-27-37-267673_chatcmpl-8b074d75-8a63-4b0d-9316-2910cbb84d5a...\n",
      "Fetching observation data for 0e351f4e-fc58-4d78-bad2-beb6f5c44f00...\n",
      "Raw JSON saved to: /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/raw_export/raw_qwen2.5-coder:32b_0d8f_psg_batch.json\n",
      "Fetching traces for session qwen2.5-coder:32b_0d8f_tpusg_batch...\n",
      "Fetching observation data for time-01-32-53-337175_chatcmpl-902e2518-0f16-4b8e-966d-52d48cd15786...\n",
      "Fetching observation data for time-01-33-18-207211_chatcmpl-e887ba34-f94c-494d-b281-37cfc76ae41b...\n",
      "Fetching observation data for time-01-33-42-892515_chatcmpl-ebd4ad74-b6bb-4554-a13a-f828f746a6e6...\n",
      "Fetching observation data for time-01-34-07-873467_chatcmpl-06244faf-0eff-4f81-b4d3-e81ea5122c5e...\n",
      "Fetching observation data for time-01-34-32-765010_chatcmpl-5bb7e091-460f-41c0-9d2f-38113005ae5d...\n",
      "Fetching observation data for b9004e45-bdaa-4fe6-b4c8-c0e20c4ec98d...\n",
      "Fetching observation data for time-01-30-23-860076_chatcmpl-5a815b78-f481-4f04-80ac-75214afd6ee3...\n",
      "Fetching observation data for time-01-30-48-584711_chatcmpl-3d3dfe89-6dc6-467f-a1a7-f6c6e522012f...\n",
      "Fetching observation data for time-01-31-13-405155_chatcmpl-36973079-9ce6-48a0-ade8-128d02ea8116...\n",
      "Fetching observation data for time-01-31-38-131564_chatcmpl-24e1567f-b89f-4190-abb3-677964c2a531...\n",
      "Fetching observation data for time-01-32-02-907281_chatcmpl-779fb67c-ccf7-4c44-99a6-0ccb77a7b482...\n",
      "Fetching observation data for 4094fa78-0d3f-484e-906d-7447c124ac55...\n",
      "Fetching observation data for time-01-27-52-927545_chatcmpl-5705b5ed-7fc8-4e28-8cf1-ae4d602e2f59...\n",
      "Fetching observation data for time-01-28-17-681107_chatcmpl-3b52466b-3148-4fce-ab01-d4d512451a7e...\n",
      "Fetching observation data for time-01-28-42-401748_chatcmpl-5422a22e-74b7-45b0-9093-3f96d9b47d31...\n",
      "Fetching observation data for time-01-29-07-469285_chatcmpl-7eb140e9-ffd7-4939-b395-bd66cd939e39...\n",
      "Fetching observation data for time-01-29-32-135325_chatcmpl-d8cb2f01-d867-43cc-949e-42ae1ad522a7...\n",
      "Fetching observation data for 2ada4472-fcdd-489b-b847-760670efb2cf...\n",
      "Fetching observation data for time-01-25-23-437965_chatcmpl-c6821955-533f-4d34-8b45-e8428934d527...\n",
      "Fetching observation data for time-01-25-48-171634_chatcmpl-8aedddb0-0a9d-4d4a-8481-bd33d0a3a968...\n",
      "Fetching observation data for time-01-26-12-909555_chatcmpl-26c29b67-c99e-425e-9f36-3881bb61371c...\n",
      "Fetching observation data for time-01-26-37-668231_chatcmpl-cfa78d82-fbf3-4cd9-85e2-aa77a651e3cf...\n",
      "Fetching observation data for time-01-27-02-664529_chatcmpl-5989c3ab-81f4-4264-9fbd-7ec82e86fec2...\n",
      "Fetching observation data for dfe01324-fd5b-4c75-876c-13979de2453e...\n",
      "Fetching observation data for time-01-22-52-745728_chatcmpl-b9ed3560-0f6e-4185-a0c6-3065aff16c67...\n",
      "Fetching observation data for time-01-23-17-515054_chatcmpl-da0488f1-6cf8-4eb4-a87a-a88f54ba7bd3...\n",
      "Fetching observation data for time-01-23-42-454118_chatcmpl-5d49214d-c1e0-4655-b04e-28808562aba1...\n",
      "Fetching observation data for time-01-24-07-568110_chatcmpl-10d7b36a-287f-4699-a378-8f17999c9a3c...\n",
      "Fetching observation data for time-01-24-32-450352_chatcmpl-7e33f958-8fdd-4d7a-8c57-c4ce808746ec...\n",
      "Fetching observation data for 0ea67dd2-096a-407b-8910-81648fed2d46...\n",
      "Fetching observation data for time-01-20-22-093590_chatcmpl-d00152ec-8dc3-463e-af35-8c4c4d05cce1...\n",
      "Fetching observation data for time-01-20-46-906739_chatcmpl-55c5782c-2a59-4db1-8e50-64e08264c17d...\n",
      "Fetching observation data for time-01-21-11-779833_chatcmpl-057e12a3-fb1a-465a-a8c2-d5e166987a94...\n",
      "Fetching observation data for time-01-21-36-437660_chatcmpl-e13d3e1d-b9be-4f36-8357-2f8c812b84ab...\n",
      "Fetching observation data for time-01-22-01-833431_chatcmpl-09e398d6-79c6-42b5-99b1-94bebcb3d1d1...\n",
      "Fetching observation data for 280241a2-023b-4d71-8c71-9366c0f25904...\n",
      "Fetching observation data for time-01-17-51-434861_chatcmpl-1e2d9401-cb25-4c44-a892-d12921e5e73c...\n",
      "Fetching observation data for time-01-18-16-521720_chatcmpl-c8690418-2b17-4428-94d9-0d24e5d366d2...\n",
      "Fetching observation data for time-01-18-41-338700_chatcmpl-d28a91a4-bec4-427e-a23a-7a914f72dfeb...\n",
      "Fetching observation data for time-01-19-06-310911_chatcmpl-b58d941e-6a9a-425a-8dda-17f6f0685bc3...\n",
      "Fetching observation data for time-01-19-30-897719_chatcmpl-5387d399-9b2a-4ef3-ae68-03acdc5541b7...\n",
      "Fetching observation data for d7b93ac4-3b94-4612-968b-ecb04c1bb51a...\n",
      "Fetching observation data for time-01-15-20-760636_chatcmpl-5274c2dc-a6f4-4fed-b37c-899e56b30ef7...\n",
      "Fetching observation data for time-01-15-45-524125_chatcmpl-e618d60f-1c03-433e-8ea0-ef68cb083e67...\n",
      "Fetching observation data for time-01-16-10-602276_chatcmpl-0d4f6b8e-6d58-47d0-aa8f-d53f8141e90b...\n",
      "Fetching observation data for time-01-16-35-312019_chatcmpl-6c33c36a-b866-4dad-af6a-8dc86e7b866c...\n",
      "Fetching observation data for time-01-17-00-309539_chatcmpl-ae72dfe8-5381-450f-b9f1-fcd90600c64c...\n",
      "Fetching observation data for 4b0b216e-d300-483e-a002-3e417f6b8966...\n",
      "Fetching observation data for time-01-12-50-040260_chatcmpl-4b5e273f-2ffe-4f31-9cd6-6b64cdf47f37...\n",
      "Fetching observation data for time-01-13-14-927773_chatcmpl-d09e9335-9f7a-4d0b-a4b0-32eea5c99d47...\n",
      "Fetching observation data for time-01-13-39-695185_chatcmpl-939ff1af-a238-4a46-8930-5b4212a8843b...\n",
      "Fetching observation data for time-01-14-05-015457_chatcmpl-bae5058a-7af7-42bd-94f9-2c41a60e6cb2...\n",
      "Fetching observation data for time-01-14-29-789705_chatcmpl-810f1b04-9c33-400b-96e1-7eed8fb166f2...\n",
      "Fetching observation data for 56029bed-f0b9-4963-b2dd-7ebbec572d50...\n",
      "Fetching observation data for time-01-10-20-665797_chatcmpl-4b46ea32-83a8-427e-983c-35bc378ce7cb...\n",
      "Fetching observation data for time-01-10-45-362073_chatcmpl-753c4641-a87e-4b5b-87a3-507370068559...\n",
      "Fetching observation data for time-01-11-10-298306_chatcmpl-33bcac44-f296-4f98-8736-31fe34bb1e50...\n",
      "Fetching observation data for time-01-11-35-077978_chatcmpl-6b9961ef-36b2-4fb1-9b67-af39c9a858c3...\n",
      "Fetching observation data for time-01-11-59-955045_chatcmpl-07cbb6a5-ec55-4149-9583-3657cca97818...\n",
      "Fetching observation data for 07afcda4-83eb-42d5-9fa0-c427b2e3716a...\n",
      "Fetching observation data for time-01-07-50-896001_chatcmpl-116fe9f7-99f4-494b-b6fb-e1b920176f2e...\n",
      "Fetching observation data for time-01-08-15-745618_chatcmpl-93a4d0fa-8264-43b4-b143-12e630841cdc...\n",
      "Fetching observation data for time-01-08-40-464309_chatcmpl-6a54c4aa-4af8-4502-93f3-ed14c69d355c...\n",
      "Fetching observation data for time-01-09-05-572967_chatcmpl-c1f36539-c16a-4295-9dd6-95dc484581c8...\n",
      "Fetching observation data for time-01-09-30-257673_chatcmpl-8c16bd7e-6332-4153-8b71-c0d8dbb63e3d...\n",
      "Fetching observation data for e8b09c7b-cc1e-43b6-b89f-be3d85bbf229...\n",
      "Fetching observation data for time-01-05-21-471043_chatcmpl-5beb5f8c-0e3a-4df6-8ac1-65169aa8584b...\n",
      "Fetching observation data for time-01-05-46-296207_chatcmpl-5d9fbc83-f635-4039-96a3-9d79f00ffb4c...\n",
      "Fetching observation data for time-01-06-11-030634_chatcmpl-25b1fd89-2e34-4d7e-8708-e9c12b608312...\n",
      "Fetching observation data for time-01-06-35-741045_chatcmpl-b14cfab0-5c15-462f-8de0-37831c8f487c...\n",
      "Fetching observation data for time-01-07-00-612266_chatcmpl-3612719e-003f-42a7-8aee-bbc6b8455e89...\n",
      "Fetching observation data for ef59ef4e-189e-4168-82b3-eaf303e86932...\n",
      "Fetching observation data for time-01-02-50-948817_chatcmpl-2a5eafe8-d2ec-411b-a2a7-7832af9979c6...\n",
      "Fetching observation data for time-01-03-16-474680_chatcmpl-6a4f009d-624e-48f7-9a6b-96be2106f925...\n",
      "Fetching observation data for time-01-03-41-058951_chatcmpl-a66b4d9e-83bb-4cad-8427-4f35dd6847a5...\n",
      "Fetching observation data for time-01-04-05-955183_chatcmpl-3b7e6947-cb60-4da1-ae80-67d7e6b35b84...\n",
      "Fetching observation data for time-01-04-30-576567_chatcmpl-e7d640ae-5c46-4454-b674-4f00c11451bd...\n",
      "Fetching observation data for c142aa18-0d2b-4fd7-abae-a083e2193b5b...\n",
      "Fetching observation data for time-01-00-21-479697_chatcmpl-5489b581-26ae-492f-a763-3ce932e9383a...\n",
      "Fetching observation data for time-01-00-46-300097_chatcmpl-e8148f8f-8ecc-4ea3-8686-229f2036bcbd...\n",
      "Fetching observation data for time-01-01-11-607278_chatcmpl-55943f6f-65c4-4a59-b9e5-10716ea71da4...\n",
      "Fetching observation data for time-01-01-36-610021_chatcmpl-08da01ea-eb09-4ca1-b026-21c298534fac...\n",
      "Fetching observation data for time-01-02-01-323063_chatcmpl-bb4dfb63-bf7d-4882-abd2-7b035f71d720...\n",
      "Fetching observation data for b281bfc3-c530-4fc1-b791-cc6d1cb245ff...\n",
      "Fetching observation data for time-00-57-51-986859_chatcmpl-c541623b-68ed-49be-a87a-eeb2d7108127...\n",
      "Fetching observation data for time-00-58-16-679403_chatcmpl-0f2092b3-2608-4ac8-b057-13fa0e231dab...\n",
      "Fetching observation data for time-00-58-41-496536_chatcmpl-fd73607c-fef5-4a57-a348-48ace01986fe...\n",
      "Fetching observation data for time-00-59-06-503586_chatcmpl-47c3085a-98db-46c7-8967-e532e562e22c...\n",
      "Fetching observation data for time-00-59-31-125742_chatcmpl-ced8856a-5b65-4496-a7db-ff2f07cf22dc...\n",
      "Fetching observation data for d92f7a71-d143-44f3-9781-64f81b51433d...\n",
      "Fetching observation data for time-00-55-22-604467_chatcmpl-7e1cfbee-eca2-46d5-aeed-83f52f66d3d6...\n",
      "Fetching observation data for time-00-55-47-365080_chatcmpl-c9d89fe2-4abb-42b9-b350-e23925ed47fb...\n",
      "Fetching observation data for time-00-56-12-148577_chatcmpl-1199653a-981e-46b2-a499-371f344f913f...\n",
      "Fetching observation data for time-00-56-36-935469_chatcmpl-f16b7540-5157-446c-bbc8-3e81be2beca1...\n",
      "Fetching observation data for time-00-57-01-629992_chatcmpl-f0d4ce8b-1776-4162-814e-0dff5659c6ab...\n",
      "Fetching observation data for 8f55f102-0eff-4b0b-aee6-ef1262426826...\n",
      "Fetching observation data for time-00-52-51-757176_chatcmpl-5bc25655-aae3-4a30-8c44-e510fb4b05f9...\n",
      "Fetching observation data for time-00-53-16-517715_chatcmpl-4f895911-13a6-4c81-8372-3d40c6a8f24b...\n",
      "Fetching observation data for time-00-53-41-428191_chatcmpl-33c5a3b4-fde3-43d9-b841-af50f3b6ef45...\n",
      "Fetching observation data for time-00-54-06-360954_chatcmpl-ec6034c4-4756-4db7-bad8-4e250c967462...\n",
      "Fetching observation data for time-00-54-31-210785_chatcmpl-37e40a1f-12a9-4596-876f-b7f2227fab6d...\n",
      "Fetching observation data for 056e9030-29bd-46eb-8683-590be37805db...\n",
      "Fetching observation data for time-00-50-21-196846_chatcmpl-4d3a09ec-1fed-49c6-8420-27aaa8ffe54b...\n",
      "Fetching observation data for time-00-50-45-999045_chatcmpl-cee9f153-5837-4ef1-9bb5-a2158badf89f...\n",
      "Fetching observation data for time-00-51-11-072200_chatcmpl-6a3afc38-c2be-4d7d-98e8-e8a3424e2477...\n",
      "Fetching observation data for time-00-51-35-707969_chatcmpl-7bc02db9-57ce-4fb0-9ad9-74db529d52de...\n",
      "Fetching observation data for time-00-52-00-648616_chatcmpl-3dfa5948-7496-4c72-b4b0-68f8b8c6bd18...\n",
      "Fetching observation data for 9701d419-d23f-41c7-9d3a-162b4603f4a2...\n",
      "Fetching observation data for time-00-47-50-433172_chatcmpl-d6b01d61-f368-4251-b10b-c2f6de6090e9...\n",
      "Fetching observation data for time-00-48-15-202845_chatcmpl-226070dd-a633-48a4-a179-36938124fe8c...\n",
      "Fetching observation data for time-00-48-39-948951_chatcmpl-73e4f70f-8f4b-4961-b174-5908d376ad1a...\n",
      "Fetching observation data for time-00-49-04-918370_chatcmpl-612376a3-6c54-4b0f-9ee7-bbb4ef02e061...\n",
      "Fetching observation data for time-00-49-29-757141_chatcmpl-12835a76-9f80-4407-9322-d7656cbd550b...\n",
      "Fetching observation data for c588f080-0f61-448b-90e2-3828e90a47bd...\n",
      "Fetching observation data for time-00-45-20-036481_chatcmpl-0ccddba9-dc31-4d84-87b7-276e2ce22808...\n",
      "Fetching observation data for time-00-45-44-831472_chatcmpl-176d82b0-dda5-472a-a656-8a4a54bc0f55...\n",
      "Fetching observation data for time-00-46-09-689268_chatcmpl-42c15efc-8d83-4baa-bdb4-0cf00dc7b3be...\n",
      "Fetching observation data for time-00-46-34-584992_chatcmpl-f0daa12a-f530-48a5-86e6-ec4d8f3467e4...\n",
      "Fetching observation data for time-00-46-59-545339_chatcmpl-14d9e4e5-189b-4d9b-b0b6-620e62414a47...\n",
      "Fetching observation data for c7261626-e847-4b6c-8bc0-612bd981318e...\n",
      "Fetching observation data for time-00-42-49-524768_chatcmpl-570ba27d-a9bf-4e85-ad09-a8137b8e1bdc...\n",
      "Fetching observation data for time-00-43-14-493864_chatcmpl-72c914fb-d39c-4f24-b396-a7166f769a6c...\n",
      "Fetching observation data for time-00-43-39-311883_chatcmpl-7c768da0-0e73-44a5-9f31-60c517dbbf79...\n",
      "Fetching observation data for time-00-44-04-151879_chatcmpl-862ead40-6438-4531-bfc8-e17c4d6e70fc...\n",
      "Fetching observation data for time-00-44-28-905858_chatcmpl-dcfe5bc5-2b78-44e0-83b8-6fff30463d6c...\n",
      "Fetching observation data for c14c2c11-b211-4816-a802-947b8cf759dc...\n",
      "Fetching observation data for time-00-40-19-163541_chatcmpl-357f072e-003a-4bc2-af45-d52114ad1f0b...\n",
      "Fetching observation data for time-00-40-43-932496_chatcmpl-e6694295-b962-4527-8374-f743dca572b3...\n",
      "Fetching observation data for time-00-41-09-148123_chatcmpl-dda62186-41e5-4fbc-8f4c-049b8a25221c...\n",
      "Fetching observation data for time-00-41-33-930067_chatcmpl-d9c8b976-573f-4a7b-8a5d-39c33b253847...\n",
      "Fetching observation data for time-00-41-58-925781_chatcmpl-28f8f621-6bf8-4135-b19a-4989c244def7...\n",
      "Fetching observation data for b4f99e12-d9a1-4626-85c2-3897788010aa...\n",
      "Fetching observation data for time-00-37-48-704856_chatcmpl-bc83d41b-780f-43c6-8b1a-f35cd0c1256e...\n",
      "Fetching observation data for time-00-38-13-623285_chatcmpl-f6f6720c-7f47-46d3-9c34-fb504b0993db...\n",
      "Fetching observation data for time-00-38-38-476557_chatcmpl-59b4d81f-7bc7-4e0f-9e86-74720301f915...\n",
      "Fetching observation data for time-00-39-03-356881_chatcmpl-09b18765-ddd8-468c-8dc9-d3fb5b6d9edf...\n",
      "Fetching observation data for time-00-39-28-124652_chatcmpl-05bbb76e-0e62-4211-900b-bc64159a0f3f...\n",
      "Fetching observation data for 17777c2e-6cc3-4f8f-95c7-2d9d3bd49889...\n",
      "Fetching observation data for time-00-35-18-265383_chatcmpl-924e5aa4-50e6-4844-bd4d-bb2076cf89e4...\n",
      "Fetching observation data for time-00-35-43-669148_chatcmpl-40fb79de-47d9-48bf-9e74-73dae49bbceb...\n",
      "Fetching observation data for time-00-36-08-937484_chatcmpl-0f5473e9-dfd6-4faa-bf25-e52b608a349a...\n",
      "Fetching observation data for time-00-36-33-643839_chatcmpl-1560bb18-9544-4740-bfcc-9edbfe153f78...\n",
      "Fetching observation data for time-00-36-58-381537_chatcmpl-da5e0f14-689d-4b77-8a30-cd9b2d666c60...\n",
      "Fetching observation data for 33eee769-404e-4985-858d-ed7112d30a2d...\n",
      "Fetching observation data for time-00-32-47-821827_chatcmpl-eac282d9-2d76-4b98-910e-f7df1b0afce6...\n",
      "Fetching observation data for time-00-33-12-731997_chatcmpl-d3e91426-8069-4bc0-857d-08a1b88c0da1...\n",
      "Fetching observation data for time-00-33-37-485040_chatcmpl-af77875e-3704-4d14-858e-3e4b13e0c985...\n",
      "Fetching observation data for time-00-34-02-629521_chatcmpl-376b436f-765d-4a18-bbe7-f3f938e45945...\n",
      "Fetching observation data for time-00-34-27-446582_chatcmpl-3de89025-cf6f-44f4-8dcb-ebc945e673ba...\n",
      "Fetching observation data for 48109037-2907-4eac-b2d2-9377ac8db649...\n",
      "Fetching observation data for time-00-30-17-293578_chatcmpl-3df60f94-a701-4670-a2f1-3d7116e9c8a2...\n",
      "Fetching observation data for time-00-30-42-291588_chatcmpl-fe0af023-e1a9-4f1a-9463-19c760ee1a16...\n",
      "Fetching observation data for time-00-31-07-522996_chatcmpl-52a9eef0-f2d2-43a4-9e42-10fc89e32e7c...\n",
      "Fetching observation data for time-00-31-32-444150_chatcmpl-ed5e21a0-df1b-4cdb-929f-1da00333214e...\n",
      "Fetching observation data for time-00-31-57-140050_chatcmpl-86a3c03e-ba90-4231-b3fd-87f53c6fda5f...\n",
      "Fetching observation data for 7e9e028c-0e94-4f9e-a3b9-996e785c0fd9...\n",
      "Fetching observation data for time-00-27-46-780801_chatcmpl-1fe85f6d-c027-46d5-bdf7-715aa4474cde...\n",
      "Fetching observation data for time-00-28-11-887228_chatcmpl-dadaad60-1c00-4085-b6c7-aa04b999557f...\n",
      "Fetching observation data for time-00-28-36-589564_chatcmpl-e6b51bb5-7b10-4a2d-8f83-912bded4e2fa...\n",
      "Fetching observation data for time-00-29-01-776674_chatcmpl-2f48a4a7-d873-476e-9679-8b82f1b26304...\n",
      "Fetching observation data for time-00-29-26-498672_chatcmpl-ef3ecae6-366c-49dc-b267-6fcd22c2aede...\n",
      "Fetching observation data for 48b63bd6-ef91-4ec0-809b-025bf89b3206...\n",
      "Fetching observation data for time-00-25-16-248612_chatcmpl-fdd02505-228e-45c2-bc1f-790b1ba19fdc...\n",
      "Fetching observation data for time-00-25-41-261581_chatcmpl-7a5a17be-7bed-40ef-8263-af0887e0a28c...\n",
      "Fetching observation data for time-00-26-06-290726_chatcmpl-39e39643-37d4-4be0-b7ab-488b76bd12ab...\n",
      "Fetching observation data for time-00-26-30-938014_chatcmpl-5e464b56-e815-4edc-bebc-47965c00d778...\n",
      "Fetching observation data for time-00-26-55-604950_chatcmpl-0f2eef2e-d975-4191-9446-09542bdf33fc...\n",
      "Fetching observation data for 99cc7729-80fb-4d36-b71a-87dd05e29730...\n",
      "Fetching observation data for time-00-22-45-719749_chatcmpl-718fe752-115a-4055-a124-37a72871e27f...\n",
      "Fetching observation data for time-00-23-10-737744_chatcmpl-f01776ca-0360-4213-b944-b8faccc14cfd...\n",
      "Fetching observation data for time-00-23-35-514382_chatcmpl-d728aef8-753c-4dd4-a0e5-00b23bc31333...\n",
      "Fetching observation data for time-00-24-00-351097_chatcmpl-eddb8284-87f3-459c-a946-a549ff8a6f1d...\n",
      "Fetching observation data for time-00-24-25-100293_chatcmpl-68fbc73c-5667-4333-9460-27484b1cea23...\n",
      "Fetching observation data for 51c389e0-2b84-4d40-8142-bbad662c0c8f...\n",
      "Fetching observation data for time-00-20-15-207132_chatcmpl-d6bbf5ad-226f-4559-8bea-576d4f05b7f2...\n",
      "Fetching observation data for time-00-20-40-154129_chatcmpl-86af4b07-160e-45a9-a6ec-f2bc878342c4...\n",
      "Fetching observation data for time-00-21-05-097489_chatcmpl-e2f7754b-6169-4668-8ed4-b57b5b552d54...\n",
      "Fetching observation data for time-00-21-29-870113_chatcmpl-3f8f1a2e-abd9-4b70-a119-b1e93993ad14...\n",
      "Fetching observation data for time-00-21-54-583151_chatcmpl-eb79634f-2d10-43f7-8113-6f7236a9ff68...\n",
      "Fetching observation data for 37fac728-3887-4f2f-911c-9d321eacaaeb...\n",
      "Raw JSON saved to: /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/raw_export/raw_qwen2.5-coder:32b_0d8f_tpusg_batch.json\n",
      "Fetching traces for session qwen2.5-coder:32b_0d8f_sg_batch...\n",
      "Fetching observation data for time-03-46-46-751655_chatcmpl-e40bfe99-c7e1-4208-8c15-7651ace0a067...\n",
      "Fetching observation data for time-03-46-52-660552_chatcmpl-673952e2-889e-4eb1-a734-7987bfe8c01c...\n",
      "Fetching observation data for time-03-47-41-566705_chatcmpl-6b3c3614-a05a-43bd-b4d3-966b53cb47c4...\n",
      "Fetching observation data for time-03-48-29-597586_chatcmpl-051783fb-9e27-411d-80ec-b94b1c7dfdab...\n",
      "Fetching observation data for time-03-49-17-705421_chatcmpl-0bccf1d8-0a09-4d71-b116-22a172f7e274...\n",
      "Fetching observation data for time-03-50-05-737466_chatcmpl-764f8f79-43b2-4252-b84d-5b525546d948...\n",
      "Fetching observation data for 9197788d-830a-46b5-80a3-fc82255bce5f...\n",
      "Fetching observation data for time-03-42-15-318416_chatcmpl-9255eac3-b2d3-45dc-b168-f7da6555b577...\n",
      "Fetching observation data for time-03-42-20-963966_chatcmpl-1ce14303-e8e0-4604-97ac-9380ae9da2a4...\n",
      "Fetching observation data for time-03-43-08-931710_chatcmpl-89b5fb8c-8725-43f6-bcad-d53298dba452...\n",
      "Fetching observation data for time-03-43-56-909173_chatcmpl-a6a0ec77-9229-422e-b263-2040854d0592...\n",
      "Fetching observation data for time-03-44-44-946819_chatcmpl-cdfedaff-1575-4ccc-9be6-5abff10477eb...\n",
      "Fetching observation data for time-03-45-32-857868_chatcmpl-09920410-c657-4c92-801d-61e455e53f6a...\n",
      "Fetching observation data for 1b9d5a27-b7bc-4982-939f-723c6bc19c14...\n",
      "Fetching observation data for time-03-37-42-777756_chatcmpl-b0af91cb-2a73-4d45-994e-82306811ab8d...\n",
      "Fetching observation data for time-03-37-48-443457_chatcmpl-c92e30f5-d01c-4aa5-871a-3d6734f048b3...\n",
      "Fetching observation data for time-03-38-36-879662_chatcmpl-d9f25c7d-5dff-4619-ab0a-154efeeccd3e...\n",
      "Fetching observation data for time-03-39-25-155403_chatcmpl-d514d397-9670-423a-a10f-b3833b254a6c...\n",
      "Fetching observation data for time-03-40-13-264650_chatcmpl-488afd17-b240-48f2-8545-7f1c0088a437...\n",
      "Fetching observation data for time-03-41-01-048004_chatcmpl-ff185420-fafa-4abb-a6fd-1189e4e2a7d5...\n",
      "Fetching observation data for 377e8f62-8692-446c-8494-2ca04cad99a9...\n",
      "Fetching observation data for time-03-33-08-277589_chatcmpl-d1239df6-0a31-45ea-8569-eb3badf6ffa2...\n",
      "Fetching observation data for time-03-33-13-931489_chatcmpl-12659c7a-1a75-4f06-90af-791bc79bf5fe...\n",
      "Fetching observation data for time-03-34-02-772324_chatcmpl-44288064-ff56-43e4-ae86-9547afe08cc8...\n",
      "Fetching observation data for time-03-34-51-228636_chatcmpl-3a9dd79f-eff5-47b2-8608-685f5bb4ae3f...\n",
      "Fetching observation data for time-03-35-39-578598_chatcmpl-4d25b941-ddcd-4d9b-99a8-2f34efda6136...\n",
      "Fetching observation data for time-03-36-28-059710_chatcmpl-fef9d21b-f9cd-4e32-8ae5-4d113a4379a4...\n",
      "Fetching observation data for cbb1ef65-c833-4be3-b728-dd2f00ab18c3...\n",
      "Fetching observation data for time-03-28-34-771640_chatcmpl-f692c6a4-e65b-4dd5-808a-9d83de060534...\n",
      "Fetching observation data for time-03-28-40-673808_chatcmpl-3a51a87e-ba79-453e-95c2-10a1b2032b3e...\n",
      "Fetching observation data for time-03-29-28-777004_chatcmpl-98f27007-e3ce-46c2-b993-edeba79b3d74...\n",
      "Fetching observation data for time-03-30-16-650379_chatcmpl-eb561a0e-da3a-4486-b643-1d3790c4926e...\n",
      "Fetching observation data for time-03-31-04-727243_chatcmpl-c9fa4ff6-a61c-41f8-9fab-13e18a907d91...\n",
      "Fetching observation data for time-03-31-52-586407_chatcmpl-910a757e-9f66-465e-878e-a053a6d37e4e...\n",
      "Fetching observation data for 88bc226b-8e98-416b-8c8e-dccf1f5ff710...\n",
      "Fetching observation data for time-03-24-03-336514_chatcmpl-6e2e97e8-180b-492a-a493-2e2d6e50f62a...\n",
      "Fetching observation data for time-03-24-09-027780_chatcmpl-faf6b335-1d2a-4020-9674-ac3d2df1ce26...\n",
      "Fetching observation data for time-03-24-57-290171_chatcmpl-afb12784-6eaf-44d1-9322-2173f29ac670...\n",
      "Fetching observation data for time-03-25-45-449154_chatcmpl-69feaa91-fe53-4e7d-9a26-d1165367b453...\n",
      "Fetching observation data for time-03-26-33-373010_chatcmpl-794001ff-308d-423a-9150-ffa134367455...\n",
      "Fetching observation data for time-03-27-21-353001_chatcmpl-d959c2de-5512-4540-8551-4561d5b6360b...\n",
      "Fetching observation data for 49d6dd6c-2bbc-46d0-b0eb-168cbea1237f...\n",
      "Fetching observation data for time-03-19-30-849310_chatcmpl-45e3e085-b00c-4b1f-93c5-72336494f3cf...\n",
      "Fetching observation data for time-03-19-36-506966_chatcmpl-d8a0647e-7468-4da3-ac0f-c6ebdb3ecb03...\n",
      "Fetching observation data for time-03-20-24-803079_chatcmpl-b4859385-56d6-4813-8d55-eaa3632376b5...\n",
      "Fetching observation data for time-03-21-12-944728_chatcmpl-9bc21a34-b96f-4e6d-82e0-7da4dfbe2a01...\n",
      "Fetching observation data for time-03-22-01-097327_chatcmpl-de8196b1-b323-4fcf-b96e-dbd40ec2303b...\n",
      "Fetching observation data for time-03-22-49-077050_chatcmpl-03d6ef0d-1a12-4580-ae07-b7e6d48f0da3...\n",
      "Fetching observation data for bedd733a-30ac-4a6a-91a7-cbc7df44b558...\n",
      "Fetching observation data for time-03-14-58-375722_chatcmpl-d5ea836a-0a9c-4da5-8828-affa83f406d3...\n",
      "Fetching observation data for time-03-15-04-045183_chatcmpl-4544ddea-2a6e-4032-80f8-a94d5059a4ca...\n",
      "Fetching observation data for time-03-15-52-915189_chatcmpl-cf80957c-c1ed-441f-a51d-50eba977800c...\n",
      "Fetching observation data for time-03-16-41-132788_chatcmpl-a75f2516-a3ba-44fa-819d-0b2d835879fb...\n",
      "Fetching observation data for time-03-17-29-315038_chatcmpl-6737559f-4a18-4dc1-ab75-1cf81d880b01...\n",
      "Fetching observation data for time-03-18-17-266651_chatcmpl-67e2221d-1686-4a9d-895d-a584091f4c6b...\n",
      "Fetching observation data for 1ba3be43-be83-4a55-a0a2-93b7017b775b...\n",
      "Fetching observation data for time-03-10-25-866795_chatcmpl-6695f1b2-e2e5-4fe6-924a-67ce7bc4bff6...\n",
      "Fetching observation data for time-03-10-31-559375_chatcmpl-f2626722-bd0f-44b1-8428-d7bd3e921874...\n",
      "Fetching observation data for time-03-11-20-353911_chatcmpl-24cef19b-67ee-43d9-805d-de5642e05aad...\n",
      "Fetching observation data for time-03-12-08-367310_chatcmpl-d7327fd5-c35e-43c4-ace5-ee5dfd4fc1d1...\n",
      "Fetching observation data for time-03-12-56-408801_chatcmpl-a1aa41f1-4daf-4c0f-b73a-d51d1feae8df...\n",
      "Fetching observation data for time-03-13-44-282188_chatcmpl-9f4e1d0d-6a48-4680-84a0-593a050a3c33...\n",
      "Fetching observation data for 3403bbd5-95ef-47a8-97ff-6ad3cd2dc128...\n",
      "Fetching observation data for time-03-05-53-431315_chatcmpl-fe59837d-aacc-4b21-b1ec-ad0df762e813...\n",
      "Fetching observation data for time-03-05-59-162730_chatcmpl-b3331ad1-616f-4fdd-a5e7-1d62b6dcff04...\n",
      "Fetching observation data for time-03-06-47-874554_chatcmpl-cb4b8056-061a-4a7f-8d43-9d9359b04e19...\n",
      "Fetching observation data for time-03-07-36-092383_chatcmpl-fd9666b8-be5f-464c-bdf8-7e8de8591809...\n",
      "Fetching observation data for time-03-08-24-164233_chatcmpl-eaf7c423-be56-4c08-824b-566f18a3b227...\n",
      "Fetching observation data for time-03-09-11-992339_chatcmpl-72b63e45-0e66-4bbf-9a5c-f8dd3b767d6b...\n",
      "Fetching observation data for e08a542d-3b41-40bf-b92c-fb3b6761492e...\n",
      "Fetching observation data for time-03-01-20-905546_chatcmpl-aab63897-ac25-4b37-abbc-4e833a3ff800...\n",
      "Fetching observation data for time-03-01-26-599662_chatcmpl-5d098529-65a5-496f-9ef3-94ecd23826e4...\n",
      "Fetching observation data for time-03-02-15-078333_chatcmpl-a4fde492-bda9-4d2c-a765-35fcff7f137a...\n",
      "Fetching observation data for time-03-03-03-170774_chatcmpl-1b2304ba-ac5c-4309-8ed7-66a30058260b...\n",
      "Fetching observation data for time-03-03-51-373422_chatcmpl-c2b29f76-93cd-4a46-ab9a-e76b7bfc3b31...\n",
      "Fetching observation data for time-03-04-39-244505_chatcmpl-f38ee009-6131-4852-b3c4-b667db31a211...\n",
      "Fetching observation data for dcb8c3e6-5f76-4714-8922-1433eb4a8ec1...\n",
      "Fetching observation data for time-02-56-48-434221_chatcmpl-a9c20686-53ee-44cb-99fb-594d22c13118...\n",
      "Fetching observation data for time-02-56-54-045809_chatcmpl-91d52b44-8f8b-4084-9404-a5d051857be2...\n",
      "Fetching observation data for time-02-57-42-723196_chatcmpl-8a1174fa-a012-44b5-abc4-3620a3ed143a...\n",
      "Fetching observation data for time-02-58-30-681513_chatcmpl-8b38ce87-c483-4d22-95a7-dc54ac856ec1...\n",
      "Fetching observation data for time-02-59-18-766788_chatcmpl-d143f30e-60ad-4659-80d4-3e6c977d0489...\n",
      "Fetching observation data for time-03-00-07-073420_chatcmpl-fe77cafe-9ea9-4ec7-93f7-c25c39fdb2b7...\n",
      "Fetching observation data for 47289b3d-2914-4fc2-8a1d-2f21b379935e...\n",
      "Fetching observation data for time-02-52-16-904081_chatcmpl-aae7f61f-9451-4ba2-9894-b57f3fa9f476...\n",
      "Fetching observation data for time-02-52-22-549451_chatcmpl-100ed4bb-abe5-44be-aa91-44ec7c6e0209...\n",
      "Fetching observation data for time-02-53-11-029538_chatcmpl-1f102a8b-8ec7-4b54-87f5-273b2e23e55b...\n",
      "Fetching observation data for time-02-53-59-071706_chatcmpl-92d45147-1744-4464-be03-da3b782b5a86...\n",
      "Fetching observation data for time-02-54-47-003361_chatcmpl-6e7c0b62-feb2-4f59-a617-c87ff173c026...\n",
      "Fetching observation data for time-02-55-35-039841_chatcmpl-93c477fb-9410-488c-b2a2-c23ad9c2c635...\n",
      "Fetching observation data for 5348736d-9eb8-49fb-a863-68cae890c003...\n",
      "Fetching observation data for time-02-47-44-482724_chatcmpl-0807bf8b-6152-4fa6-8f66-feb1e0fef31d...\n",
      "Fetching observation data for time-02-47-50-153231_chatcmpl-70e524a4-4441-4fdf-b2e4-5a54a5b7e92d...\n",
      "Fetching observation data for time-02-48-38-404800_chatcmpl-9265b233-d6fa-4ccf-ba8b-f9e23adc6d1e...\n",
      "Fetching observation data for time-02-49-26-504813_chatcmpl-a9cf8147-d406-4442-ae19-4b3da5152904...\n",
      "Fetching observation data for time-02-50-14-399361_chatcmpl-4bf66ebe-1edc-460f-93bc-d18d16b0fa68...\n",
      "Fetching observation data for time-02-51-02-499658_chatcmpl-efe27390-97af-4a6f-ab80-1d4e8dadc55e...\n",
      "Fetching observation data for 5f1d6fe9-a32f-4160-b6a7-616a59cb47fd...\n",
      "Fetching observation data for time-02-43-13-026468_chatcmpl-99dedf48-98d3-4fed-88a7-cce68cff636b...\n",
      "Fetching observation data for time-02-43-18-690053_chatcmpl-71a86902-2ad2-4898-96e6-f27df268a20b...\n",
      "Fetching observation data for time-02-44-06-905028_chatcmpl-99fab635-77f8-4165-ab27-f3cb13ba4833...\n",
      "Fetching observation data for time-02-44-54-966917_chatcmpl-3bdddd37-94d0-4414-8c21-9c7bb01d64c7...\n",
      "Fetching observation data for time-02-45-43-575410_chatcmpl-375f5449-1c0b-42da-bc65-e5584fe30b2e...\n",
      "Fetching observation data for time-02-46-31-702333_chatcmpl-bb897dfa-4a05-417f-8093-fa5841cd13dc...\n",
      "Fetching observation data for 84090c25-fc92-4e57-b367-3c8ca5cd53d3...\n",
      "Fetching observation data for time-02-38-41-464491_chatcmpl-d2d649db-f413-4edd-a0fd-ab5768cf31dc...\n",
      "Fetching observation data for time-02-38-47-085345_chatcmpl-d0b6f1aa-4347-409c-b567-8bd7d3422af0...\n",
      "Fetching observation data for time-02-39-35-508672_chatcmpl-a2fcd73f-750d-4fe7-934f-a506445b7a5a...\n",
      "Fetching observation data for time-02-40-23-464343_chatcmpl-0e957c5b-84fe-4645-9864-1df839762b14...\n",
      "Fetching observation data for time-02-41-11-390801_chatcmpl-fd9bd025-1378-46ac-845f-e76bdb69a697...\n",
      "Fetching observation data for time-02-41-59-324487_chatcmpl-c7458931-b102-4b0b-9d38-3792194ce323...\n",
      "Fetching observation data for bfbc07f4-2728-4dac-9138-1e81a87858b8...\n",
      "Fetching observation data for time-02-34-09-984917_chatcmpl-058ca895-d4ce-4e9a-9aeb-e99af229740e...\n",
      "Fetching observation data for time-02-34-15-655014_chatcmpl-014a08a1-dcb7-4db2-ae01-0ae595e1d679...\n",
      "Fetching observation data for time-02-35-04-273871_chatcmpl-c30a0eb2-e663-49ba-9857-5e0768a4c756...\n",
      "Fetching observation data for time-02-35-52-281202_chatcmpl-ecde3ad6-365d-40d7-b705-e92f3b1427aa...\n",
      "Fetching observation data for time-02-36-40-133816_chatcmpl-01309740-f370-4478-8fb0-e9abda9061c9...\n",
      "Fetching observation data for time-02-37-28-010715_chatcmpl-6003fe31-adf9-4090-a530-71c1b7c90716...\n",
      "Fetching observation data for a1238170-ff83-42bd-99c8-d11fccf38a65...\n",
      "Fetching observation data for time-02-29-37-523935_chatcmpl-5ad69de2-0815-4a24-ae83-f07fee8998ee...\n",
      "Fetching observation data for time-02-29-43-141086_chatcmpl-82a1cd82-8cef-4535-be00-5152c36eb313...\n",
      "Fetching observation data for time-02-30-31-545674_chatcmpl-e9c025ff-8c8b-4666-8225-0f6f0e2420f0...\n",
      "Fetching observation data for time-02-31-19-786318_chatcmpl-ce814689-ddcd-4110-bafe-0f6b46933593...\n",
      "Fetching observation data for time-02-32-07-979406_chatcmpl-f0f78510-b7e3-4a56-9f9e-45c3fec4999b...\n",
      "Fetching observation data for time-02-32-55-922540_chatcmpl-5197dde5-6b1b-4b6f-b090-e89d2778d89b...\n",
      "Fetching observation data for 996a8244-5bbc-4be6-9f4e-2426f57774fc...\n",
      "Fetching observation data for time-02-25-04-994074_chatcmpl-eba1c1a5-221f-472d-a979-b0c43f52af00...\n",
      "Fetching observation data for time-02-25-10-733670_chatcmpl-b6e11b5f-8e41-44d6-b92b-10c16b26d071...\n",
      "Fetching observation data for time-02-25-59-121662_chatcmpl-4eb55c02-d99b-4881-9322-4cfa2c7c4f2a...\n",
      "Fetching observation data for time-02-26-46-956234_chatcmpl-6f0da5eb-fd6d-4dbf-9742-93d864531146...\n",
      "Fetching observation data for time-02-27-35-235925_chatcmpl-9b40b823-b138-4458-bb36-6e1a1026235f...\n",
      "Fetching observation data for time-02-28-23-444986_chatcmpl-4506750c-d5ec-418c-b5b6-3f1de1d3aa99...\n",
      "Fetching observation data for 1413a5c5-8841-480e-92f6-5eae4510d0f7...\n",
      "Fetching observation data for time-02-20-32-428862_chatcmpl-c3734771-4f98-40cf-9fba-ea2555c4d0da...\n",
      "Fetching observation data for time-02-20-38-158141_chatcmpl-4efce5df-2292-4aa7-926a-519dd496e2a6...\n",
      "Fetching observation data for time-02-21-26-542498_chatcmpl-3b2458b5-f266-40c4-8ca8-7a207c564135...\n",
      "Fetching observation data for time-02-22-14-459357_chatcmpl-5a7992a6-b984-4263-9635-dfda1158390d...\n",
      "Fetching observation data for time-02-23-02-875593_chatcmpl-5b52ea9e-338e-428b-bff7-87fb6f974b21...\n",
      "Fetching observation data for time-02-23-51-173945_chatcmpl-ccd89eac-ab11-4674-bc0f-a8f2825ce778...\n",
      "Fetching observation data for e000222d-5beb-4302-b3ac-0aebe34b79b9...\n",
      "Fetching observation data for time-02-15-59-002366_chatcmpl-0ce8fc29-e75b-4d38-aa7d-4a1095ce07ff...\n",
      "Fetching observation data for time-02-16-04-873491_chatcmpl-a917e5f1-229b-4db5-b0c8-2e41b4e36d87...\n",
      "Fetching observation data for time-02-16-53-345949_chatcmpl-727fd234-5557-4891-8785-9ab86ad4f25b...\n",
      "Fetching observation data for time-02-17-41-889898_chatcmpl-b4e983f4-bb65-41dc-9212-eb1ce8766e66...\n",
      "Fetching observation data for time-02-18-30-042579_chatcmpl-469f845a-6f51-4595-ae4e-7161a51429f5...\n",
      "Fetching observation data for time-02-19-18-355575_chatcmpl-b46e0564-641d-400f-997c-0d1965e9ff68...\n",
      "Fetching observation data for 8fa2d380-02cd-48dc-b395-664350dfb90c...\n",
      "Fetching observation data for time-02-11-26-439486_chatcmpl-378c4057-1aae-4660-9637-864c59a9ac46...\n",
      "Fetching observation data for time-02-11-32-056203_chatcmpl-15f3c601-ca79-4ac7-b403-8f275cdf568e...\n",
      "Fetching observation data for time-02-12-20-545923_chatcmpl-149f210b-af97-4543-bac4-4d9519f1fd0e...\n",
      "Fetching observation data for time-02-13-08-476985_chatcmpl-03e724b4-9cdd-449a-a1f0-a4db732b770f...\n",
      "Fetching observation data for time-02-13-56-773695_chatcmpl-58d294e6-3c8e-4173-a675-ddbf5c6d0737...\n",
      "Fetching observation data for time-02-14-45-080450_chatcmpl-f717bb3f-c902-4114-a5c7-aae82a98418c...\n",
      "Fetching observation data for e6f820a4-aadb-460d-b238-1af0faf91e49...\n",
      "Fetching observation data for time-02-06-54-900579_chatcmpl-4f1873c3-d6d3-4a4c-bf20-1105a02464eb...\n",
      "Fetching observation data for time-02-07-00-501237_chatcmpl-ba9662ef-162c-4c6b-a877-73576e051ea0...\n",
      "Fetching observation data for time-02-07-48-774687_chatcmpl-943df810-f969-4fc4-b1fe-ede81d157d0a...\n",
      "Fetching observation data for time-02-08-36-802823_chatcmpl-3a8cda25-dfed-47bd-bbbb-bc345edf9675...\n",
      "Fetching observation data for time-02-09-25-199260_chatcmpl-92b73b71-be30-4e13-a862-ee61935da424...\n",
      "Fetching observation data for time-02-10-13-384619_chatcmpl-38a15b4e-2695-4bae-9c25-95f27fb5f46e...\n",
      "Fetching observation data for ee81a296-c85d-4a06-9fd7-bf024649608d...\n",
      "Fetching observation data for time-02-02-22-300713_chatcmpl-07a2dea4-35b2-4bdd-90a7-60da67c5babc...\n",
      "Fetching observation data for time-02-02-28-048151_chatcmpl-33a04210-8ebf-41b3-b254-687794f397ef...\n",
      "Fetching observation data for time-02-03-16-483149_chatcmpl-8e5416f2-0af6-4ffc-a383-b60e7664873e...\n",
      "Fetching observation data for time-02-04-04-829768_chatcmpl-a44beca8-d7f7-4425-a51c-aa10165f979d...\n",
      "Fetching observation data for time-02-04-53-308471_chatcmpl-a8911463-79b4-428f-963e-b6d44078ed38...\n",
      "Fetching observation data for time-02-05-41-583726_chatcmpl-7c609ded-8a90-42e2-bd77-2e87c21d6974...\n",
      "Fetching observation data for f1f7a14e-5628-4a55-b5ab-4fa363a76706...\n",
      "Fetching observation data for time-01-57-49-767403_chatcmpl-c3ef7396-6dfb-4053-9729-430b6b4b3b68...\n",
      "Fetching observation data for time-01-57-55-404556_chatcmpl-503dbfc5-8eb3-4f62-ba92-b655da1078b6...\n",
      "Fetching observation data for time-01-58-43-677453_chatcmpl-6d2d48e9-a83d-4751-9386-68635882cdc6...\n",
      "Fetching observation data for time-01-59-31-813696_chatcmpl-5a89ec9e-e7ee-4836-8953-b5530875e525...\n",
      "Fetching observation data for time-02-00-19-840807_chatcmpl-8003abeb-c1ff-42cd-ad32-4f217ef93c5d...\n",
      "Fetching observation data for time-02-01-08-218725_chatcmpl-cdeb4af7-2bdc-4608-9951-48ba60101c36...\n",
      "Fetching observation data for b34d06d0-9a37-4319-bf38-855b86055b38...\n",
      "Fetching observation data for time-01-53-17-301428_chatcmpl-640b13db-302e-4790-8b72-eed0aad8ee2f...\n",
      "Fetching observation data for time-01-53-22-930465_chatcmpl-7facc475-7057-411f-8b3d-8e91302bb4d8...\n",
      "Fetching observation data for time-01-54-11-146586_chatcmpl-ea3b7c67-4993-4b7c-b182-6a966dc34ab9...\n",
      "Fetching observation data for time-01-54-59-220535_chatcmpl-ee846568-770c-46d7-a4e6-65a2e7b9db91...\n",
      "Fetching observation data for time-01-55-47-306987_chatcmpl-4faf4f6d-8ac1-4028-bc12-66e9f75c23f1...\n",
      "Fetching observation data for time-01-56-35-339227_chatcmpl-ac2c2694-2fa9-4c3a-9a04-0a548f81de37...\n",
      "Fetching observation data for f4b3e1cb-b52e-480a-9a60-5dbe6a706b37...\n",
      "Fetching observation data for time-01-48-44-584801_chatcmpl-b2ff7083-9125-4cc8-8585-23d9aeca762b...\n",
      "Fetching observation data for time-01-48-50-225931_chatcmpl-cc84d85a-e82c-43bd-ba0d-a4a5bc7a918b...\n",
      "Fetching observation data for time-01-49-38-943077_chatcmpl-be271490-cb26-4581-ab37-181a64d925a6...\n",
      "Fetching observation data for time-01-50-27-386304_chatcmpl-b556455a-93e6-4567-92c6-87f2ae288bcd...\n",
      "Fetching observation data for time-01-51-15-435463_chatcmpl-bc0df92c-230d-4525-a2ae-ec3ecaba5f06...\n",
      "Fetching observation data for time-01-52-03-541310_chatcmpl-937eb9f1-daa3-4b06-b059-8e0908565b73...\n",
      "Fetching observation data for d71f1fa3-f56e-4994-b63c-1ba0f0d96339...\n",
      "Fetching observation data for time-01-44-11-123993_chatcmpl-15a8355c-c702-41a1-930f-54622f39aa52...\n",
      "Fetching observation data for time-01-44-16-736607_chatcmpl-e11c5a55-2220-4c5d-bcca-123ca4973d8f...\n",
      "Fetching observation data for time-01-45-05-234797_chatcmpl-07ac3270-2a6f-474a-b626-dade4abf69fe...\n",
      "Fetching observation data for time-01-45-53-579088_chatcmpl-e3310efb-e868-4568-a37c-cb5d704fa8d8...\n",
      "Fetching observation data for time-01-46-41-930596_chatcmpl-b148fd43-17f0-416f-8834-93426b9ba546...\n",
      "Fetching observation data for time-01-47-30-372797_chatcmpl-4067231d-2c00-4bc6-b9ec-13d3705a2a2e...\n",
      "Fetching observation data for ddb9ca5a-9219-46c2-b773-0b72c910a071...\n",
      "Fetching observation data for time-01-39-38-561989_chatcmpl-5cb3e833-f7d4-45c2-bf6c-f152021bdd3f...\n",
      "Fetching observation data for time-01-39-44-171337_chatcmpl-50f4b6f6-9310-470b-9935-b9c7b2c322c2...\n",
      "Fetching observation data for time-01-40-32-631161_chatcmpl-7b1031e1-eead-4965-aa20-f5bb770ce987...\n",
      "Fetching observation data for time-01-41-20-646466_chatcmpl-89625b11-e409-4807-b440-516df735a18f...\n",
      "Fetching observation data for time-01-42-08-594307_chatcmpl-f6b1e0a8-4096-4ed3-bcc0-eb952ed1b543...\n",
      "Fetching observation data for time-01-42-56-692452_chatcmpl-1ea37461-8fb6-4351-bcc2-c2ff02a59331...\n",
      "Fetching observation data for 6a800ce9-bbbd-4406-8305-2c85aec65e41...\n",
      "Fetching observation data for time-01-35-04-907671_chatcmpl-8ad2c65d-37f7-419b-9b71-cef26a250a10...\n",
      "Fetching observation data for time-01-35-10-591302_chatcmpl-321aecaa-74e8-40f3-b862-9b1c422bbee3...\n",
      "Fetching observation data for time-01-35-59-699156_chatcmpl-b3693d47-3cf0-4c32-93e8-29fca6cbddda...\n",
      "Fetching observation data for time-01-36-47-880429_chatcmpl-aaa98bf0-7170-42e1-bf6c-a4505ab178ff...\n",
      "Fetching observation data for time-01-37-36-105866_chatcmpl-1a9ac549-6ed8-4a7b-8fba-4c0721074cec...\n",
      "Fetching observation data for time-01-38-24-244177_chatcmpl-2ee0a447-9645-4f7a-8494-d2a5e896f601...\n",
      "Fetching observation data for f788087b-5fdd-49cb-a284-a8c5878635e7...\n",
      "Raw JSON saved to: /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/raw_export/raw_qwen2.5-coder:32b_0d8f_sg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_3f_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260224000329_psg_qwen2.5-coder:32b/tmp_20260224000329_psg_qwen2.5-coder:32b.py\", line 72, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_d9_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223235741_psg_qwen2.5-coder:32b/tmp_20260223235741_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_62_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223235549_psg_qwen2.5-coder:32b/tmp_20260223235549_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_15_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223235358_psg_qwen2.5-coder:32b/tmp_20260223235358_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_75_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223235207_psg_qwen2.5-coder:32b/tmp_20260223235207_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_f6_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223235016_psg_qwen2.5-coder:32b/tmp_20260223235016_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_76_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223234824_psg_qwen2.5-coder:32b/tmp_20260223234824_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_6a_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223234631_psg_qwen2.5-coder:32b/tmp_20260223234631_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_4b_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223234439_psg_qwen2.5-coder:32b/tmp_20260223234439_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_45_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223234248_psg_qwen2.5-coder:32b/tmp_20260223234248_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_3e_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223234056_psg_qwen2.5-coder:32b/tmp_20260223234056_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_c0_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223233904_psg_qwen2.5-coder:32b/tmp_20260223233904_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_dc_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223233711_psg_qwen2.5-coder:32b/tmp_20260223233711_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_61_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223233520_psg_qwen2.5-coder:32b/tmp_20260223233520_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_33_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223233329_psg_qwen2.5-coder:32b/tmp_20260223233329_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_e8_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223233137_psg_qwen2.5-coder:32b/tmp_20260223233137_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_e3_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223232945_psg_qwen2.5-coder:32b/tmp_20260223232945_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_d0_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223232754_psg_qwen2.5-coder:32b/tmp_20260223232754_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:32b_0d8f_psg_batch\n",
      "SPAN error_45_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_48de1013_1771889688.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_ba_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_9175df8c_1771889539.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_ac_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_3227c1d0_1771889388.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_c0_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_c8a78f50_1771889238.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_98_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_3dd9e11d_1771889088.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_19_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_c8fa5432_1771888937.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_59_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_cd218fd5_1771888786.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_77_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_d9960907_1771888636.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_c0_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_aca6b3a6_1771888485.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_1a_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_0bddd004_1771888336.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_91_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_9468060a_1771888186.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_d5_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_46891d77_1771888036.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_02_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_b14da6aa_1771887886.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_2b_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_71f14c9f_1771887737.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_fc_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_ad6c5594_1771887587.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_93_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_777c8d86_1771887437.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_5e_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_2f1cff62_1771887287.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_2f_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_55938386_1771887136.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_47_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_8257591b_1771886985.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_c0_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_db1cb44c_1771886835.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_35_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_d270488e_1771886685.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_46_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_8bd8ba92_1771886535.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_73_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_32ba9f57_1771886384.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_fb_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_34c53149_1771886234.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_93_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_23a39bc0_1771886083.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_eb_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_ec7f58ae_1771885933.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_75_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_921504e0_1771885782.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_47_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_da702944_1771885631.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_31_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_3449643f_1771885481.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "SPAN error_0c_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_179889dd_1771885330.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(resized_frame))\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175..\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:32b_0d8f_tpusg_batch\n",
      "SPAN error_c6_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224035028_qwen2.5-coder:32b/compiling_20260224035028_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224035028_qwen2.5-coder:32b/compiling_20260224035028_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224035028_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224035028_qwen2.5-coder:32b/compiling_20260224035028_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224035028_qwen2.5-coder:32b/compiling_20260224035028_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224035028_qwen2.5-coder:32b/compiling_20260224035028_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224035028_qwen2.5-coder:32b/compiling_20260224035028_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224035028_qwen2.5-coder:32b/compiling_20260224035028_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224035028_qwen2.5-coder:32b/compiling_20260224035028_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224035028_qwen2.5-coder:32b/compiling_20260224035028_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_78_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034556_qwen2.5-coder:32b/compiling_20260224034556_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034556_qwen2.5-coder:32b/compiling_20260224034556_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034556_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034556_qwen2.5-coder:32b/compiling_20260224034556_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034556_qwen2.5-coder:32b/compiling_20260224034556_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034556_qwen2.5-coder:32b/compiling_20260224034556_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034556_qwen2.5-coder:32b/compiling_20260224034556_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034556_qwen2.5-coder:32b/compiling_20260224034556_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034556_qwen2.5-coder:32b/compiling_20260224034556_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034556_qwen2.5-coder:32b/compiling_20260224034556_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_9d_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034124_qwen2.5-coder:32b/compiling_20260224034124_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034124_qwen2.5-coder:32b/compiling_20260224034124_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034124_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034124_qwen2.5-coder:32b/compiling_20260224034124_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034124_qwen2.5-coder:32b/compiling_20260224034124_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034124_qwen2.5-coder:32b/compiling_20260224034124_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034124_qwen2.5-coder:32b/compiling_20260224034124_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034124_qwen2.5-coder:32b/compiling_20260224034124_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034124_qwen2.5-coder:32b/compiling_20260224034124_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224034124_qwen2.5-coder:32b/compiling_20260224034124_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_8a_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033651_qwen2.5-coder:32b/compiling_20260224033651_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033651_qwen2.5-coder:32b/compiling_20260224033651_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033651_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033651_qwen2.5-coder:32b/compiling_20260224033651_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033651_qwen2.5-coder:32b/compiling_20260224033651_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033651_qwen2.5-coder:32b/compiling_20260224033651_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033651_qwen2.5-coder:32b/compiling_20260224033651_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033651_qwen2.5-coder:32b/compiling_20260224033651_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033651_qwen2.5-coder:32b/compiling_20260224033651_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033651_qwen2.5-coder:32b/compiling_20260224033651_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_e0_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033215_qwen2.5-coder:32b/compiling_20260224033215_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033215_qwen2.5-coder:32b/compiling_20260224033215_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033215_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033215_qwen2.5-coder:32b/compiling_20260224033215_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033215_qwen2.5-coder:32b/compiling_20260224033215_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033215_qwen2.5-coder:32b/compiling_20260224033215_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033215_qwen2.5-coder:32b/compiling_20260224033215_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033215_qwen2.5-coder:32b/compiling_20260224033215_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033215_qwen2.5-coder:32b/compiling_20260224033215_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224033215_qwen2.5-coder:32b/compiling_20260224033215_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_34_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032744_qwen2.5-coder:32b/compiling_20260224032744_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032744_qwen2.5-coder:32b/compiling_20260224032744_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032744_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032744_qwen2.5-coder:32b/compiling_20260224032744_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032744_qwen2.5-coder:32b/compiling_20260224032744_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032744_qwen2.5-coder:32b/compiling_20260224032744_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032744_qwen2.5-coder:32b/compiling_20260224032744_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032744_qwen2.5-coder:32b/compiling_20260224032744_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032744_qwen2.5-coder:32b/compiling_20260224032744_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032744_qwen2.5-coder:32b/compiling_20260224032744_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_1c_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032312_qwen2.5-coder:32b/compiling_20260224032312_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032312_qwen2.5-coder:32b/compiling_20260224032312_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032312_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032312_qwen2.5-coder:32b/compiling_20260224032312_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032312_qwen2.5-coder:32b/compiling_20260224032312_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032312_qwen2.5-coder:32b/compiling_20260224032312_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032312_qwen2.5-coder:32b/compiling_20260224032312_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032312_qwen2.5-coder:32b/compiling_20260224032312_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032312_qwen2.5-coder:32b/compiling_20260224032312_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224032312_qwen2.5-coder:32b/compiling_20260224032312_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_10_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031840_qwen2.5-coder:32b/compiling_20260224031840_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031840_qwen2.5-coder:32b/compiling_20260224031840_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031840_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031840_qwen2.5-coder:32b/compiling_20260224031840_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031840_qwen2.5-coder:32b/compiling_20260224031840_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031840_qwen2.5-coder:32b/compiling_20260224031840_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031840_qwen2.5-coder:32b/compiling_20260224031840_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031840_qwen2.5-coder:32b/compiling_20260224031840_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031840_qwen2.5-coder:32b/compiling_20260224031840_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031840_qwen2.5-coder:32b/compiling_20260224031840_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_5d_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031407_qwen2.5-coder:32b/compiling_20260224031407_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031407_qwen2.5-coder:32b/compiling_20260224031407_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031407_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031407_qwen2.5-coder:32b/compiling_20260224031407_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031407_qwen2.5-coder:32b/compiling_20260224031407_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031407_qwen2.5-coder:32b/compiling_20260224031407_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031407_qwen2.5-coder:32b/compiling_20260224031407_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031407_qwen2.5-coder:32b/compiling_20260224031407_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031407_qwen2.5-coder:32b/compiling_20260224031407_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224031407_qwen2.5-coder:32b/compiling_20260224031407_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_75_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030935_qwen2.5-coder:32b/compiling_20260224030935_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030935_qwen2.5-coder:32b/compiling_20260224030935_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030935_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030935_qwen2.5-coder:32b/compiling_20260224030935_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030935_qwen2.5-coder:32b/compiling_20260224030935_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030935_qwen2.5-coder:32b/compiling_20260224030935_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030935_qwen2.5-coder:32b/compiling_20260224030935_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030935_qwen2.5-coder:32b/compiling_20260224030935_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030935_qwen2.5-coder:32b/compiling_20260224030935_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030935_qwen2.5-coder:32b/compiling_20260224030935_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_43_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030502_qwen2.5-coder:32b/compiling_20260224030502_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030502_qwen2.5-coder:32b/compiling_20260224030502_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030502_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030502_qwen2.5-coder:32b/compiling_20260224030502_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030502_qwen2.5-coder:32b/compiling_20260224030502_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030502_qwen2.5-coder:32b/compiling_20260224030502_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030502_qwen2.5-coder:32b/compiling_20260224030502_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030502_qwen2.5-coder:32b/compiling_20260224030502_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030502_qwen2.5-coder:32b/compiling_20260224030502_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030502_qwen2.5-coder:32b/compiling_20260224030502_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_31_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030030_qwen2.5-coder:32b/compiling_20260224030030_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030030_qwen2.5-coder:32b/compiling_20260224030030_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030030_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030030_qwen2.5-coder:32b/compiling_20260224030030_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030030_qwen2.5-coder:32b/compiling_20260224030030_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030030_qwen2.5-coder:32b/compiling_20260224030030_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030030_qwen2.5-coder:32b/compiling_20260224030030_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030030_qwen2.5-coder:32b/compiling_20260224030030_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030030_qwen2.5-coder:32b/compiling_20260224030030_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224030030_qwen2.5-coder:32b/compiling_20260224030030_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_98_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025558_qwen2.5-coder:32b/compiling_20260224025558_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025558_qwen2.5-coder:32b/compiling_20260224025558_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025558_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025558_qwen2.5-coder:32b/compiling_20260224025558_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025558_qwen2.5-coder:32b/compiling_20260224025558_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025558_qwen2.5-coder:32b/compiling_20260224025558_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025558_qwen2.5-coder:32b/compiling_20260224025558_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025558_qwen2.5-coder:32b/compiling_20260224025558_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025558_qwen2.5-coder:32b/compiling_20260224025558_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025558_qwen2.5-coder:32b/compiling_20260224025558_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_94_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025125_qwen2.5-coder:32b/compiling_20260224025125_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025125_qwen2.5-coder:32b/compiling_20260224025125_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025125_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025125_qwen2.5-coder:32b/compiling_20260224025125_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025125_qwen2.5-coder:32b/compiling_20260224025125_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025125_qwen2.5-coder:32b/compiling_20260224025125_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025125_qwen2.5-coder:32b/compiling_20260224025125_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025125_qwen2.5-coder:32b/compiling_20260224025125_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025125_qwen2.5-coder:32b/compiling_20260224025125_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224025125_qwen2.5-coder:32b/compiling_20260224025125_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_76_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024655_qwen2.5-coder:32b/compiling_20260224024655_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024655_qwen2.5-coder:32b/compiling_20260224024655_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024655_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024655_qwen2.5-coder:32b/compiling_20260224024655_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024655_qwen2.5-coder:32b/compiling_20260224024655_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024655_qwen2.5-coder:32b/compiling_20260224024655_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024655_qwen2.5-coder:32b/compiling_20260224024655_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024655_qwen2.5-coder:32b/compiling_20260224024655_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024655_qwen2.5-coder:32b/compiling_20260224024655_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024655_qwen2.5-coder:32b/compiling_20260224024655_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_d3_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024222_qwen2.5-coder:32b/compiling_20260224024222_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024222_qwen2.5-coder:32b/compiling_20260224024222_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024222_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024222_qwen2.5-coder:32b/compiling_20260224024222_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024222_qwen2.5-coder:32b/compiling_20260224024222_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024222_qwen2.5-coder:32b/compiling_20260224024222_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024222_qwen2.5-coder:32b/compiling_20260224024222_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024222_qwen2.5-coder:32b/compiling_20260224024222_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024222_qwen2.5-coder:32b/compiling_20260224024222_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224024222_qwen2.5-coder:32b/compiling_20260224024222_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_5f_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023751_qwen2.5-coder:32b/compiling_20260224023751_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023751_qwen2.5-coder:32b/compiling_20260224023751_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023751_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023751_qwen2.5-coder:32b/compiling_20260224023751_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023751_qwen2.5-coder:32b/compiling_20260224023751_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023751_qwen2.5-coder:32b/compiling_20260224023751_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023751_qwen2.5-coder:32b/compiling_20260224023751_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023751_qwen2.5-coder:32b/compiling_20260224023751_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023751_qwen2.5-coder:32b/compiling_20260224023751_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023751_qwen2.5-coder:32b/compiling_20260224023751_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_a1_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023319_qwen2.5-coder:32b/compiling_20260224023319_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023319_qwen2.5-coder:32b/compiling_20260224023319_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023319_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023319_qwen2.5-coder:32b/compiling_20260224023319_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023319_qwen2.5-coder:32b/compiling_20260224023319_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023319_qwen2.5-coder:32b/compiling_20260224023319_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023319_qwen2.5-coder:32b/compiling_20260224023319_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023319_qwen2.5-coder:32b/compiling_20260224023319_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023319_qwen2.5-coder:32b/compiling_20260224023319_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224023319_qwen2.5-coder:32b/compiling_20260224023319_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_03_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022846_qwen2.5-coder:32b/compiling_20260224022846_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022846_qwen2.5-coder:32b/compiling_20260224022846_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022846_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022846_qwen2.5-coder:32b/compiling_20260224022846_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022846_qwen2.5-coder:32b/compiling_20260224022846_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022846_qwen2.5-coder:32b/compiling_20260224022846_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022846_qwen2.5-coder:32b/compiling_20260224022846_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022846_qwen2.5-coder:32b/compiling_20260224022846_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022846_qwen2.5-coder:32b/compiling_20260224022846_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022846_qwen2.5-coder:32b/compiling_20260224022846_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_db_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022414_qwen2.5-coder:32b/compiling_20260224022414_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022414_qwen2.5-coder:32b/compiling_20260224022414_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022414_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022414_qwen2.5-coder:32b/compiling_20260224022414_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022414_qwen2.5-coder:32b/compiling_20260224022414_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022414_qwen2.5-coder:32b/compiling_20260224022414_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022414_qwen2.5-coder:32b/compiling_20260224022414_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022414_qwen2.5-coder:32b/compiling_20260224022414_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022414_qwen2.5-coder:32b/compiling_20260224022414_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224022414_qwen2.5-coder:32b/compiling_20260224022414_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_b5_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021941_qwen2.5-coder:32b/compiling_20260224021941_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021941_qwen2.5-coder:32b/compiling_20260224021941_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021941_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021941_qwen2.5-coder:32b/compiling_20260224021941_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021941_qwen2.5-coder:32b/compiling_20260224021941_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021941_qwen2.5-coder:32b/compiling_20260224021941_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021941_qwen2.5-coder:32b/compiling_20260224021941_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021941_qwen2.5-coder:32b/compiling_20260224021941_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021941_qwen2.5-coder:32b/compiling_20260224021941_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021941_qwen2.5-coder:32b/compiling_20260224021941_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_20_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021508_qwen2.5-coder:32b/compiling_20260224021508_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021508_qwen2.5-coder:32b/compiling_20260224021508_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021508_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021508_qwen2.5-coder:32b/compiling_20260224021508_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021508_qwen2.5-coder:32b/compiling_20260224021508_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021508_qwen2.5-coder:32b/compiling_20260224021508_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021508_qwen2.5-coder:32b/compiling_20260224021508_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021508_qwen2.5-coder:32b/compiling_20260224021508_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021508_qwen2.5-coder:32b/compiling_20260224021508_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021508_qwen2.5-coder:32b/compiling_20260224021508_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_51_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021036_qwen2.5-coder:32b/compiling_20260224021036_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021036_qwen2.5-coder:32b/compiling_20260224021036_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021036_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021036_qwen2.5-coder:32b/compiling_20260224021036_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021036_qwen2.5-coder:32b/compiling_20260224021036_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021036_qwen2.5-coder:32b/compiling_20260224021036_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021036_qwen2.5-coder:32b/compiling_20260224021036_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021036_qwen2.5-coder:32b/compiling_20260224021036_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021036_qwen2.5-coder:32b/compiling_20260224021036_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224021036_qwen2.5-coder:32b/compiling_20260224021036_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_1a_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020604_qwen2.5-coder:32b/compiling_20260224020604_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020604_qwen2.5-coder:32b/compiling_20260224020604_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020604_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020604_qwen2.5-coder:32b/compiling_20260224020604_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020604_qwen2.5-coder:32b/compiling_20260224020604_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020604_qwen2.5-coder:32b/compiling_20260224020604_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020604_qwen2.5-coder:32b/compiling_20260224020604_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020604_qwen2.5-coder:32b/compiling_20260224020604_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020604_qwen2.5-coder:32b/compiling_20260224020604_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020604_qwen2.5-coder:32b/compiling_20260224020604_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_ec_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020131_qwen2.5-coder:32b/compiling_20260224020131_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020131_qwen2.5-coder:32b/compiling_20260224020131_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020131_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020131_qwen2.5-coder:32b/compiling_20260224020131_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020131_qwen2.5-coder:32b/compiling_20260224020131_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020131_qwen2.5-coder:32b/compiling_20260224020131_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020131_qwen2.5-coder:32b/compiling_20260224020131_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020131_qwen2.5-coder:32b/compiling_20260224020131_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020131_qwen2.5-coder:32b/compiling_20260224020131_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224020131_qwen2.5-coder:32b/compiling_20260224020131_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_95_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015658_qwen2.5-coder:32b/compiling_20260224015658_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015658_qwen2.5-coder:32b/compiling_20260224015658_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015658_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015658_qwen2.5-coder:32b/compiling_20260224015658_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015658_qwen2.5-coder:32b/compiling_20260224015658_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015658_qwen2.5-coder:32b/compiling_20260224015658_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015658_qwen2.5-coder:32b/compiling_20260224015658_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015658_qwen2.5-coder:32b/compiling_20260224015658_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015658_qwen2.5-coder:32b/compiling_20260224015658_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015658_qwen2.5-coder:32b/compiling_20260224015658_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_bc_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015226_qwen2.5-coder:32b/compiling_20260224015226_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015226_qwen2.5-coder:32b/compiling_20260224015226_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015226_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015226_qwen2.5-coder:32b/compiling_20260224015226_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015226_qwen2.5-coder:32b/compiling_20260224015226_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015226_qwen2.5-coder:32b/compiling_20260224015226_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015226_qwen2.5-coder:32b/compiling_20260224015226_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015226_qwen2.5-coder:32b/compiling_20260224015226_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015226_qwen2.5-coder:32b/compiling_20260224015226_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224015226_qwen2.5-coder:32b/compiling_20260224015226_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_48_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014753_qwen2.5-coder:32b/compiling_20260224014753_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014753_qwen2.5-coder:32b/compiling_20260224014753_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014753_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014753_qwen2.5-coder:32b/compiling_20260224014753_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014753_qwen2.5-coder:32b/compiling_20260224014753_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014753_qwen2.5-coder:32b/compiling_20260224014753_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014753_qwen2.5-coder:32b/compiling_20260224014753_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014753_qwen2.5-coder:32b/compiling_20260224014753_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014753_qwen2.5-coder:32b/compiling_20260224014753_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014753_qwen2.5-coder:32b/compiling_20260224014753_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_60_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014319_qwen2.5-coder:32b/compiling_20260224014319_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014319_qwen2.5-coder:32b/compiling_20260224014319_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014319_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014319_qwen2.5-coder:32b/compiling_20260224014319_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014319_qwen2.5-coder:32b/compiling_20260224014319_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014319_qwen2.5-coder:32b/compiling_20260224014319_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014319_qwen2.5-coder:32b/compiling_20260224014319_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014319_qwen2.5-coder:32b/compiling_20260224014319_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014319_qwen2.5-coder:32b/compiling_20260224014319_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224014319_qwen2.5-coder:32b/compiling_20260224014319_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_a2_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224013847_qwen2.5-coder:32b/compiling_20260224013847_qwen2.5-coder:32b.ino:17:22: error: conflicting declaration 'const tflite::Model* model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                      ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224013847_qwen2.5-coder:32b/compiling_20260224013847_qwen2.5-coder:32b.ino:6:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224013847_qwen2.5-coder:32b/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224013847_qwen2.5-coder:32b/compiling_20260224013847_qwen2.5-coder:32b.ino:17:47: error: 'g_model' was not declared in this scope\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224013847_qwen2.5-coder:32b/compiling_20260224013847_qwen2.5-coder:32b.ino:17:47: note: suggested alternative: 'model'\n",
      " const tflite::Model* model = tflite::GetModel(g_model);\n",
      "                                               ^~~~~~~\n",
      "                                               model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224013847_qwen2.5-coder:32b/compiling_20260224013847_qwen2.5-coder:32b.ino:18:1: error: expected unqualified-id before 'if'\n",
      " if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      " ^~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224013847_qwen2.5-coder:32b/compiling_20260224013847_qwen2.5-coder:32b.ino:22:21: error: 'AllOpsResolver' in namespace 'tflite::ops::micro' does not name a type\n",
      " tflite::ops::micro::AllOpsResolver resolver;\n",
      "                     ^~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224013847_qwen2.5-coder:32b/compiling_20260224013847_qwen2.5-coder:32b.ino:25:45: error: 'resolver' was not declared in this scope\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224013847_qwen2.5-coder:32b/compiling_20260224013847_qwen2.5-coder:32b.ino:25:45: note: suggested alternative: 'remove'\n",
      " tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                             ^~~~~~~~\n",
      "                                             remove\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260224013847_qwen2.5-coder:32b/compiling_20260224013847_qwen2.5-coder:32b.ino:29:1: error: expected unqualified-id before 'if'\n",
      " if (allocate_status != kTfLiteOk) {\n",
      " ^~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:32b_0d8f_sg_batch\n",
      "======================================================================================================================================================\n",
      "TOTAL 0 TRACES SKIPPED. THEY ARE []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "skipped_trace_details = []  # Keep reason + observation that triggered the skip\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            error_markers = [\n",
    "             \n",
    "                \"litellm.apiconnectionerror\",\n",
    "                \"ollamaexception\",\n",
    "                \"llama runner process has terminated: cuda error\",\n",
    "            ]\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict):\n",
    "                    ob_name = obs.get(\"name\", \"\")\n",
    "                    status_message = obs.get(\"statusMessage\") or \"\"\n",
    "                    if not status_message and \"output\" in obs:\n",
    "                        output_field = obs.get(\"output\")\n",
    "                        if isinstance(output_field, dict):\n",
    "                            status_message = output_field.get(\"message\", \"\")\n",
    "                        elif isinstance(output_field, str):\n",
    "                            status_message = output_field\n",
    "                    lower_message = status_message.lower() if status_message else \"\"\n",
    "                    if ob_name.startswith(\"error\") and status_message:\n",
    "                        print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if any(marker in lower_message for marker in error_markers):\n",
    "                        trace_name = data.get(\"name\", \"<unknown trace>\")\n",
    "                        matched_marker = next(\n",
    "                            (marker for marker in error_markers if marker in lower_message),\n",
    "                            \"unknown error\",\n",
    "                        )\n",
    "                        reason = status_message or matched_marker\n",
    "                        condition = f\"error_marker:{matched_marker}\"\n",
    "                        print(\n",
    "                            f\"Found error marker in observation {ob_name} -> skipping trace {trace_name} ({reason})\"\n",
    "                        )\n",
    "                        skip_trace = True\n",
    "                        if trace_name not in skipped_traces:\n",
    "                            skipped_traces.append(trace_name)\n",
    "                        skipped_trace_details.append(\n",
    "                            {\n",
    "                                \"trace\": trace_name,\n",
    "                                \"observation\": ob_name,\n",
    "                                \"reason\": reason,\n",
    "                                \"condition\": condition,\n",
    "                            }\n",
    "                        )\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(\"=\"*150)\n",
    "print(f\"TOTAL {len(skipped_traces)} TRACES SKIPPED. THEY ARE {skipped_traces}\")\n",
    "if skipped_trace_details:\n",
    "    print(\"SKIP REASONS:\\n```\")\n",
    "    for detail in skipped_trace_details:\n",
    "        print(\n",
    "            f\"- {detail['trace']} (observation: {detail['observation']} | condition: {detail['condition']}): {detail['reason']}\"\n",
    "        )\n",
    "    print(\"```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session qwen2.5-coder:32b_0d8f_psg_batch, simple id qwen2.5-coder:32b_0d8f. Look for /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/raw_export/trimmed_qwen2.5-coder:32b_0d8f_psg_batch.json\n",
      "/home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/processed_data/qwen2.5-coder:32b_0d8f/clean_qwen2.5-coder:32b_0d8f_psg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/processed_data/qwen2.5-coder:32b_0d8f/clean_qwen2.5-coder:32b_0d8f_psg_batch.csv\n",
      "Processing session qwen2.5-coder:32b_0d8f_tpusg_batch, simple id qwen2.5-coder:32b_0d8f. Look for /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/raw_export/trimmed_qwen2.5-coder:32b_0d8f_tpusg_batch.json\n",
      "/home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/processed_data/qwen2.5-coder:32b_0d8f/clean_qwen2.5-coder:32b_0d8f_tpusg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/processed_data/qwen2.5-coder:32b_0d8f/clean_qwen2.5-coder:32b_0d8f_tpusg_batch.csv\n",
      "Processing session qwen2.5-coder:32b_0d8f_sg_batch, simple id qwen2.5-coder:32b_0d8f. Look for /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/raw_export/trimmed_qwen2.5-coder:32b_0d8f_sg_batch.json\n",
      "/home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/processed_data/qwen2.5-coder:32b_0d8f/clean_qwen2.5-coder:32b_0d8f_sg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/processed_data/qwen2.5-coder:32b_0d8f/clean_qwen2.5-coder:32b_0d8f_sg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Generation with Generation Counts\n",
    "\n",
    "This section creates CSV files similar to the langfuse_export section 3, but adds a column for the number of generation attempts used for each trace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sessions: ['qwen2.5-coder:32b_0d8f_psg_batch', 'qwen2.5-coder:32b_0d8f_sg_batch', 'qwen2.5-coder:32b_0d8f_tpusg_batch']\n",
      "Looking for raw files in: /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/raw_export\n",
      "Will save CSV files to: /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/processed_data\n",
      "Processing session qwen2.5-coder:32b_0d8f_psg_batch, simple id qwen2.5-coder:32b_0d8f. Look for /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/raw_export/trimmed_qwen2.5-coder:32b_0d8f_psg_batch.json\n",
      "/home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/processed_data/qwen2.5-coder:32b_0d8f/clean_qwen2.5-coder:32b_0d8f_psg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/processed_data/qwen2.5-coder:32b_0d8f/clean_qwen2.5-coder:32b_0d8f_psg_batch.csv\n",
      "Processing session qwen2.5-coder:32b_0d8f_sg_batch, simple id qwen2.5-coder:32b_0d8f. Look for /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/raw_export/trimmed_qwen2.5-coder:32b_0d8f_sg_batch.json\n",
      "/home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/processed_data/qwen2.5-coder:32b_0d8f/clean_qwen2.5-coder:32b_0d8f_sg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/processed_data/qwen2.5-coder:32b_0d8f/clean_qwen2.5-coder:32b_0d8f_sg_batch.csv\n",
      "Processing session qwen2.5-coder:32b_0d8f_tpusg_batch, simple id qwen2.5-coder:32b_0d8f. Look for /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/raw_export/trimmed_qwen2.5-coder:32b_0d8f_tpusg_batch.json\n",
      "/home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/processed_data/qwen2.5-coder:32b_0d8f/clean_qwen2.5-coder:32b_0d8f_tpusg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/benchmark-tinyml_llm-2026/langfuse_export/2026/02.20_abla-l1-p-qw32/processed_data/qwen2.5-coder:32b_0d8f/clean_qwen2.5-coder:32b_0d8f_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "# Setup paths - same as langfuse_export\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "\n",
    "\n",
    "# Get session id list from data directory\n",
    "session_id_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(raw_export_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if \"trimmed_\" in file_path:\n",
    "            session_id = file_path.split('trimmed_')[1].rstrip('.json')\n",
    "            session_id_list.append(session_id)\n",
    "\n",
    "print(f\"Processing sessions: {session_id_list}\")\n",
    "print(f\"Looking for raw files in: {raw_export_dir}\")\n",
    "print(f\"Will save CSV files to: {processed_data_dir}\")\n",
    "\n",
    "\n",
    "def json_to_csv_weighted(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "    Upgraded version that includes generation_count column.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "            \"generation_count\": 0,  # New field for generation count\n",
    "        }\n",
    "\n",
    "        # Count generations and process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"generation_count\"] += 1\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "                    \n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "            \n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        \n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv_weighted(session_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
