{
  "data": [
    {
      "id": "6bfbeeb3",
      "timestamp": "2026-02-23T22:18:51.787000+00:00",
      "name": "6bfb_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom PIL import ImageDraw, ImageFont\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors.\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Check if camera opened successfully\nif not cap.isOpened():\n    print(\"Error: Could not open video.\")\n    exit()\n\n# Get video properties\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef draw_boxes_on_frame(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            label = labels[int(classes[i])]\n            score = scores[i]\n\n            # Convert normalized coordinates to absolute coordinates\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw rectangle and text on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label_text = f'{label}: {score:.2f}'\n            font = cv2.FONT_HERSHEY_SIMPLEX\n            cv2.putText(frame, label_text, (int(left), int(top) - 10),\n                        font, 0.9, (0, 255, 0), 2)\n\n# Process each frame in the video\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess frame\n    input_shape = input_details[0]['shape']\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n    input_data = np.expand_dims(frame_rgb, axis=0)\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw boxes on the frame\n    draw_boxes_on_frame(frame, boxes, classes, scores)\n\n    # Write the frame with detection to the output video file\n    out.write(frame)\n\n# Release everything when job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(f\"Processed video saved as {output_path}\")"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 43.238,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-00-18-51-788939_chatcmpl-c7adb18b-78cb-48a8-98a0-389aa5fbb263",
          "traceId": "6bfbeeb3",
          "type": "GENERATION",
          "name": "6bfb_psg_gen_attempt#1",
          "startTime": "2026-02-23T22:18:51.788000+00:00",
          "endTime": "2026-02-23T22:19:13.514000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21726.0,
          "totalTokens": 1037,
          "costDetails": {},
          "completionTokens": 838,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-00-19-13-691765_chatcmpl-58ff806f-2965-4a23-9c71-5bbed375f785",
          "traceId": "6bfbeeb3",
          "type": "GENERATION",
          "name": "6bfb_psg_gen_attempt#2",
          "startTime": "2026-02-23T22:19:13.691000+00:00",
          "endTime": "2026-02-23T22:19:35.026000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21335.0,
          "totalTokens": 1025,
          "costDetails": {},
          "completionTokens": 826,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-23T22:20:15.014Z",
      "environment": "default",
      "createdAt": "2026-02-23T22:18:52.329Z"
    },
    {
      "id": "55cfe8a8",
      "timestamp": "2026-02-23T22:17:07.426000+00:00",
      "name": "55cf_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom PIL import ImageDraw, ImageFont\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors.\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Check if camera opened successfully\nif not cap.isOpened():\n    print(\"Error: Could not open video.\")\n    exit()\n\n# Get video properties\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef draw_boxes_on_frame(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            label = labels[int(classes[i])]\n            score = scores[i]\n\n            # Convert normalized coordinates to absolute coordinates\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw rectangle and text on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label_text = f'{label}: {score:.2f}'\n            font = cv2.FONT_HERSHEY_SIMPLEX\n            cv2.putText(frame, label_text, (int(left), int(top) - 10),\n                        font, 0.9, (0, 255, 0), 2)\n\n# Process each frame in the video\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess frame\n    input_shape = input_details[0]['shape']\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n    input_data = np.expand_dims(frame_rgb, axis=0)\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw boxes on the frame\n    draw_boxes_on_frame(frame, boxes, classes, scores)\n\n    # Write the frame with detection to the output video file\n    out.write(frame)\n\n# Release everything when job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(f\"Processed video saved as {output_path}\")"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 43.379,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-00-17-07-426742_chatcmpl-f1ec2662-cd79-41c6-bb39-69cf9aa572af",
          "traceId": "55cfe8a8",
          "type": "GENERATION",
          "name": "55cf_psg_gen_attempt#1",
          "startTime": "2026-02-23T22:17:07.426000+00:00",
          "endTime": "2026-02-23T22:17:29.137000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21711.0,
          "totalTokens": 1036,
          "costDetails": {},
          "completionTokens": 837,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-00-17-29-511491_chatcmpl-b9526eb6-7a7d-4a0b-9aa2-3383f393918e",
          "traceId": "55cfe8a8",
          "type": "GENERATION",
          "name": "55cf_psg_gen_attempt#2",
          "startTime": "2026-02-23T22:17:29.511000+00:00",
          "endTime": "2026-02-23T22:17:50.805000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21294.0,
          "totalTokens": 1025,
          "costDetails": {},
          "completionTokens": 826,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-23T22:18:31.143Z",
      "environment": "default",
      "createdAt": "2026-02-23T22:17:07.972Z"
    },
    {
      "id": "0c7fd144",
      "timestamp": "2026-02-23T22:15:03.722000+00:00",
      "name": "0c7f_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom PIL import ImageDraw, ImageFont\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors.\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Check if camera opened successfully\nif not cap.isOpened():\n    print(\"Error: Could not open video.\")\n    exit()\n\n# Get video properties\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef draw_boxes_on_frame(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            label = labels[int(classes[i])]\n            score = scores[i]\n\n            # Convert normalized coordinates to absolute coordinates\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw rectangle and text on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label_text = f'{label}: {score:.2f}'\n            font = cv2.FONT_HERSHEY_SIMPLEX\n            cv2.putText(frame, label_text, (int(left), int(top) - 10),\n                        font, 0.9, (0, 255, 0), 2)\n\n# Process each frame in the video\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess frame\n    input_shape = input_details[0]['shape']\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n    input_data = np.expand_dims(frame_rgb, axis=0)\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw boxes on the frame\n    draw_boxes_on_frame(frame, boxes, classes, scores)\n\n    # Write the frame with detection to the output video file\n    out.write(frame)\n\n# Release everything when job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(f\"Processed video saved as {output_path}\")"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 65.633,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-00-15-03-724041_chatcmpl-6ff5e937-fc83-4750-aa19-f88c60b15871",
          "traceId": "0c7fd144",
          "type": "GENERATION",
          "name": "0c7f_psg_gen_attempt#1",
          "startTime": "2026-02-23T22:15:03.724000+00:00",
          "endTime": "2026-02-23T22:15:25.554000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21830.0,
          "totalTokens": 1037,
          "costDetails": {},
          "completionTokens": 838,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-00-15-25-731781_chatcmpl-09915d59-2db1-4114-829d-b4a0f5d45a4a",
          "traceId": "0c7fd144",
          "type": "GENERATION",
          "name": "0c7f_psg_gen_attempt#2",
          "startTime": "2026-02-23T22:15:25.731000+00:00",
          "endTime": "2026-02-23T22:15:47.417000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21686.0,
          "totalTokens": 1036,
          "costDetails": {},
          "completionTokens": 837,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-00-15-47-783770_chatcmpl-65a6d7be-0c4a-47e9-90e3-401dd3e13658",
          "traceId": "0c7fd144",
          "type": "GENERATION",
          "name": "0c7f_psg_gen_attempt#3",
          "startTime": "2026-02-23T22:15:47.783000+00:00",
          "endTime": "2026-02-23T22:16:09.357000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21574.0,
          "totalTokens": 1025,
          "costDetails": {},
          "completionTokens": 826,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-23T22:16:46.468Z",
      "environment": "default",
      "createdAt": "2026-02-23T22:15:04.277Z"
    },
    {
      "id": "eea5e0a6",
      "timestamp": "2026-02-23T22:13:44.328000+00:00",
      "name": "eea5_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom PIL import ImageDraw, ImageFont\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors.\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Check if camera opened successfully\nif not cap.isOpened():\n    print(\"Error: Could not open video.\")\n    exit()\n\n# Get video properties\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef draw_boxes_on_frame(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            label = labels[int(classes[i])]\n            score = scores[i]\n\n            # Convert normalized coordinates to absolute coordinates\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw rectangle and text on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label_text = f'{label}: {score:.2f}'\n            font = cv2.FONT_HERSHEY_SIMPLEX\n            cv2.putText(frame, label_text, (int(left), int(top) - 10),\n                        font, 0.9, (0, 255, 0), 2)\n\n# Process each frame in the video\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess frame\n    input_shape = input_details[0]['shape']\n    image_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    image_rgb = cv2.cvtColor(image_resized, cv2.COLOR_BGR2RGB)\n    input_data = np.expand_dims(image_rgb, axis=0)\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.uint8))\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes on the frame\n    draw_boxes_on_frame(frame, boxes, classes, scores)\n\n    # Write the frame with detection to the output video file\n    out.write(frame)\n\n# Release everything when job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(f\"Processed video saved as {output_path}\")"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 22.151,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-00-13-44-329096_chatcmpl-0d350305-10c9-4b98-a104-1cf84995df7b",
          "traceId": "eea5e0a6",
          "type": "GENERATION",
          "name": "eea5_psg_gen_attempt#1",
          "startTime": "2026-02-23T22:13:44.329000+00:00",
          "endTime": "2026-02-23T22:14:06.480000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22151.0,
          "totalTokens": 1032,
          "costDetails": {},
          "completionTokens": 833,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-23T22:14:43.522Z",
      "environment": "default",
      "createdAt": "2026-02-23T22:13:44.882Z"
    },
    {
      "id": "536a9917",
      "timestamp": "2026-02-23T22:12:24.957000+00:00",
      "name": "536a_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom PIL import ImageDraw, ImageFont\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors.\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Check if camera opened successfully\nif not cap.isOpened():\n    print(\"Error: Could not open video.\")\n    exit()\n\n# Get video properties\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef draw_boxes_on_frame(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            label = labels[int(classes[i])]\n            score = scores[i]\n\n            # Convert normalized coordinates to absolute coordinates\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw rectangle and text on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label_text = f'{label}: {score:.2f}'\n            font = cv2.FONT_HERSHEY_SIMPLEX\n            cv2.putText(frame, label_text, (int(left), int(top) - 10),\n                        font, 0.9, (0, 255, 0), 2)\n\n# Process each frame in the video\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess frame\n    input_shape = input_details[0]['shape']\n    image_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    image_rgb = cv2.cvtColor(image_resized, cv2.COLOR_BGR2RGB)\n    input_data = np.expand_dims(image_rgb, axis=0)\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.uint8))\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes on the frame\n    draw_boxes_on_frame(frame, boxes, classes, scores)\n\n    # Write the frame with detection to the output video file\n    out.write(frame)\n\n# Release everything when job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(f\"Processed video saved as {output_path}\")"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 22.009,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-00-12-24-958450_chatcmpl-79de57dc-e49b-4b45-a57f-acf6cb7e47e8",
          "traceId": "536a9917",
          "type": "GENERATION",
          "name": "536a_psg_gen_attempt#1",
          "startTime": "2026-02-23T22:12:24.958000+00:00",
          "endTime": "2026-02-23T22:12:46.967000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22009.0,
          "totalTokens": 1032,
          "costDetails": {},
          "completionTokens": 833,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-23T22:13:23.636Z",
      "environment": "default",
      "createdAt": "2026-02-23T22:12:25.511Z"
    },
    {
      "id": "1fe9d8db",
      "timestamp": "2026-02-23T22:10:43.406000+00:00",
      "name": "1fe9_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom PIL import ImageDraw, ImageFont\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors.\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Check if camera opened successfully\nif not cap.isOpened():\n    print(\"Error: Could not open video.\")\n    exit()\n\n# Get video properties\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef draw_boxes_on_frame(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            label = labels[int(classes[i])]\n            score = scores[i]\n\n            # Convert normalized coordinates to absolute coordinates\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw rectangle and text on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label_text = f'{label}: {score:.2f}'\n            font = cv2.FONT_HERSHEY_SIMPLEX\n            cv2.putText(frame, label_text, (int(left), int(top) - 10),\n                        font, 0.9, (0, 255, 0), 2)\n\n# Process each frame in the video\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess frame\n    input_shape = input_details[0]['shape']\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n    input_data = np.expand_dims(frame_rgb, axis=0)\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw boxes on the frame\n    draw_boxes_on_frame(frame, boxes, classes, scores)\n\n    # Write the frame with detection to the output video file\n    out.write(frame)\n\n# Release everything when job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(f\"Processed video saved as {output_path}\")"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 43.875,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-00-10-43-407118_chatcmpl-abb630e5-16a3-4c82-8603-9f55bc5f6a8b",
          "traceId": "1fe9d8db",
          "type": "GENERATION",
          "name": "1fe9_psg_gen_attempt#1",
          "startTime": "2026-02-23T22:10:43.407000+00:00",
          "endTime": "2026-02-23T22:11:05.112000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21705.0,
          "totalTokens": 1036,
          "costDetails": {},
          "completionTokens": 837,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-00-11-05-897233_chatcmpl-3674bda9-58c0-43a6-9b1d-994d8211c575",
          "traceId": "1fe9d8db",
          "type": "GENERATION",
          "name": "1fe9_psg_gen_attempt#2",
          "startTime": "2026-02-23T22:11:05.897000+00:00",
          "endTime": "2026-02-23T22:11:27.282000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21385.0,
          "totalTokens": 1025,
          "costDetails": {},
          "completionTokens": 826,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-23T22:12:04.654Z",
      "environment": "default",
      "createdAt": "2026-02-23T22:10:43.958Z"
    },
    {
      "id": "80b2b1e4",
      "timestamp": "2026-02-23T22:08:38.916000+00:00",
      "name": "80b2_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom PIL import ImageDraw, ImageFont\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors.\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Check if camera opened successfully\nif not cap.isOpened():\n    print(\"Error: Could not open video.\")\n    exit()\n\n# Get video properties\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef draw_boxes_on_frame(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            label = labels[int(classes[i])]\n            score = scores[i]\n\n            # Convert normalized coordinates to absolute coordinates\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw rectangle and text on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label_text = f'{label}: {score:.2f}'\n            font = cv2.FONT_HERSHEY_SIMPLEX\n            cv2.putText(frame, label_text, (int(left), int(top) - 10),\n                        font, 0.9, (0, 255, 0), 2)\n\n# Process each frame in the video\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess frame\n    input_shape = input_details[0]['shape']\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n    input_data = np.expand_dims(frame_rgb, axis=0)\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw boxes on the frame\n    draw_boxes_on_frame(frame, boxes, classes, scores)\n\n    # Write the frame with detection to the output video file\n    out.write(frame)\n\n# Release everything when job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(f\"Processed video saved as {output_path}\")"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 65.001,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-00-08-38-917393_chatcmpl-431546be-5ad1-45ab-be73-e4c751e3ee50",
          "traceId": "80b2b1e4",
          "type": "GENERATION",
          "name": "80b2_psg_gen_attempt#1",
          "startTime": "2026-02-23T22:08:38.917000+00:00",
          "endTime": "2026-02-23T22:09:00.823000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21906.0,
          "totalTokens": 1037,
          "costDetails": {},
          "completionTokens": 838,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-00-09-00-996418_chatcmpl-fa8fa2ad-1d6f-469c-ba75-a1ef86059aff",
          "traceId": "80b2b1e4",
          "type": "GENERATION",
          "name": "80b2_psg_gen_attempt#2",
          "startTime": "2026-02-23T22:09:00.996000+00:00",
          "endTime": "2026-02-23T22:09:22.163000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21167.0,
          "totalTokens": 1017,
          "costDetails": {},
          "completionTokens": 818,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-00-09-22-529957_chatcmpl-b4c9daec-a37b-4f9e-9f2a-0e64e92c6ede",
          "traceId": "80b2b1e4",
          "type": "GENERATION",
          "name": "80b2_psg_gen_attempt#3",
          "startTime": "2026-02-23T22:09:22.529000+00:00",
          "endTime": "2026-02-23T22:09:43.918000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21389.0,
          "totalTokens": 1025,
          "costDetails": {},
          "completionTokens": 826,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-23T22:10:23.192Z",
      "environment": "default",
      "createdAt": "2026-02-23T22:08:39.465Z"
    },
    {
      "id": "2566e7ff",
      "timestamp": "2026-02-23T22:07:19.566000+00:00",
      "name": "2566_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom PIL import ImageDraw, ImageFont\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors.\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Check if camera opened successfully\nif not cap.isOpened():\n    print(\"Error: Could not open video.\")\n    exit()\n\n# Get video properties\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef draw_boxes_on_frame(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            label = labels[int(classes[i])]\n            score = scores[i]\n\n            # Convert normalized coordinates to absolute coordinates\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw rectangle and text on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label_text = f'{label}: {score:.2f}'\n            font = cv2.FONT_HERSHEY_SIMPLEX\n            cv2.putText(frame, label_text, (int(left), int(top) - 10),\n                        font, 0.9, (0, 255, 0), 2)\n\n# Process each frame in the video\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess frame\n    input_shape = input_details[0]['shape']\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n    input_data = np.expand_dims(frame_rgb, axis=0)\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw boxes on the frame\n    draw_boxes_on_frame(frame, boxes, classes, scores)\n\n    # Write the frame with detection to the output video file\n    out.write(frame)\n\n# Release everything when job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(f\"Processed video saved as {output_path}\")"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 21.584,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-00-07-19-567693_chatcmpl-5fee9223-2617-4f45-9381-ead7b76e7d83",
          "traceId": "2566e7ff",
          "type": "GENERATION",
          "name": "2566_psg_gen_attempt#1",
          "startTime": "2026-02-23T22:07:19.567000+00:00",
          "endTime": "2026-02-23T22:07:41.151000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21584.0,
          "totalTokens": 1025,
          "costDetails": {},
          "completionTokens": 826,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-23T22:08:18.250Z",
      "environment": "default",
      "createdAt": "2026-02-23T22:07:20.114Z"
    },
    {
      "id": "550ce630",
      "timestamp": "2026-02-23T22:05:38.134000+00:00",
      "name": "550c_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom PIL import ImageDraw, ImageFont\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors.\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Check if camera opened successfully\nif not cap.isOpened():\n    print(\"Error: Could not open video.\")\n    exit()\n\n# Get video properties\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef draw_boxes_on_frame(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            label = labels[int(classes[i])]\n            score = scores[i]\n\n            # Convert normalized coordinates to absolute coordinates\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw rectangle and text on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label_text = f'{label}: {score:.2f}'\n            font = cv2.FONT_HERSHEY_SIMPLEX\n            cv2.putText(frame, label_text, (int(left), int(top) - 10),\n                        font, 0.9, (0, 255, 0), 2)\n\n# Process each frame in the video\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess frame\n    input_shape = input_details[0]['shape']\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n    input_data = np.expand_dims(frame_rgb, axis=0)\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw boxes on the frame\n    draw_boxes_on_frame(frame, boxes, classes, scores)\n\n    # Write the frame with detection to the output video file\n    out.write(frame)\n\n# Release everything when job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(f\"Processed video saved as {output_path}\")"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 43.418,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-00-05-38-136021_chatcmpl-eabe7106-a3a7-4abb-a31d-54c52365b36f",
          "traceId": "550ce630",
          "type": "GENERATION",
          "name": "550c_psg_gen_attempt#1",
          "startTime": "2026-02-23T22:05:38.136000+00:00",
          "endTime": "2026-02-23T22:05:59.886000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21750.0,
          "totalTokens": 1037,
          "costDetails": {},
          "completionTokens": 838,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-00-06-00-231983_chatcmpl-65b0ee1f-b7b3-4483-8967-55ca40d49582",
          "traceId": "550ce630",
          "type": "GENERATION",
          "name": "550c_psg_gen_attempt#2",
          "startTime": "2026-02-23T22:06:00.231000+00:00",
          "endTime": "2026-02-23T22:06:21.554000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21323.0,
          "totalTokens": 1025,
          "costDetails": {},
          "completionTokens": 826,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-23T22:06:58.865Z",
      "environment": "default",
      "createdAt": "2026-02-23T22:05:38.681Z"
    },
    {
      "id": "1b9325f1",
      "timestamp": "2026-02-23T22:03:54.733000+00:00",
      "name": "1b93_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom PIL import ImageDraw, ImageFont\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors.\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Check if camera opened successfully\nif not cap.isOpened():\n    print(\"Error: Could not open video.\")\n    exit()\n\n# Get video properties\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef draw_boxes_on_frame(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            label = labels[int(classes[i])]\n            score = scores[i]\n\n            # Convert normalized coordinates to absolute coordinates\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw rectangle and text on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label_text = f'{label}: {score:.2f}'\n            font = cv2.FONT_HERSHEY_SIMPLEX\n            cv2.putText(frame, label_text, (int(left), int(top) - 10),\n                        font, 0.9, (0, 255, 0), 2)\n\n# Process each frame in the video\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess frame\n    input_shape = input_details[0]['shape']\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n    input_data = np.expand_dims(frame_rgb, axis=0)\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw boxes on the frame\n    draw_boxes_on_frame(frame, boxes, classes, scores)\n\n    # Write the frame with detection to the output video file\n    out.write(frame)\n\n# Release everything when job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(f\"Processed video saved as {output_path}\")"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 43.398,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-00-03-54-734105_chatcmpl-0d332fef-d013-48cb-a99a-94717eefd36b",
          "traceId": "1b9325f1",
          "type": "GENERATION",
          "name": "1b93_psg_gen_attempt#1",
          "startTime": "2026-02-23T22:03:54.734000+00:00",
          "endTime": "2026-02-23T22:04:16.437000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21703.0,
          "totalTokens": 1036,
          "costDetails": {},
          "completionTokens": 837,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-00-04-16-816217_chatcmpl-c435b675-a6e3-42bf-955b-cb81e5ba1632",
          "traceId": "1b9325f1",
          "type": "GENERATION",
          "name": "1b93_psg_gen_attempt#2",
          "startTime": "2026-02-23T22:04:16.816000+00:00",
          "endTime": "2026-02-23T22:04:38.132000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21316.0,
          "totalTokens": 1025,
          "costDetails": {},
          "completionTokens": 826,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-23T22:05:17.905Z",
      "environment": "default",
      "createdAt": "2026-02-23T22:03:55.277Z"
    },
    {
      "id": "3f15c88d",
      "timestamp": "2026-02-23T22:01:39.258000+00:00",
      "name": "3f15_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom PIL import ImageDraw, ImageFont\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors.\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Check if camera opened successfully\nif not cap.isOpened():\n    print(\"Error: Could not open video.\")\n    exit()\n\n# Get video properties\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef draw_boxes_on_frame(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            label = labels[int(classes[i])]\n            score = scores[i]\n\n            # Convert normalized coordinates to image coordinates\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw rectangle and text on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label_text = f'{label}: {score:.2f}'\n            font = cv2.FONT_HERSHEY_SIMPLEX\n            cv2.putText(frame, label_text, (int(left), int(top) - 10),\n                        font, 0.9, (0, 255, 0), 2)\n\n# Process each frame in the video\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess frame\n    input_data = cv2.resize(frame, (300, 300))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = input_data.astype(np.float32) / 127.5 - 1.0\n\n    # Set tensor to point to the input data to be inferred\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Run inference\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes on the frame\n    draw_boxes_on_frame(frame, boxes, classes, scores)\n\n    # Write the frame with the detection to the output video file\n    out.write(frame)\n\n# Release everything when job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(f\"Processed video saved as {output_path}\")",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260224000329_psg_qwen2.5-coder:32b/tmp_20260224000329_psg_qwen2.5-coder:32b.py\", line 72, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 110.331,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-00-01-39-259482_chatcmpl-87efbdb3-5563-4dd7-a0a1-6365381e6773",
          "traceId": "3f15c88d",
          "type": "GENERATION",
          "name": "3f15_psg_gen_attempt#1",
          "startTime": "2026-02-23T22:01:39.259000+00:00",
          "endTime": "2026-02-23T22:02:00.939000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21680.0,
          "totalTokens": 1036,
          "costDetails": {},
          "completionTokens": 837,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-00-02-01-909237_chatcmpl-1bb1f3d8-b98b-453a-af88-5bf4f7f24b9d",
          "traceId": "3f15c88d",
          "type": "GENERATION",
          "name": "3f15_psg_gen_attempt#2",
          "startTime": "2026-02-23T22:02:01.909000+00:00",
          "endTime": "2026-02-23T22:02:23.532000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21623.0,
          "totalTokens": 1037,
          "costDetails": {},
          "completionTokens": 838,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-00-02-23-730714_chatcmpl-7c2c17f9-42ce-4116-9710-22a3c3160fa1",
          "traceId": "3f15c88d",
          "type": "GENERATION",
          "name": "3f15_psg_gen_attempt#3",
          "startTime": "2026-02-23T22:02:23.730000+00:00",
          "endTime": "2026-02-23T22:02:45.351000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21621.0,
          "totalTokens": 1036,
          "costDetails": {},
          "completionTokens": 837,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-00-02-45-735432_chatcmpl-895176cc-9451-4db7-ad12-0873f2fe2e38",
          "traceId": "3f15c88d",
          "type": "GENERATION",
          "name": "3f15_psg_gen_attempt#4",
          "startTime": "2026-02-23T22:02:45.735000+00:00",
          "endTime": "2026-02-23T22:03:07.339000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21604.0,
          "totalTokens": 1036,
          "costDetails": {},
          "completionTokens": 837,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-00-03-07-792527_chatcmpl-af5d9cbb-ccf0-44b1-abe5-a30d0c58cf80",
          "traceId": "3f15c88d",
          "type": "GENERATION",
          "name": "3f15_psg_gen_attempt#5",
          "startTime": "2026-02-23T22:03:07.792000+00:00",
          "endTime": "2026-02-23T22:03:29.418000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21626.0,
          "totalTokens": 1037,
          "costDetails": {},
          "completionTokens": 838,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "28eb2582-6ee7-416f-a316-6e374e05389e",
          "traceId": "3f15c88d",
          "type": "SPAN",
          "name": "error_3f_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-23T22:03:29.590000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260224000329_psg_qwen2.5-coder:32b/tmp_20260224000329_psg_qwen2.5-coder:32b.py\", line 72, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-23T22:03:34.963Z",
      "environment": "default",
      "createdAt": "2026-02-23T22:01:39.802Z"
    },
    {
      "id": "9c267462",
      "timestamp": "2026-02-23T21:59:53.413000+00:00",
      "name": "9c26_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom PIL import ImageDraw, ImageFont\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors.\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Check if camera opened successfully\nif not cap.isOpened():\n    print(\"Error: Could not open video.\")\n    exit()\n\n# Get video properties\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef draw_boxes_on_frame(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            label = labels[int(classes[i])]\n            score = scores[i]\n\n            # Convert normalized coordinates to absolute coordinates\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw rectangle and text on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label_text = f'{label}: {score:.2f}'\n            font = cv2.FONT_HERSHEY_SIMPLEX\n            cv2.putText(frame, label_text, (int(left), int(top) - 10),\n                        font, 0.9, (0, 255, 0), 2)\n\n# Process each frame in the video\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess frame\n    input_shape = input_details[0]['shape']\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n    input_data = np.expand_dims(frame_rgb, axis=0)\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw boxes on the frame\n    draw_boxes_on_frame(frame, boxes, classes, scores)\n\n    # Write the frame with detection to the output video file\n    out.write(frame)\n\n# Release everything when job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(f\"Processed video saved as {output_path}\")"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 43.259,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-00-00-15-349676_chatcmpl-3c7110df-8c6d-4334-9bc2-6e0d0bdb7cc8",
          "traceId": "9c267462",
          "type": "GENERATION",
          "name": "9c26_psg_gen_attempt#2",
          "startTime": "2026-02-23T22:00:15.349000+00:00",
          "endTime": "2026-02-23T22:00:36.673000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21324.0,
          "totalTokens": 1025,
          "costDetails": {},
          "completionTokens": 826,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-59-53-414770_chatcmpl-783e6a5e-cc73-432f-a970-a92b579783c9",
          "traceId": "9c267462",
          "type": "GENERATION",
          "name": "9c26_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:59:53.414000+00:00",
          "endTime": "2026-02-23T22:00:15.131000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21717.0,
          "totalTokens": 1037,
          "costDetails": {},
          "completionTokens": 838,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-23T22:01:18.147Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:59:53.956Z"
    },
    {
      "id": "6bfd3301",
      "timestamp": "2026-02-23T21:58:08.739000+00:00",
      "name": "6bfd_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom PIL import ImageDraw, ImageFont\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors.\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Check if camera opened successfully\nif not cap.isOpened():\n    print(\"Error: Could not open video.\")\n    exit()\n\n# Get video properties\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef draw_boxes_on_frame(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            label = labels[int(classes[i])]\n            score = scores[i]\n\n            # Convert normalized coordinates to absolute coordinates\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw rectangle and text on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label_text = f'{label}: {score:.2f}'\n            font = cv2.FONT_HERSHEY_SIMPLEX\n            cv2.putText(frame, label_text, (int(left), int(top) - 10),\n                        font, 0.9, (0, 255, 0), 2)\n\n# Process each frame in the video\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess frame\n    input_shape = input_details[0]['shape']\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n    input_data = np.expand_dims(frame_rgb, axis=0)\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw boxes on the frame\n    draw_boxes_on_frame(frame, boxes, classes, scores)\n\n    # Write the frame with the detection boxes to the output video file\n    out.write(frame)\n\n# Release everything when job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(f\"Processed video saved as {output_path}\")"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 45.014,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-58-08-741618_chatcmpl-26bb0393-97bb-42ec-aace-b4e877aa81e4",
          "traceId": "6bfd3301",
          "type": "GENERATION",
          "name": "6bfd_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:58:08.741000+00:00",
          "endTime": "2026-02-23T21:58:30.897000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22156.0,
          "totalTokens": 1037,
          "costDetails": {},
          "completionTokens": 838,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-58-32-154392_chatcmpl-c95dc3e2-0eb6-4176-87ef-b7880a6937e1",
          "traceId": "6bfd3301",
          "type": "GENERATION",
          "name": "6bfd_psg_gen_attempt#2",
          "startTime": "2026-02-23T21:58:32.154000+00:00",
          "endTime": "2026-02-23T21:58:53.755000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21601.0,
          "totalTokens": 1029,
          "costDetails": {},
          "completionTokens": 830,
          "promptTokens": 199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-23T21:59:32.972Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:58:09.282Z"
    },
    {
      "id": "d9083f0d",
      "timestamp": "2026-02-23T21:56:16.844000+00:00",
      "name": "d908_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    height, width = input_shape[1:3]\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    input_data = input_data.astype(np.float32) / 255.0\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223235741_psg_qwen2.5-coder:32b/tmp_20260223235741_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 84.78,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-56-16-845203_chatcmpl-737c2036-fd12-4450-b067-d62313729530",
          "traceId": "d9083f0d",
          "type": "GENERATION",
          "name": "d908_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:56:16.845000+00:00",
          "endTime": "2026-02-23T21:56:33.797000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16952.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-56-33-960587_chatcmpl-cb2ca0f6-a2dd-4917-a81d-a26bc363539b",
          "traceId": "d9083f0d",
          "type": "GENERATION",
          "name": "d908_psg_gen_attempt#2",
          "startTime": "2026-02-23T21:56:33.960000+00:00",
          "endTime": "2026-02-23T21:56:50.756000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16796.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-56-50-910860_chatcmpl-eb83463e-1244-4118-92b0-e8e82962f987",
          "traceId": "d9083f0d",
          "type": "GENERATION",
          "name": "d908_psg_gen_attempt#3",
          "startTime": "2026-02-23T21:56:50.910000+00:00",
          "endTime": "2026-02-23T21:57:07.692000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16782.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-57-07-847223_chatcmpl-1ece63c0-92eb-4112-9116-92886f675300",
          "traceId": "d9083f0d",
          "type": "GENERATION",
          "name": "d908_psg_gen_attempt#4",
          "startTime": "2026-02-23T21:57:07.847000+00:00",
          "endTime": "2026-02-23T21:57:24.563000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16716.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-57-24-712278_chatcmpl-78c147fb-5fec-441d-a38e-c821dddfa3c1",
          "traceId": "d9083f0d",
          "type": "GENERATION",
          "name": "d908_psg_gen_attempt#5",
          "startTime": "2026-02-23T21:57:24.712000+00:00",
          "endTime": "2026-02-23T21:57:41.465000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16753.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "cdba1ed8-59b8-4796-9ce9-fada1abf6e68",
          "traceId": "d9083f0d",
          "type": "SPAN",
          "name": "error_d9_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-23T21:57:41.625000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223235741_psg_qwen2.5-coder:32b/tmp_20260223235741_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-23T21:57:47.397Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:56:17.385Z"
    },
    {
      "id": "62cd00fd",
      "timestamp": "2026-02-23T21:54:25.351000+00:00",
      "name": "62cd_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    height, width = input_shape[1:3]\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    input_data = input_data.astype(np.float32) / 255.0\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223235549_psg_qwen2.5-coder:32b/tmp_20260223235549_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 84.808,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-54-25-352818_chatcmpl-653b4425-1467-47ca-84d8-1c0bca099c2c",
          "traceId": "62cd00fd",
          "type": "GENERATION",
          "name": "62cd_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:54:25.352000+00:00",
          "endTime": "2026-02-23T21:54:42.205000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16853.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-54-42-363336_chatcmpl-dc51f1e7-6e14-4f1b-aedc-1312332e2dac",
          "traceId": "62cd00fd",
          "type": "GENERATION",
          "name": "62cd_psg_gen_attempt#2",
          "startTime": "2026-02-23T21:54:42.363000+00:00",
          "endTime": "2026-02-23T21:54:59.108000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16745.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-54-59-327059_chatcmpl-0086c45c-c4f9-4c30-bfb0-999f15954060",
          "traceId": "62cd00fd",
          "type": "GENERATION",
          "name": "62cd_psg_gen_attempt#3",
          "startTime": "2026-02-23T21:54:59.327000+00:00",
          "endTime": "2026-02-23T21:55:16.072000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16745.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-55-16-352535_chatcmpl-cbdd3b2f-a26a-47ec-9e5d-77f6d2b95298",
          "traceId": "62cd00fd",
          "type": "GENERATION",
          "name": "62cd_psg_gen_attempt#4",
          "startTime": "2026-02-23T21:55:16.352000+00:00",
          "endTime": "2026-02-23T21:55:33.112000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16760.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-55-33-269345_chatcmpl-8df1dcf3-0e41-4a0a-be76-2ec4a5028276",
          "traceId": "62cd00fd",
          "type": "GENERATION",
          "name": "62cd_psg_gen_attempt#5",
          "startTime": "2026-02-23T21:55:33.269000+00:00",
          "endTime": "2026-02-23T21:55:49.991000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16722.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "db53d75d-8de7-4c19-a6c5-f5b4da1f30d9",
          "traceId": "62cd00fd",
          "type": "SPAN",
          "name": "error_62_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-23T21:55:50.160000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223235549_psg_qwen2.5-coder:32b/tmp_20260223235549_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-23T21:55:55.800Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:54:25.891Z"
    },
    {
      "id": "15734ae7",
      "timestamp": "2026-02-23T21:52:33.780000+00:00",
      "name": "1573_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    height, width = input_shape[1:3]\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    input_data = input_data.astype(np.float32) / 255.0\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223235358_psg_qwen2.5-coder:32b/tmp_20260223235358_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 85.081,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-52-33-781458_chatcmpl-48ca8f99-cf58-43f7-b76f-bb359f10f28a",
          "traceId": "15734ae7",
          "type": "GENERATION",
          "name": "1573_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:52:33.781000+00:00",
          "endTime": "2026-02-23T21:52:50.605000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16824.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-52-50-762470_chatcmpl-e306750a-8474-410a-82d7-a27925cdf8fc",
          "traceId": "15734ae7",
          "type": "GENERATION",
          "name": "1573_psg_gen_attempt#2",
          "startTime": "2026-02-23T21:52:50.762000+00:00",
          "endTime": "2026-02-23T21:53:07.514000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16752.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-53-07-668097_chatcmpl-13e389b8-2fe4-4390-b9e3-c9b0b4e13962",
          "traceId": "15734ae7",
          "type": "GENERATION",
          "name": "1573_psg_gen_attempt#3",
          "startTime": "2026-02-23T21:53:07.668000+00:00",
          "endTime": "2026-02-23T21:53:24.392000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16724.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-53-24-685267_chatcmpl-e137a9b2-0dc6-419a-9105-895e5cb5bc7c",
          "traceId": "15734ae7",
          "type": "GENERATION",
          "name": "1573_psg_gen_attempt#4",
          "startTime": "2026-02-23T21:53:24.685000+00:00",
          "endTime": "2026-02-23T21:53:41.495000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16810.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-53-41-647680_chatcmpl-497a5e89-7e4a-42af-a2ad-e70cab6fb2ff",
          "traceId": "15734ae7",
          "type": "GENERATION",
          "name": "1573_psg_gen_attempt#5",
          "startTime": "2026-02-23T21:53:41.647000+00:00",
          "endTime": "2026-02-23T21:53:58.394000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16747.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "b96e88cb-0bd4-4254-a060-7aa13148de03",
          "traceId": "15734ae7",
          "type": "SPAN",
          "name": "error_15_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-23T21:53:58.862000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223235358_psg_qwen2.5-coder:32b/tmp_20260223235358_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-23T21:54:04.504Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:52:34.318Z"
    },
    {
      "id": "750412f9",
      "timestamp": "2026-02-23T21:50:42.413000+00:00",
      "name": "7504_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    height, width = input_shape[1:3]\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    input_data = input_data.astype(np.float32) / 255.0\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223235207_psg_qwen2.5-coder:32b/tmp_20260223235207_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 85.066,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-50-42-414140_chatcmpl-c6dc73d6-9ee5-4d51-8daa-15d3ea20afb3",
          "traceId": "750412f9",
          "type": "GENERATION",
          "name": "7504_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:50:42.414000+00:00",
          "endTime": "2026-02-23T21:50:59.216000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16802.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-50-59-555627_chatcmpl-cc36b894-8e48-4cee-bbc5-a06c64990c1e",
          "traceId": "750412f9",
          "type": "GENERATION",
          "name": "7504_psg_gen_attempt#2",
          "startTime": "2026-02-23T21:50:59.555000+00:00",
          "endTime": "2026-02-23T21:51:16.277000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16722.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-51-16-426305_chatcmpl-20de5ffc-cba8-40a2-94b0-b6efbf3e6dd1",
          "traceId": "750412f9",
          "type": "GENERATION",
          "name": "7504_psg_gen_attempt#3",
          "startTime": "2026-02-23T21:51:16.426000+00:00",
          "endTime": "2026-02-23T21:51:33.283000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16857.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-51-33-598162_chatcmpl-08d07e55-f119-4eea-a5d6-30ec873de79e",
          "traceId": "750412f9",
          "type": "GENERATION",
          "name": "7504_psg_gen_attempt#4",
          "startTime": "2026-02-23T21:51:33.598000+00:00",
          "endTime": "2026-02-23T21:51:50.430000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16832.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-51-50-586845_chatcmpl-a44e2571-923e-43b1-b692-07229c170d88",
          "traceId": "750412f9",
          "type": "GENERATION",
          "name": "7504_psg_gen_attempt#5",
          "startTime": "2026-02-23T21:51:50.586000+00:00",
          "endTime": "2026-02-23T21:52:07.326000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16740.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "533105ff-74b6-4e56-b136-31ff7850122f",
          "traceId": "750412f9",
          "type": "SPAN",
          "name": "error_75_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-23T21:52:07.480000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223235207_psg_qwen2.5-coder:32b/tmp_20260223235207_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-23T21:52:13.106Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:50:42.950Z"
    },
    {
      "id": "f675573a",
      "timestamp": "2026-02-23T21:48:51.023000+00:00",
      "name": "f675_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    height, width = input_shape[1:3]\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    input_data = input_data.astype(np.float32) / 255.0\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223235016_psg_qwen2.5-coder:32b/tmp_20260223235016_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 85.366,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-48-51-024829_chatcmpl-db57b1b2-11bb-436b-ba61-c190ad402269",
          "traceId": "f675573a",
          "type": "GENERATION",
          "name": "f675_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:48:51.024000+00:00",
          "endTime": "2026-02-23T21:49:07.864000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16840.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-49-08-015062_chatcmpl-a664877f-8f04-46d6-b5cb-b82784cd8770",
          "traceId": "f675573a",
          "type": "GENERATION",
          "name": "f675_psg_gen_attempt#2",
          "startTime": "2026-02-23T21:49:08.015000+00:00",
          "endTime": "2026-02-23T21:49:24.959000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16944.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-49-25-351965_chatcmpl-aa758067-38ce-4a66-831f-aa9042442cc7",
          "traceId": "f675573a",
          "type": "GENERATION",
          "name": "f675_psg_gen_attempt#3",
          "startTime": "2026-02-23T21:49:25.351000+00:00",
          "endTime": "2026-02-23T21:49:42.079000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16728.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-49-42-235653_chatcmpl-aa1f3cec-336f-4f02-9bad-79825745e7c9",
          "traceId": "f675573a",
          "type": "GENERATION",
          "name": "f675_psg_gen_attempt#4",
          "startTime": "2026-02-23T21:49:42.235000+00:00",
          "endTime": "2026-02-23T21:49:58.955000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16720.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-49-59-501597_chatcmpl-61f23766-48eb-4dca-9f84-11dbd2992508",
          "traceId": "f675573a",
          "type": "GENERATION",
          "name": "f675_psg_gen_attempt#5",
          "startTime": "2026-02-23T21:49:59.501000+00:00",
          "endTime": "2026-02-23T21:50:16.233000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16732.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "1296b6d1-968c-4f8c-a562-3cf5dfc411d3",
          "traceId": "f675573a",
          "type": "SPAN",
          "name": "error_f6_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-23T21:50:16.390000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223235016_psg_qwen2.5-coder:32b/tmp_20260223235016_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-23T21:50:21.717Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:48:51.558Z"
    },
    {
      "id": "762d6486",
      "timestamp": "2026-02-23T21:46:59.569000+00:00",
      "name": "762d_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    height, width = input_shape[1:3]\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    input_data = input_data.astype(np.float32) / 255.0\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223234824_psg_qwen2.5-coder:32b/tmp_20260223234824_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 84.645,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-46-59-570656_chatcmpl-b454b5ac-4e16-4a9e-9732-6ed8f0e40398",
          "traceId": "762d6486",
          "type": "GENERATION",
          "name": "762d_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:46:59.570000+00:00",
          "endTime": "2026-02-23T21:47:16.390000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16820.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-47-16-543564_chatcmpl-c7a6b62e-aaa9-47b1-9058-3bc84ff9898e",
          "traceId": "762d6486",
          "type": "GENERATION",
          "name": "762d_psg_gen_attempt#2",
          "startTime": "2026-02-23T21:47:16.543000+00:00",
          "endTime": "2026-02-23T21:47:33.322000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16779.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-47-33-476745_chatcmpl-7aeb29aa-f549-4a67-8e5e-510e0035a5e3",
          "traceId": "762d6486",
          "type": "GENERATION",
          "name": "762d_psg_gen_attempt#3",
          "startTime": "2026-02-23T21:47:33.476000+00:00",
          "endTime": "2026-02-23T21:47:50.262000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16786.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-47-50-414276_chatcmpl-1ac845b1-20f0-479f-b17d-826e674a331d",
          "traceId": "762d6486",
          "type": "GENERATION",
          "name": "762d_psg_gen_attempt#4",
          "startTime": "2026-02-23T21:47:50.414000+00:00",
          "endTime": "2026-02-23T21:48:07.170000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16756.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-48-07-326517_chatcmpl-05d610f5-92bf-410e-afad-5396177410ba",
          "traceId": "762d6486",
          "type": "GENERATION",
          "name": "762d_psg_gen_attempt#5",
          "startTime": "2026-02-23T21:48:07.326000+00:00",
          "endTime": "2026-02-23T21:48:24.067000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16741.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "891ab3a1-cda3-46cc-8778-56d4f400943a",
          "traceId": "762d6486",
          "type": "SPAN",
          "name": "error_76_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-23T21:48:24.215000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223234824_psg_qwen2.5-coder:32b/tmp_20260223234824_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-23T21:48:30.011Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:47:00.207Z"
    },
    {
      "id": "6a30e5f2",
      "timestamp": "2026-02-23T21:45:07.280000+00:00",
      "name": "6a30_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    height, width = input_shape[1:3]\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    input_data = input_data.astype(np.float32) / 255.0\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223234631_psg_qwen2.5-coder:32b/tmp_20260223234631_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 84.614,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-45-07-281507_chatcmpl-87f6c790-de32-4da7-996f-0211a181576a",
          "traceId": "6a30e5f2",
          "type": "GENERATION",
          "name": "6a30_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:45:07.281000+00:00",
          "endTime": "2026-02-23T21:45:24.140000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16859.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-45-24-300132_chatcmpl-62b820ae-769e-45c0-8161-c5b96dd0f57b",
          "traceId": "6a30e5f2",
          "type": "GENERATION",
          "name": "6a30_psg_gen_attempt#2",
          "startTime": "2026-02-23T21:45:24.300000+00:00",
          "endTime": "2026-02-23T21:45:41.021000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16721.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-45-41-174127_chatcmpl-4bdc3e28-4595-49d9-99b6-404eababe6d7",
          "traceId": "6a30e5f2",
          "type": "GENERATION",
          "name": "6a30_psg_gen_attempt#3",
          "startTime": "2026-02-23T21:45:41.174000+00:00",
          "endTime": "2026-02-23T21:45:57.900000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16726.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-45-58-159120_chatcmpl-db90c3a7-31a1-47b0-aa69-cca5eb263f8b",
          "traceId": "6a30e5f2",
          "type": "GENERATION",
          "name": "6a30_psg_gen_attempt#4",
          "startTime": "2026-02-23T21:45:58.159000+00:00",
          "endTime": "2026-02-23T21:46:14.875000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16716.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-46-15-029108_chatcmpl-0f052f17-53ab-431c-8da4-935a244cf879",
          "traceId": "6a30e5f2",
          "type": "GENERATION",
          "name": "6a30_psg_gen_attempt#5",
          "startTime": "2026-02-23T21:46:15.029000+00:00",
          "endTime": "2026-02-23T21:46:31.748000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16719.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "0c37449c-5bde-4560-8911-2d5a087f4d29",
          "traceId": "6a30e5f2",
          "type": "SPAN",
          "name": "error_6a_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-23T21:46:31.895000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223234631_psg_qwen2.5-coder:32b/tmp_20260223234631_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-23T21:46:37.728Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:45:07.809Z"
    },
    {
      "id": "4b9cc1cc",
      "timestamp": "2026-02-23T21:43:14.628000+00:00",
      "name": "4b9c_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    height, width = input_shape[1:3]\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    input_data = input_data.astype(np.float32) / 255.0\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223234439_psg_qwen2.5-coder:32b/tmp_20260223234439_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 10
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 85.362,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-43-14-629450_chatcmpl-73e4e8c8-793b-4daa-8c38-60eb5cd2a649",
          "traceId": "4b9cc1cc",
          "type": "GENERATION",
          "name": "4b9c_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:43:14.629000+00:00",
          "endTime": "2026-02-23T21:43:31.923000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17294.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-43-32-074956_chatcmpl-0951339c-3a58-4b9f-9404-fbfe4e79fdd6",
          "traceId": "4b9cc1cc",
          "type": "GENERATION",
          "name": "4b9c_psg_gen_attempt#2",
          "startTime": "2026-02-23T21:43:32.074000+00:00",
          "endTime": "2026-02-23T21:43:48.971000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16897.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-43-49-125232_chatcmpl-44d1e669-410b-49a5-9726-dde056f583a4",
          "traceId": "4b9cc1cc",
          "type": "GENERATION",
          "name": "4b9c_psg_gen_attempt#3",
          "startTime": "2026-02-23T21:43:49.125000+00:00",
          "endTime": "2026-02-23T21:44:05.933000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16808.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-44-06-081939_chatcmpl-986e8a30-dabb-4239-8617-01fd9255e510",
          "traceId": "4b9cc1cc",
          "type": "GENERATION",
          "name": "4b9c_psg_gen_attempt#4",
          "startTime": "2026-02-23T21:44:06.081000+00:00",
          "endTime": "2026-02-23T21:44:22.903000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16822.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-44-23-071606_chatcmpl-a35c87c7-c9e7-4f32-afcf-26c3730104fa",
          "traceId": "4b9cc1cc",
          "type": "GENERATION",
          "name": "4b9c_psg_gen_attempt#5",
          "startTime": "2026-02-23T21:44:23.071000+00:00",
          "endTime": "2026-02-23T21:44:39.839000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16768.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "83444241-33cf-49b5-995b-d26d9932a234",
          "traceId": "4b9cc1cc",
          "type": "SPAN",
          "name": "error_4b_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-23T21:44:39.991000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223234439_psg_qwen2.5-coder:32b/tmp_20260223234439_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-23T21:44:45.309Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:43:15.152Z"
    },
    {
      "id": "45de0a3f",
      "timestamp": "2026-02-23T21:41:23.180000+00:00",
      "name": "45de_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    height, width = input_shape[1:3]\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    input_data = input_data.astype(np.float32) / 255.0\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223234248_psg_qwen2.5-coder:32b/tmp_20260223234248_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 9
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 85.018,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-41-23-180742_chatcmpl-40b23386-1f12-430e-b920-4edde6f910aa",
          "traceId": "45de0a3f",
          "type": "GENERATION",
          "name": "45de_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:41:23.180000+00:00",
          "endTime": "2026-02-23T21:41:40.367000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17187.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-41-40-525544_chatcmpl-bafb9789-26ed-4b6b-ad67-963f61b6cb9c",
          "traceId": "45de0a3f",
          "type": "GENERATION",
          "name": "45de_psg_gen_attempt#2",
          "startTime": "2026-02-23T21:41:40.525000+00:00",
          "endTime": "2026-02-23T21:41:57.302000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16777.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-41-57-463454_chatcmpl-54b2c1af-1d41-4273-98d3-0b71718e4b68",
          "traceId": "45de0a3f",
          "type": "GENERATION",
          "name": "45de_psg_gen_attempt#3",
          "startTime": "2026-02-23T21:41:57.463000+00:00",
          "endTime": "2026-02-23T21:42:14.202000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16739.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-42-14-361129_chatcmpl-0c8ac9ae-69b6-470a-ab9c-51e681f22bdd",
          "traceId": "45de0a3f",
          "type": "GENERATION",
          "name": "45de_psg_gen_attempt#4",
          "startTime": "2026-02-23T21:42:14.361000+00:00",
          "endTime": "2026-02-23T21:42:31.106000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16745.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-42-31-259677_chatcmpl-aaed4580-e35b-4a04-88a1-891d03ed38b8",
          "traceId": "45de0a3f",
          "type": "GENERATION",
          "name": "45de_psg_gen_attempt#5",
          "startTime": "2026-02-23T21:42:31.259000+00:00",
          "endTime": "2026-02-23T21:42:48.047000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16788.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "64908855-dde9-4455-9925-c13115f574f2",
          "traceId": "45de0a3f",
          "type": "SPAN",
          "name": "error_45_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-23T21:42:48.198000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223234248_psg_qwen2.5-coder:32b/tmp_20260223234248_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-23T21:42:53.609Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:41:23.695Z"
    },
    {
      "id": "3ebcbf92",
      "timestamp": "2026-02-23T21:39:31.547000+00:00",
      "name": "3ebc_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    height, width = input_shape[1:3]\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    input_data = input_data.astype(np.float32) / 255.0\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223234056_psg_qwen2.5-coder:32b/tmp_20260223234056_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 8
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 85.265,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-39-31-548205_chatcmpl-234cbab4-be0b-4ce7-803d-1ad160eed21f",
          "traceId": "3ebcbf92",
          "type": "GENERATION",
          "name": "3ebc_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:39:31.548000+00:00",
          "endTime": "2026-02-23T21:39:48.401000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16853.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-39-49-059330_chatcmpl-df727d9c-42bc-4a0b-b4bb-e665c23561c1",
          "traceId": "3ebcbf92",
          "type": "GENERATION",
          "name": "3ebc_psg_gen_attempt#2",
          "startTime": "2026-02-23T21:39:49.059000+00:00",
          "endTime": "2026-02-23T21:40:05.798000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16739.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-40-05-952751_chatcmpl-0a140540-5a39-4899-8016-b71c570e2f55",
          "traceId": "3ebcbf92",
          "type": "GENERATION",
          "name": "3ebc_psg_gen_attempt#3",
          "startTime": "2026-02-23T21:40:05.952000+00:00",
          "endTime": "2026-02-23T21:40:22.892000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16940.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-40-23-059074_chatcmpl-79679e13-3a88-48e8-8d7d-9d9b5cd373a5",
          "traceId": "3ebcbf92",
          "type": "GENERATION",
          "name": "3ebc_psg_gen_attempt#4",
          "startTime": "2026-02-23T21:40:23.059000+00:00",
          "endTime": "2026-02-23T21:40:39.791000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16732.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-40-39-949629_chatcmpl-5673a3b7-5fae-4414-8ba2-eb042d787909",
          "traceId": "3ebcbf92",
          "type": "GENERATION",
          "name": "3ebc_psg_gen_attempt#5",
          "startTime": "2026-02-23T21:40:39.949000+00:00",
          "endTime": "2026-02-23T21:40:56.665000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16716.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "2663d1ae-f6e7-4ba4-877e-85dd1f057a3e",
          "traceId": "3ebcbf92",
          "type": "SPAN",
          "name": "error_3e_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-23T21:40:56.813000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223234056_psg_qwen2.5-coder:32b/tmp_20260223234056_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-23T21:41:02.205Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:39:32.067Z"
    },
    {
      "id": "c0495a9e",
      "timestamp": "2026-02-23T21:37:39.614000+00:00",
      "name": "c049_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    height, width = input_shape[1:3]\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    input_data = input_data.astype(np.float32) / 255.0\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223233904_psg_qwen2.5-coder:32b/tmp_20260223233904_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 7
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 84.639,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-37-39-615387_chatcmpl-60a23b08-6e08-46d0-9a3b-3a0562b13151",
          "traceId": "c0495a9e",
          "type": "GENERATION",
          "name": "c049_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:37:39.615000+00:00",
          "endTime": "2026-02-23T21:37:56.483000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16868.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-37-56-640002_chatcmpl-8d2a0ebf-76da-4fd3-8d7e-72c54c96f2a5",
          "traceId": "c0495a9e",
          "type": "GENERATION",
          "name": "c049_psg_gen_attempt#2",
          "startTime": "2026-02-23T21:37:56.640000+00:00",
          "endTime": "2026-02-23T21:38:13.355000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16715.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-38-13-516849_chatcmpl-25ae5bcc-ecd4-4c06-95d8-c15c203fbb78",
          "traceId": "c0495a9e",
          "type": "GENERATION",
          "name": "c049_psg_gen_attempt#3",
          "startTime": "2026-02-23T21:38:13.516000+00:00",
          "endTime": "2026-02-23T21:38:30.244000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16728.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-38-30-392686_chatcmpl-067064f3-4291-45a8-98b6-f4adefd9cfb3",
          "traceId": "c0495a9e",
          "type": "GENERATION",
          "name": "c049_psg_gen_attempt#4",
          "startTime": "2026-02-23T21:38:30.392000+00:00",
          "endTime": "2026-02-23T21:38:47.144000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16752.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-38-47-310790_chatcmpl-28a9fb28-62f9-46e8-9b3f-b9fd3415dc39",
          "traceId": "c0495a9e",
          "type": "GENERATION",
          "name": "c049_psg_gen_attempt#5",
          "startTime": "2026-02-23T21:38:47.310000+00:00",
          "endTime": "2026-02-23T21:39:04.091000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16781.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "71152293-4180-44f0-b59d-8699799ea371",
          "traceId": "c0495a9e",
          "type": "SPAN",
          "name": "error_c0_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-23T21:39:04.254000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223233904_psg_qwen2.5-coder:32b/tmp_20260223233904_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-23T21:39:09.994Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:37:40.142Z"
    },
    {
      "id": "dc81b3fd",
      "timestamp": "2026-02-23T21:35:47.415000+00:00",
      "name": "dc81_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    height, width = input_shape[1:3]\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    input_data = input_data.astype(np.float32) / 255.0\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223233711_psg_qwen2.5-coder:32b/tmp_20260223233711_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 6
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 84.689,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-35-47-416007_chatcmpl-0f9c935b-14aa-4227-8d24-213bbf5d5825",
          "traceId": "dc81b3fd",
          "type": "GENERATION",
          "name": "dc81_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:35:47.416000+00:00",
          "endTime": "2026-02-23T21:36:04.226000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16810.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-36-04-381790_chatcmpl-bfb6a70f-24d4-4cf8-af08-d036d5003896",
          "traceId": "dc81b3fd",
          "type": "GENERATION",
          "name": "dc81_psg_gen_attempt#2",
          "startTime": "2026-02-23T21:36:04.381000+00:00",
          "endTime": "2026-02-23T21:36:21.153000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16772.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-36-21-323782_chatcmpl-f939e0b2-87d3-4d02-8239-f65238803e15",
          "traceId": "dc81b3fd",
          "type": "GENERATION",
          "name": "dc81_psg_gen_attempt#3",
          "startTime": "2026-02-23T21:36:21.323000+00:00",
          "endTime": "2026-02-23T21:36:38.041000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16718.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-36-38-210164_chatcmpl-5dea0aa5-b2a3-4900-b1c3-f5c5673db24a",
          "traceId": "dc81b3fd",
          "type": "GENERATION",
          "name": "dc81_psg_gen_attempt#4",
          "startTime": "2026-02-23T21:36:38.210000+00:00",
          "endTime": "2026-02-23T21:36:54.987000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16777.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-36-55-139580_chatcmpl-03e9fcfc-adbd-4116-8614-caee4ff6fd34",
          "traceId": "dc81b3fd",
          "type": "GENERATION",
          "name": "dc81_psg_gen_attempt#5",
          "startTime": "2026-02-23T21:36:55.139000+00:00",
          "endTime": "2026-02-23T21:37:11.948000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16809.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "8cdfcb40-8eaf-4e7b-9b79-6cc60079f843",
          "traceId": "dc81b3fd",
          "type": "SPAN",
          "name": "error_dc_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-23T21:37:12.105000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223233711_psg_qwen2.5-coder:32b/tmp_20260223233711_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-23T21:37:17.985Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:35:47.936Z"
    },
    {
      "id": "61077eb3",
      "timestamp": "2026-02-23T21:33:55.840000+00:00",
      "name": "6107_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    height, width = input_shape[1:3]\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    input_data = input_data.astype(np.float32) / 255.0\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223233520_psg_qwen2.5-coder:32b/tmp_20260223233520_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 5
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 84.838,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-33-55-841217_chatcmpl-071b2674-01aa-4eef-b5e4-39fe3618caab",
          "traceId": "61077eb3",
          "type": "GENERATION",
          "name": "6107_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:33:55.841000+00:00",
          "endTime": "2026-02-23T21:34:12.704000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16863.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-34-12-860834_chatcmpl-4bba199f-b8a2-4180-98f5-3f8c4edd3aff",
          "traceId": "61077eb3",
          "type": "GENERATION",
          "name": "6107_psg_gen_attempt#2",
          "startTime": "2026-02-23T21:34:12.860000+00:00",
          "endTime": "2026-02-23T21:34:29.633000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16773.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-34-29-801712_chatcmpl-fdc5614b-30fd-4018-adcf-70a68fdaa616",
          "traceId": "61077eb3",
          "type": "GENERATION",
          "name": "6107_psg_gen_attempt#3",
          "startTime": "2026-02-23T21:34:29.801000+00:00",
          "endTime": "2026-02-23T21:34:46.611000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16810.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-34-46-774676_chatcmpl-54bd8a93-cfb9-48e0-bfc6-70934e9a9512",
          "traceId": "61077eb3",
          "type": "GENERATION",
          "name": "6107_psg_gen_attempt#4",
          "startTime": "2026-02-23T21:34:46.774000+00:00",
          "endTime": "2026-02-23T21:35:03.592000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16818.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-35-03-761243_chatcmpl-4458feac-7ebf-4fb8-a344-7506410963a4",
          "traceId": "61077eb3",
          "type": "GENERATION",
          "name": "6107_psg_gen_attempt#5",
          "startTime": "2026-02-23T21:35:03.761000+00:00",
          "endTime": "2026-02-23T21:35:20.491000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16730.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "9fab05e0-2547-4236-ade4-df85a2b984ae",
          "traceId": "61077eb3",
          "type": "SPAN",
          "name": "error_61_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-23T21:35:20.679000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223233520_psg_qwen2.5-coder:32b/tmp_20260223233520_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-23T21:35:26.289Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:33:56.364Z"
    },
    {
      "id": "3309ade0",
      "timestamp": "2026-02-23T21:32:04.431000+00:00",
      "name": "3309_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    height, width = input_shape[1:3]\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    input_data = input_data.astype(np.float32) / 255.0\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223233329_psg_qwen2.5-coder:32b/tmp_20260223233329_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 4
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 85.411,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-32-04-432944_chatcmpl-c341f514-440c-422c-8c6a-21f4d3d6626b",
          "traceId": "3309ade0",
          "type": "GENERATION",
          "name": "3309_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:32:04.432000+00:00",
          "endTime": "2026-02-23T21:32:21.329000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16897.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-32-21-818741_chatcmpl-7517b595-9974-4b16-a8e1-d3d01ab0b904",
          "traceId": "3309ade0",
          "type": "GENERATION",
          "name": "3309_psg_gen_attempt#2",
          "startTime": "2026-02-23T21:32:21.818000+00:00",
          "endTime": "2026-02-23T21:32:38.704000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16886.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-32-38-860502_chatcmpl-b5ad51e7-2f3a-45e1-a1a1-6e2f38ffd05f",
          "traceId": "3309ade0",
          "type": "GENERATION",
          "name": "3309_psg_gen_attempt#3",
          "startTime": "2026-02-23T21:32:38.860000+00:00",
          "endTime": "2026-02-23T21:32:55.787000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16927.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-32-55-950547_chatcmpl-484d75e6-e5c2-4394-aa39-515b157a44b0",
          "traceId": "3309ade0",
          "type": "GENERATION",
          "name": "3309_psg_gen_attempt#4",
          "startTime": "2026-02-23T21:32:55.950000+00:00",
          "endTime": "2026-02-23T21:33:12.751000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16801.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-33-12-904693_chatcmpl-2daa38a5-9b46-4033-9993-e7d08deb32c8",
          "traceId": "3309ade0",
          "type": "GENERATION",
          "name": "3309_psg_gen_attempt#5",
          "startTime": "2026-02-23T21:33:12.904000+00:00",
          "endTime": "2026-02-23T21:33:29.678000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16774.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "fe1ff47d-d42e-4db1-84fe-8997d896658e",
          "traceId": "3309ade0",
          "type": "SPAN",
          "name": "error_33_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-23T21:33:29.843000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223233329_psg_qwen2.5-coder:32b/tmp_20260223233329_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-23T21:33:35.094Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:32:04.959Z"
    },
    {
      "id": "e8e72e7d",
      "timestamp": "2026-02-23T21:30:12.370000+00:00",
      "name": "e8e7_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    height, width = input_shape[1:3]\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    input_data = input_data.astype(np.float32) / 255.0\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223233137_psg_qwen2.5-coder:32b/tmp_20260223233137_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 3
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 84.828,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-30-12-371678_chatcmpl-a58db01f-9996-47ac-83c6-c462cd35c9f3",
          "traceId": "e8e72e7d",
          "type": "GENERATION",
          "name": "e8e7_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:30:12.371000+00:00",
          "endTime": "2026-02-23T21:30:29.270000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16899.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-30-29-424541_chatcmpl-173d0223-35a5-49c7-9646-82446be2e5b5",
          "traceId": "e8e72e7d",
          "type": "GENERATION",
          "name": "e8e7_psg_gen_attempt#2",
          "startTime": "2026-02-23T21:30:29.424000+00:00",
          "endTime": "2026-02-23T21:30:46.206000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16782.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-30-46-360477_chatcmpl-82ebf5da-cd22-4966-9caa-ff3b9eaeec36",
          "traceId": "e8e72e7d",
          "type": "GENERATION",
          "name": "e8e7_psg_gen_attempt#3",
          "startTime": "2026-02-23T21:30:46.360000+00:00",
          "endTime": "2026-02-23T21:31:03.103000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16743.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-31-03-253363_chatcmpl-7c72e9c9-66c7-4db7-b242-681c617352d0",
          "traceId": "e8e72e7d",
          "type": "GENERATION",
          "name": "e8e7_psg_gen_attempt#4",
          "startTime": "2026-02-23T21:31:03.253000+00:00",
          "endTime": "2026-02-23T21:31:20.114000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16861.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-31-20-285962_chatcmpl-b3d33b7e-2329-4c0b-9543-c8da5ce67946",
          "traceId": "e8e72e7d",
          "type": "GENERATION",
          "name": "e8e7_psg_gen_attempt#5",
          "startTime": "2026-02-23T21:31:20.285000+00:00",
          "endTime": "2026-02-23T21:31:37.039000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16754.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "e0f8aa71-ae27-4bc0-93ab-aae752327c26",
          "traceId": "e8e72e7d",
          "type": "SPAN",
          "name": "error_e8_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-23T21:31:37.199000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223233137_psg_qwen2.5-coder:32b/tmp_20260223233137_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-23T21:31:42.991Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:30:12.895Z"
    },
    {
      "id": "e38d9a4c",
      "timestamp": "2026-02-23T21:28:20.694000+00:00",
      "name": "e38d_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    height, width = input_shape[1:3]\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    input_data = input_data.astype(np.float32) / 255.0\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223232945_psg_qwen2.5-coder:32b/tmp_20260223232945_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 2
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 85.402,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-28-20-695504_chatcmpl-4af7c81e-647e-4217-aa21-93fcfe4e4470",
          "traceId": "e38d9a4c",
          "type": "GENERATION",
          "name": "e38d_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:28:20.695000+00:00",
          "endTime": "2026-02-23T21:28:38.094000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17399.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-28-38-257565_chatcmpl-74d58bd2-0eb4-493f-8de1-4585bcec2b0b",
          "traceId": "e38d9a4c",
          "type": "GENERATION",
          "name": "e38d_psg_gen_attempt#2",
          "startTime": "2026-02-23T21:28:38.257000+00:00",
          "endTime": "2026-02-23T21:28:55.044000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16787.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-28-55-202269_chatcmpl-8d3879c4-eb02-4bba-b499-097a7fb59df8",
          "traceId": "e38d9a4c",
          "type": "GENERATION",
          "name": "e38d_psg_gen_attempt#3",
          "startTime": "2026-02-23T21:28:55.202000+00:00",
          "endTime": "2026-02-23T21:29:12.022000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16820.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-29-12-169244_chatcmpl-4b2e9e1c-b9bd-4df1-bcc4-df04a92a2d3d",
          "traceId": "e38d9a4c",
          "type": "GENERATION",
          "name": "e38d_psg_gen_attempt#4",
          "startTime": "2026-02-23T21:29:12.169000+00:00",
          "endTime": "2026-02-23T21:29:29.029000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16860.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-29-29-184536_chatcmpl-deef65ed-806f-45d4-85b9-8d7bcfb08a8a",
          "traceId": "e38d9a4c",
          "type": "GENERATION",
          "name": "e38d_psg_gen_attempt#5",
          "startTime": "2026-02-23T21:29:29.184000+00:00",
          "endTime": "2026-02-23T21:29:45.937000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16753.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "acac7733-76da-4c5b-9bc9-0e2c7900242d",
          "traceId": "e38d9a4c",
          "type": "SPAN",
          "name": "error_e3_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-23T21:29:46.097000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223232945_psg_qwen2.5-coder:32b/tmp_20260223232945_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-23T21:29:51.405Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:28:21.219Z"
    },
    {
      "id": "d081869f",
      "timestamp": "2026-02-23T21:25:59.252000+00:00",
      "name": "d081_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    height, width = input_shape[1:3]\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    input_data = input_data.astype(np.float32) / 255.0\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Draw bounding boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223232754_psg_qwen2.5-coder:32b/tmp_20260223232754_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:32b_0d8f_psg_batch",
      "metadata": {
        "num_run": 1
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:32b"
      ],
      "latency": 115.053,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-25-59-253482_chatcmpl-072f8ecb-807a-40cc-9a02-59ac36fa7d6c",
          "traceId": "d081869f",
          "type": "GENERATION",
          "name": "d081_psg_gen_attempt#1",
          "startTime": "2026-02-23T21:25:59.253000+00:00",
          "endTime": "2026-02-23T21:26:45.969000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 46716.0,
          "totalTokens": 861,
          "costDetails": {},
          "completionTokens": 709,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-26-46-138049_chatcmpl-e3cbaeed-6c09-4318-a2db-38f0b383c2a3",
          "traceId": "d081869f",
          "type": "GENERATION",
          "name": "d081_psg_gen_attempt#2",
          "startTime": "2026-02-23T21:26:46.138000+00:00",
          "endTime": "2026-02-23T21:27:03.106000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16968.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-27-03-317354_chatcmpl-19d57f80-f386-49ce-9b9d-088b486c3567",
          "traceId": "d081869f",
          "type": "GENERATION",
          "name": "d081_psg_gen_attempt#3",
          "startTime": "2026-02-23T21:27:03.317000+00:00",
          "endTime": "2026-02-23T21:27:20.078000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16761.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-27-20-251638_chatcmpl-4139af1f-e3e1-4bbe-acff-da51ef37bbec",
          "traceId": "d081869f",
          "type": "GENERATION",
          "name": "d081_psg_gen_attempt#4",
          "startTime": "2026-02-23T21:27:20.251000+00:00",
          "endTime": "2026-02-23T21:27:37.103000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16852.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-27-37-267673_chatcmpl-8b074d75-8a63-4b0d-9316-2910cbb84d5a",
          "traceId": "d081869f",
          "type": "GENERATION",
          "name": "d081_psg_gen_attempt#5",
          "startTime": "2026-02-23T21:27:37.267000+00:00",
          "endTime": "2026-02-23T21:27:54.150000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16883.0,
          "totalTokens": 805,
          "costDetails": {},
          "completionTokens": 653,
          "promptTokens": 152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "0e351f4e-fc58-4d78-bad2-beb6f5c44f00",
          "traceId": "d081869f",
          "type": "SPAN",
          "name": "error_d0_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-23T21:27:54.306000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260223232754_psg_qwen2.5-coder:32b/tmp_20260223232754_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-23T21:27:59.624Z",
      "environment": "default",
      "createdAt": "2026-02-23T21:25:59.932Z"
    }
  ],
  "meta": {
    "total_items": 30
  }
}