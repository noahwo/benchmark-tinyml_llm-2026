{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"qwen2.5-coder:32b_17ec_psg_batch\",\n",
    "    \"qwen2.5-coder:32b_17ec_tpusg_batch\"\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session qwen2.5-coder:32b_17ec_psg_batch...\n",
      "Fetching observation data for time-18-28-19-912487_chatcmpl-9bb01d4c-df1f-455d-960b-bb920439e25a...\n",
      "Fetching observation data for time-18-28-39-070028_chatcmpl-5256f89f-5bc7-4b27-a37b-261b3898220c...\n",
      "Fetching observation data for time-18-29-03-197673_chatcmpl-d7682ac5-a510-4f46-bdaf-008081bf40c1...\n",
      "Fetching observation data for time-18-29-29-382392_chatcmpl-851d1b2f-c370-41e4-940e-c06f398c1f71...\n",
      "Fetching observation data for time-18-30-03-385596_chatcmpl-1e6f1656-eee4-4152-8706-f024ab784cb2...\n",
      "Fetching observation data for 2eb5a1cc-fd23-45e4-8419-998b16661516...\n",
      "Fetching observation data for time-18-27-21-345461_chatcmpl-df182231-8f6a-40f6-b6b4-d5edc1858d8d...\n",
      "Fetching observation data for time-18-26-23-836256_chatcmpl-10d64757-21e1-40da-b3f0-bf9e4ffe85cc...\n",
      "Fetching observation data for time-18-25-26-319483_chatcmpl-18f900ce-92a0-41c9-8637-69712ab26cd0...\n",
      "Fetching observation data for time-18-22-57-690868_chatcmpl-85e94d06-8217-4422-b61c-b6807de0314a...\n",
      "Fetching observation data for time-18-23-18-444095_chatcmpl-1a16f163-b077-4962-b66a-3a0161e21a99...\n",
      "Fetching observation data for time-18-23-50-770067_chatcmpl-b5755472-ef2c-4440-9ce5-fe32f3bb99ea...\n",
      "Fetching observation data for time-18-24-18-819136_chatcmpl-6ea3b70c-a216-4491-bb95-0ca9ab00e34e...\n",
      "Fetching observation data for time-18-24-50-418922_chatcmpl-a51b638e-4203-4577-ac78-f7a64fb7c7ad...\n",
      "Fetching observation data for dca92a0a-2528-4e8a-a148-88d47885a7c7...\n",
      "Fetching observation data for time-18-20-02-144159_chatcmpl-d46a3f98-a821-4de1-87c6-e9c19a22b825...\n",
      "Fetching observation data for time-18-21-01-904214_chatcmpl-f5f3535f-feda-4f6e-b2ea-20f531b7ff8e...\n",
      "Fetching observation data for time-18-21-30-351170_chatcmpl-cdd05ef1-c185-41aa-be0f-6ddae125f0ad...\n",
      "Fetching observation data for time-18-22-03-016325_chatcmpl-6b5a6d2f-ec55-463b-be09-8547331a9ecd...\n",
      "Fetching observation data for time-18-22-30-348758_chatcmpl-6bf4c901-2e48-460c-80fc-4d7b3ea8cde9...\n",
      "Fetching observation data for b57dc2b9-db24-437f-a23c-c3d83753f1f2...\n",
      "Fetching observation data for time-18-19-05-583135_chatcmpl-4b38cbbc-ae00-4dba-90f0-9384e8977ef0...\n",
      "Fetching observation data for time-18-18-06-022243_chatcmpl-b3f5d643-2f8c-40a8-b33e-d0f120688dce...\n",
      "Fetching observation data for time-18-15-51-453952_chatcmpl-4a3cca0f-236a-4280-9f20-1883492444e7...\n",
      "Fetching observation data for time-18-16-11-934321_chatcmpl-f19b288e-28f6-483e-a22c-ea1f6163a959...\n",
      "Fetching observation data for time-18-16-41-045570_chatcmpl-a1f487a4-c322-48b5-9b21-95616ce4ce1e...\n",
      "Fetching observation data for time-18-17-11-560882_chatcmpl-add8d345-82b5-4ec2-a8ae-e57717a22526...\n",
      "Fetching observation data for time-18-17-36-463898_chatcmpl-aecba8ec-e1f0-4fd6-a64e-1c85a9fcdcc2...\n",
      "Fetching observation data for 2e91f593-5322-49e2-8356-9d97916c2de0...\n",
      "Fetching observation data for time-18-13-51-502985_chatcmpl-c2a597d1-6ab6-4951-a3f6-7e8c2db780c2...\n",
      "Fetching observation data for time-18-14-09-651551_chatcmpl-23b830bb-b9f8-4114-bd22-9fc482003fc3...\n",
      "Fetching observation data for time-18-14-41-317986_chatcmpl-742e1e50-0aaf-4fd6-8edf-5be5beef6cbc...\n",
      "Fetching observation data for time-18-10-58-495033_chatcmpl-c70ed27b-ba04-4e21-8b3b-6392fd9f114c...\n",
      "Fetching observation data for time-18-11-18-335728_chatcmpl-7a3e5507-a80b-4a50-b994-1e24809c9b3a...\n",
      "Fetching observation data for time-18-11-44-954749_chatcmpl-415846ee-951d-4d02-acb6-b53e87a54ee0...\n",
      "Fetching observation data for time-18-12-10-546205_chatcmpl-c1d1e6cf-3831-4cfa-ab96-7f28a5d48373...\n",
      "Fetching observation data for time-18-12-29-220684_chatcmpl-6100f3ea-4cf6-45ad-9dcb-480b079d1cc3...\n",
      "Fetching observation data for 61e21b60-ebe9-4cba-98d4-0cd034ef466d...\n",
      "Fetching observation data for time-18-08-44-973813_chatcmpl-fde64ebb-9083-49c5-9afb-f8d345c7d4c8...\n",
      "Fetching observation data for time-18-09-05-552768_chatcmpl-7fc0afa4-89b6-4efd-9e94-91718f964941...\n",
      "Fetching observation data for time-18-09-30-283152_chatcmpl-c4cbb26f-2a94-438e-a24e-270abadebc39...\n",
      "Fetching observation data for time-18-10-01-620921_chatcmpl-8639c3e6-7942-4b86-95a3-4b723a140832...\n",
      "Fetching observation data for time-18-10-28-033918_chatcmpl-f481ef2f-0da6-4fe4-b0c2-0c0be60b1eb0...\n",
      "Fetching observation data for 9dddf0d6-a8c6-4248-8e2b-0c1a37d376d5...\n",
      "Fetching observation data for time-18-06-35-322999_chatcmpl-7a24323f-ce99-461c-aa5e-b9ab47c585e1...\n",
      "Fetching observation data for time-18-06-54-333743_chatcmpl-9c934782-1456-46f0-a143-2462cb032ef7...\n",
      "Fetching observation data for time-18-07-17-295522_chatcmpl-4e8bdf96-ee7b-4c97-bc0b-9eb538a42890...\n",
      "Fetching observation data for time-18-07-39-526849_chatcmpl-16d04908-7813-42fe-a0ba-ba712958f955...\n",
      "Fetching observation data for time-18-08-04-263764_chatcmpl-ef66d7ce-2816-4c0d-9183-7223928f4079...\n",
      "Fetching observation data for 1430ca62-5e3d-42a0-b66a-264865894735...\n",
      "Fetching observation data for time-18-04-21-771080_chatcmpl-075d442c-4eaf-47d6-9087-8125eef8bd8c...\n",
      "Fetching observation data for time-18-04-42-892793_chatcmpl-3c461e45-9fc9-45e4-9b52-b2be77d6f937...\n",
      "Fetching observation data for time-18-05-07-359006_chatcmpl-536f78a0-366c-4616-ba92-018bf846502d...\n",
      "Fetching observation data for time-18-05-36-893619_chatcmpl-803243db-54af-4ca8-abbd-6769504f667a...\n",
      "Fetching observation data for time-18-05-59-134363_chatcmpl-2a9e4aa4-a64e-4a44-9d76-9485cd5794ee...\n",
      "Fetching observation data for 0a9a48ae-88c8-47f4-ae28-eb5706283c97...\n",
      "Fetching observation data for time-18-02-11-227786_chatcmpl-56272c4e-3060-440c-9d66-e48dae2fa410...\n",
      "Fetching observation data for time-18-02-30-532873_chatcmpl-d5d39d16-9897-45f4-b39d-86218eea7219...\n",
      "Fetching observation data for time-18-02-59-059995_chatcmpl-a8c1729d-13da-45e9-a291-cfcf774bf3bf...\n",
      "Fetching observation data for time-18-03-23-377690_chatcmpl-dfb9eb91-1a02-4c80-8454-443b8def9292...\n",
      "Fetching observation data for time-18-03-51-892353_chatcmpl-a927a9df-2a1b-4cda-8eae-e8c5b21bbda1...\n",
      "Fetching observation data for a41911e8-a7b5-483d-a431-f6b1d506d9e4...\n",
      "Fetching observation data for time-17-59-47-651768_chatcmpl-d910e5f2-56b8-4aea-b967-44a4aed255ec...\n",
      "Fetching observation data for time-18-00-09-736679_chatcmpl-cbde0c52-24ab-4b19-b8df-b65d3e470880...\n",
      "Fetching observation data for time-18-00-33-515802_chatcmpl-30ff0b95-b5d9-4e5d-82f8-c1b9133a5d85...\n",
      "Fetching observation data for time-18-01-07-239929_chatcmpl-4508abba-c7bf-4154-b6dc-68d3615fb538...\n",
      "Fetching observation data for time-17-57-30-109898_chatcmpl-4879780e-203b-4f8a-94fa-e7d44d86e432...\n",
      "Fetching observation data for time-17-57-51-636467_chatcmpl-4a6098bc-44b0-4ac4-b7f6-2790956a81d4...\n",
      "Fetching observation data for time-17-58-19-850125_chatcmpl-1e7fec44-4620-4d4f-af5f-dea089a87ac2...\n",
      "Fetching observation data for time-17-58-48-323558_chatcmpl-e6f200c4-ef5b-4b9b-b3e4-1ac0669e8ef4...\n",
      "Fetching observation data for time-17-59-12-655288_chatcmpl-e7678b54-bc49-4029-9929-420598589c76...\n",
      "Fetching observation data for 8ea1ccbf-a509-4228-8894-e158c3bd3109...\n",
      "Fetching observation data for time-17-55-15-364228_chatcmpl-ed989de6-66c9-4d75-8da1-b79e4a20fd0a...\n",
      "Fetching observation data for time-17-55-36-953759_chatcmpl-9091f6de-4617-4b8c-912e-41f53894966d...\n",
      "Fetching observation data for time-17-56-01-180111_chatcmpl-92347504-735a-4325-8703-df9d69618a82...\n",
      "Fetching observation data for time-17-56-28-126129_chatcmpl-f8b1525d-d0a4-4f25-b160-e13e3cdb226f...\n",
      "Fetching observation data for time-17-56-57-306228_chatcmpl-b90effec-0bb2-4474-895f-54d4692d5b3d...\n",
      "Fetching observation data for 8e188d9f-98a5-44c5-8154-6e4d0eb29463...\n",
      "Fetching observation data for time-17-52-54-486870_chatcmpl-c0380251-1efa-448c-b730-a95b4fa208cd...\n",
      "Fetching observation data for time-17-53-13-853504_chatcmpl-67b60cd6-453a-49e9-8bee-305b88b66bfd...\n",
      "Fetching observation data for time-17-53-39-678572_chatcmpl-686b8102-3cf5-4f93-b74d-dcc896470a15...\n",
      "Fetching observation data for time-17-54-11-208982_chatcmpl-016b7f5e-717d-4d78-8779-f057a69f134b...\n",
      "Fetching observation data for time-17-54-39-249508_chatcmpl-4cd1a1f7-4ad6-41b7-ae55-b7a9a20e5c66...\n",
      "Fetching observation data for fa9715ca-2a16-4172-a89c-729a2a8e3781...\n",
      "Fetching observation data for time-17-50-42-935257_chatcmpl-3b0bef08-aa0c-4b07-9ef9-f5e495b48242...\n",
      "Fetching observation data for time-17-51-03-968840_chatcmpl-4e3cf779-5f2c-4a1e-8fb1-33c92835829d...\n",
      "Fetching observation data for time-17-51-28-054523_chatcmpl-1e364e72-985c-4283-bb1d-3dcea4de8658...\n",
      "Fetching observation data for time-17-51-51-519371_chatcmpl-60478be3-958a-4ada-b1f9-28a3f2da525d...\n",
      "Fetching observation data for time-17-52-23-871557_chatcmpl-843361ba-c2a9-4ba6-a56d-f7e2a815023b...\n",
      "Fetching observation data for efadca21-bb66-47ea-a6bf-9a0b2d32195b...\n",
      "Fetching observation data for time-17-48-27-321050_chatcmpl-8076a39e-447e-4d1c-b8ee-e929343e0e39...\n",
      "Fetching observation data for time-17-48-50-306487_chatcmpl-3cee98f6-c07f-4655-bf0c-cbe013d447fe...\n",
      "Fetching observation data for time-17-49-15-800668_chatcmpl-2a8fb1bf-0e00-4bfa-880a-7faf79941c5a...\n",
      "Fetching observation data for time-17-49-42-782620_chatcmpl-5a9b18e1-1e26-482c-92dd-9d2adda5c3b3...\n",
      "Fetching observation data for time-17-50-10-198833_chatcmpl-28a0c25e-b141-46f4-b87b-c1d3aa7cc3b1...\n",
      "Fetching observation data for 94c7f5a7-5b29-4a7d-b005-32ebdb699275...\n",
      "Fetching observation data for time-17-47-29-751568_chatcmpl-32593cb7-8a18-4413-bafe-1f735343303d...\n",
      "Fetching observation data for time-17-47-49-874135_chatcmpl-5702fc32-85eb-476d-898e-5803bb422c62...\n",
      "Fetching observation data for time-17-45-10-937580_chatcmpl-8603e8ae-f11e-45de-8414-399dc7759785...\n",
      "Fetching observation data for time-17-45-32-394427_chatcmpl-c8de3dba-4421-4f04-aa3a-22c88c67ef52...\n",
      "Fetching observation data for time-17-45-57-128176_chatcmpl-a312cb7c-c290-423e-a0cc-8c76137c7bb4...\n",
      "Fetching observation data for time-17-46-13-167308_chatcmpl-b56c2197-4285-4576-bbc3-593e306c0d01...\n",
      "Fetching observation data for time-17-46-42-958259_chatcmpl-5ca0d6b7-037b-466e-98d8-8237fb05adbe...\n",
      "Fetching observation data for 8df9994d-609c-4175-a3a6-0343a87a8d0e...\n",
      "Fetching observation data for time-17-43-01-402450_chatcmpl-363ead8d-b6d9-4eff-88e6-e064457cd309...\n",
      "Fetching observation data for time-17-43-20-432350_chatcmpl-fb13e705-3a59-438e-9e04-ff0f94b2ac50...\n",
      "Fetching observation data for time-17-43-49-463112_chatcmpl-6f6bc57e-eacd-4b5c-abda-b8e4ae2ea728...\n",
      "Fetching observation data for time-17-44-15-330082_chatcmpl-c18191f6-8941-40e7-a982-abd8c288ee0e...\n",
      "Fetching observation data for time-17-44-40-470796_chatcmpl-b5f04af4-9937-4c83-9159-0e47def699a9...\n",
      "Fetching observation data for 792ec3dd-1267-43cc-a624-545bc4f033dd...\n",
      "Fetching observation data for time-17-41-00-819830_chatcmpl-e8b4da17-a6a3-4983-888d-74bdcf2f4dd4...\n",
      "Fetching observation data for time-17-41-20-531225_chatcmpl-da7cce9f-ae16-4626-85eb-5d40b52ca9d1...\n",
      "Fetching observation data for time-17-41-53-897320_chatcmpl-8f092c7e-8cdf-4cf1-a50d-b65885c55d33...\n",
      "Fetching observation data for time-17-39-37-309351_chatcmpl-a61b52b6-f346-4218-93ee-24f6fd7848a2...\n",
      "Fetching observation data for time-17-39-57-764428_chatcmpl-f52d2b38-2218-4f64-a14b-aade2b952b2f...\n",
      "Fetching observation data for time-17-38-39-781159_chatcmpl-427a79b4-6878-44f8-8cec-df29bb2baa80...\n",
      "Fetching observation data for time-17-36-14-184934_chatcmpl-56081056-c4ef-41df-b273-81a46daf070e...\n",
      "Fetching observation data for time-17-36-34-213479_chatcmpl-1e8fc58e-586d-4724-9393-245f566f8733...\n",
      "Fetching observation data for time-17-37-02-699430_chatcmpl-692927b8-4626-41a9-b0ec-4de3dfc1c861...\n",
      "Fetching observation data for time-17-37-27-854524_chatcmpl-2e958e8a-6d54-4ac0-b68d-3f7222cf267b...\n",
      "Fetching observation data for time-17-38-05-912401_chatcmpl-cdf1917f-9a36-436b-b6f2-4049849292c9...\n",
      "Fetching observation data for bdff62d9-5836-46b3-9147-790f09364351...\n",
      "Fetching observation data for time-17-33-50-599243_chatcmpl-63af26d6-7fdb-4126-8ea3-d5d1d9edec89...\n",
      "Fetching observation data for time-17-34-10-600043_chatcmpl-cb40bde2-2144-4b60-b38b-dec8be070f9d...\n",
      "Fetching observation data for time-17-34-37-944801_chatcmpl-2555d6de-e57f-4845-ae18-909b8df14830...\n",
      "Fetching observation data for time-17-35-05-838979_chatcmpl-e8b061c6-2d83-4525-aa8a-27011f0e8cc4...\n",
      "Fetching observation data for time-17-35-35-063702_chatcmpl-f05ab32a-859f-4039-b465-694077667771...\n",
      "Fetching observation data for 5950bc45-15c4-44b1-9cef-64afd4affb57...\n",
      "Fetching observation data for time-17-33-19-063078_chatcmpl-08699c2e-7144-4893-8c0c-e8c90d49b2a9...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.03/raw_export/raw_qwen2.5-coder:32b_17ec_psg_batch.json\n",
      "Fetching traces for session qwen2.5-coder:32b_17ec_tpusg_batch...\n",
      "Fetching observation data for time-17-31-55-468279_chatcmpl-a2b62e82-e438-4eb4-b035-f29069397c6e...\n",
      "Fetching observation data for time-17-30-33-850886_chatcmpl-8b3e94e1-ecbd-4b6a-94d3-504d9f7f4083...\n",
      "Fetching observation data for time-17-29-12-315613_chatcmpl-987efc06-33f0-4f54-84a2-f3d1e8ce36e3...\n",
      "Fetching observation data for time-17-27-49-751302_chatcmpl-c3e8ba57-3a81-43f0-9195-55085078d1ed...\n",
      "Fetching observation data for time-17-26-27-155774_chatcmpl-7f6b554b-d1b2-4d76-9335-a09a2cca35ac...\n",
      "Fetching observation data for time-17-23-10-548868_chatcmpl-816f5bc6-070b-4fa1-9eb8-416866a01a0e...\n",
      "Fetching observation data for time-17-23-42-146110_chatcmpl-6b4c402c-cfbb-4d75-912a-0e9483d97ff5...\n",
      "Fetching observation data for time-17-24-20-201065_chatcmpl-ec40a8ae-31d7-43b9-80bf-380b512cfcc5...\n",
      "Fetching observation data for time-17-24-59-084080_chatcmpl-973dfa78-e449-4bc3-a2ed-c10e2a5b7cfc...\n",
      "Fetching observation data for time-17-21-48-010318_chatcmpl-7197089d-39fe-455e-8c93-fde32c1e74d0...\n",
      "Fetching observation data for time-17-20-23-101583_chatcmpl-b505715b-12cd-44a1-97a7-43a8a8c6fca8...\n",
      "Fetching observation data for time-17-18-21-525135_chatcmpl-d9573b50-b729-4159-b5af-9b6517d6c4f2...\n",
      "Fetching observation data for time-17-18-52-182394_chatcmpl-72c5833c-1c86-4381-9812-feea6e4faad8...\n",
      "Fetching observation data for time-17-15-36-944658_chatcmpl-e57354de-b5e5-4b99-881f-a2029ff4183b...\n",
      "Fetching observation data for time-17-16-10-127097_chatcmpl-65330474-75eb-42ff-b115-e096fa3e3900...\n",
      "Fetching observation data for time-17-16-51-497170_chatcmpl-e475c757-bdf6-436c-b8c2-4ebe033174f3...\n",
      "Fetching observation data for time-17-14-15-109050_chatcmpl-56a2dde0-43b5-4fc5-817b-9588c7fa6215...\n",
      "Fetching observation data for time-17-12-21-549631_chatcmpl-7e5b2c5b-7ab9-47d1-8ec7-9149c1671bb8...\n",
      "Fetching observation data for time-17-12-50-366120_chatcmpl-b89e49e4-c398-4dcc-b6f8-9c168dc187f1...\n",
      "Fetching observation data for time-17-10-59-026728_chatcmpl-21ceb7a7-0f3a-4a6d-8e19-561cd5a1d56a...\n",
      "Fetching observation data for time-17-08-49-375738_chatcmpl-fbeb9818-4b2d-4040-a8df-cd1a39606000...\n",
      "Fetching observation data for time-17-09-25-001827_chatcmpl-0a45bb69-ef3a-4535-b022-e78920e0d893...\n",
      "Fetching observation data for time-17-07-26-372768_chatcmpl-612f4d5a-fe81-49cf-b57e-95685c55cab7...\n",
      "Fetching observation data for time-17-05-30-398580_chatcmpl-1b40799b-4193-41c1-8090-f69c48b722d0...\n",
      "Fetching observation data for time-17-06-03-588739_chatcmpl-3ce8635f-57e4-4a81-8787-388a15e1632f...\n",
      "Fetching observation data for time-17-01-36-771875_chatcmpl-5f36b6b8-7ba6-4312-8644-535aff722e06...\n",
      "Fetching observation data for time-17-02-07-801359_chatcmpl-85232fee-cdd6-46ce-9482-70e9fe09d8aa...\n",
      "Fetching observation data for time-17-02-43-745423_chatcmpl-fd75c3e8-5927-4606-8364-44abada6108e...\n",
      "Fetching observation data for time-17-03-21-932436_chatcmpl-e3199c6f-427f-4a19-92eb-a3dc63294aec...\n",
      "Fetching observation data for time-17-04-00-700405_chatcmpl-3f60f0ef-4241-415b-8938-525723fdf0ac...\n",
      "Fetching observation data for time-16-58-58-175606_chatcmpl-565675f5-7713-4818-b630-33585d52476a...\n",
      "Fetching observation data for time-16-59-31-290203_chatcmpl-06bc0343-232a-4b68-bc19-41697d687e32...\n",
      "Fetching observation data for time-17-00-09-546462_chatcmpl-c19d2863-205c-4bfe-b186-1937caba2277...\n",
      "Fetching observation data for time-16-57-35-537656_chatcmpl-77c9ba5b-a217-430a-98b6-d5635bb6bacd...\n",
      "Fetching observation data for time-16-56-12-004034_chatcmpl-e24e3d84-10fb-4950-b1d1-7fd7178fae42...\n",
      "Fetching observation data for time-16-54-11-043434_chatcmpl-e0e29e5f-3756-4634-ba83-36b4bb4c6890...\n",
      "Fetching observation data for time-16-54-42-414886_chatcmpl-1898e70a-8be5-47ad-83cf-0f0c238f7abe...\n",
      "Fetching observation data for time-16-52-48-114128_chatcmpl-aac22f85-5b78-4476-90fd-d1805ef3c2b2...\n",
      "Fetching observation data for time-16-50-07-481734_chatcmpl-76b6a3d0-8cac-4202-a423-8dc3e8bc3d14...\n",
      "Fetching observation data for time-16-50-39-413512_chatcmpl-8b10ead9-c111-405d-901e-2d5c8dc16d00...\n",
      "Fetching observation data for time-16-51-17-817276_chatcmpl-3e2ebfe9-a0f6-42a5-ad7a-3f1426f6d0b9...\n",
      "Fetching observation data for time-16-48-45-933502_chatcmpl-e0e273b8-982a-4ed0-840f-809f4d25f333...\n",
      "Fetching observation data for time-16-46-44-374625_chatcmpl-1f3b2c4f-25aa-4303-989b-04fc96d9cf6c...\n",
      "Fetching observation data for time-16-47-17-492756_chatcmpl-d5d0ca6c-e9dc-4a95-a206-51a337bbd5d1...\n",
      "Fetching observation data for time-16-44-40-817412_chatcmpl-ac30b174-1c89-48a4-8ab2-349e8f2bcc37...\n",
      "Fetching observation data for time-16-45-14-852501_chatcmpl-714badcd-74e2-4995-a21b-cabba1b82733...\n",
      "Fetching observation data for time-16-42-42-303005_chatcmpl-2732239d-fb6b-4b2c-bd70-e1f96574ff4d...\n",
      "Fetching observation data for time-16-43-12-853860_chatcmpl-8f0e5199-d912-4f5f-9ab6-6eb7a6ddf050...\n",
      "Fetching observation data for time-16-41-18-610680_chatcmpl-eb5c0366-6f58-40d5-86c9-d16564560394...\n",
      "Fetching observation data for time-16-39-56-040068_chatcmpl-eb71a0bc-b2f1-4e55-8ea2-d4d761b1a24d...\n",
      "Fetching observation data for time-16-38-33-477238_chatcmpl-41c19b02-8640-4a0b-a18c-8df3a71f04fd...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.03/raw_export/raw_qwen2.5-coder:32b_17ec_tpusg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_64_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804183030_psg_qwen2.5-coder:32b/tmp_20250804183030_psg_qwen2.5-coder:32b.py\", line 59, in <module>\n",
      "    num_detections = int(output_data[0][0])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_fe_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804182519_psg_qwen2.5-coder:32b/tmp_20250804182519_psg_qwen2.5-coder:32b.py\", line 62, in <module>\n",
      "    if detection[2] > 0.5:  # Confidence threshold\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "\n",
      "SPAN error_6f_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804182251_psg_qwen2.5-coder:32b/tmp_20250804182251_psg_qwen2.5-coder:32b.py\", line 58, in <module>\n",
      "    label = labels[k]\n",
      "TypeError: only integer scalar arrays can be converted to a scalar index\n",
      "\n",
      "SPAN error_2b_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804181759_psg_qwen2.5-coder:32b/tmp_20250804181759_psg_qwen2.5-coder:32b.py\", line 47, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_4c_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804181344_psg_qwen2.5-coder:32b/tmp_20250804181344_psg_qwen2.5-coder:32b.py\", line 170, in <module>\n",
      "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
      "NameError: name 'tf' is not defined\n",
      "\n",
      "SPAN error_2f_psg_failure_signal_py_sketch_generator: Failed. Last error: 2025-08-04 18:10:49.961923: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-04 18:10:49.966496: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-04 18:10:49.979880: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-04 18:10:50.000529: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-04 18:10:50.006940: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-04 18:10:50.022982: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-04 18:10:50.861989: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804181049_psg_qwen2.5-coder:32b/tmp_20250804181049_psg_qwen2.5-coder:32b.py\", line 58, in <module>\n",
      "    confidence_score = scores[top_index]\n",
      "IndexError: index 11 is out of bounds for axis 0 with size 10\n",
      "\n",
      "SPAN error_8f_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804180838_psg_qwen2.5-coder:32b/tmp_20250804180838_psg_qwen2.5-coder:32b.py\", line 23, in <module>\n",
      "    with open(label_path, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'your_label_map.txt'\n",
      "\n",
      "SPAN error_8d_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804180628_psg_qwen2.5-coder:32b/tmp_20250804180628_psg_qwen2.5-coder:32b.py\", line 21, in <module>\n",
      "    with open(label_path, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/path/to/your/labelmap.txt'\n",
      "\n",
      "SPAN error_3f_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804180414_psg_qwen2.5-coder:32b/tmp_20250804180414_psg_qwen2.5-coder:32b.py\", line 65, in <module>\n",
      "    label = labels[i]\n",
      "TypeError: only integer scalar arrays can be converted to a scalar index\n",
      "\n",
      "SPAN error_a1_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804175941_psg_qwen2.5-coder:32b/tmp_20250804175941_psg_qwen2.5-coder:32b.py\", line 50, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], img_normalized)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_36_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804175723_psg_qwen2.5-coder:32b/tmp_20250804175723_psg_qwen2.5-coder:32b.py\", line 54, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_86_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804175508_psg_qwen2.5-coder:32b/tmp_20250804175508_psg_qwen2.5-coder:32b.py\", line 60, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_93_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804175248_psg_qwen2.5-coder:32b/tmp_20250804175248_psg_qwen2.5-coder:32b.py\", line 40, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_02_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804175036_psg_qwen2.5-coder:32b/tmp_20250804175036_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_5a_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804174722_psg_qwen2.5-coder:32b/tmp_20250804174722_psg_qwen2.5-coder:32b.py\", line 67, in <module>\n",
      "    num_detections = int(np.squeeze(output_data[3]))\n",
      "IndexError: index 3 is out of bounds for axis 0 with size 1\n",
      "\n",
      "SPAN error_fe_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804174503_psg_qwen2.5-coder:32b/tmp_20250804174503_psg_qwen2.5-coder:32b.py\", line 20, in <module>\n",
      "    with open(label_path, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'path_to_labelmap.txt'\n",
      "\n",
      "SPAN error_a0_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804173833_psg_qwen2.5-coder:32b/tmp_20250804173833_psg_qwen2.5-coder:32b.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_05_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804173607_psg_qwen2.5-coder:32b/tmp_20250804173607_psg_qwen2.5-coder:32b.py\", line 34, in <module>\n",
      "    height = int(cap.get(cv2.CAP_PROP_HEIGHT))\n",
      "AttributeError: module 'cv2' has no attribute 'CAP_PROP_HEIGHT'\n",
      "\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:32b_17ec_psg_batch\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:32b_17ec_tpusg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session qwen2.5-coder:32b_17ec_psg_batch, simple id qwen2.5-coder:32b_17ec. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.03/raw_export/trimmed_qwen2.5-coder:32b_17ec_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.03/processed_data/qwen2.5-coder:32b_17ec/clean_qwen2.5-coder:32b_17ec_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.03/processed_data/qwen2.5-coder:32b_17ec/clean_qwen2.5-coder:32b_17ec_psg_batch.csv\n",
      "Processing session qwen2.5-coder:32b_17ec_tpusg_batch, simple id qwen2.5-coder:32b_17ec. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.03/raw_export/trimmed_qwen2.5-coder:32b_17ec_tpusg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.03/processed_data/qwen2.5-coder:32b_17ec/clean_qwen2.5-coder:32b_17ec_tpusg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.03/processed_data/qwen2.5-coder:32b_17ec/clean_qwen2.5-coder:32b_17ec_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below is archived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Simply calculate success rate\"\"\"\n",
    "\n",
    "\n",
    "# def cal_success_rate(session_id):\n",
    "\n",
    "#     end_signal_count = 0\n",
    "#     failure_signal_count = 0\n",
    "#     # Function to print the name of each observation\n",
    "#     with open(f\"{raw_export_dir}/trimmed_{session_id}.json\", \"r\") as file:\n",
    "#         data = json.load(file)[\"data\"]\n",
    "#     for i in data:\n",
    "\n",
    "#         observations = i[\"observations\"]\n",
    "\n",
    "#         for observation in observations:\n",
    "#             # print(type(observation))\n",
    "#             for key, value in observation.items():\n",
    "#                 # print(f\"{key}: {value}\")\n",
    "#                 for key, value in value.items():\n",
    "#                     # print(f\"{key}: {value}\")\n",
    "#                     if key == \"name\":\n",
    "#                         if \"end_\" in value:\n",
    "\n",
    "#                             end_signal_count += 1\n",
    "#                         if \"failure_signal\" in value:\n",
    "\n",
    "#                             failure_signal_count += 1\n",
    "\n",
    "#     print(f\"Session ID: {session_id}\")\n",
    "#     total_count = end_signal_count + failure_signal_count\n",
    "#     if total_count > 0:\n",
    "#         success_rate = end_signal_count / total_count\n",
    "#         print(f\"Success rate: {success_rate:.4f}\")\n",
    "#     else:\n",
    "#         print(\"Success rate: N/A (no signals found)\")\n",
    "#     print(f\"Passed:\\t{end_signal_count}\\nFailed:\\t{failure_signal_count}\")\n",
    "#     print(\n",
    "#         \"\"\n",
    "#         if total_count == 30\n",
    "#         else \"Number of ending signals does not match the expected number!\"\n",
    "#     )\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# for session_id in session_id_list:\n",
    "#     cal_success_rate(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_time(start_time, end_time):\n",
    "#     time_diff = datetime.fromisoformat(\n",
    "#         end_time.replace(\"Z\", \"+00:00\")\n",
    "#     ) - datetime.fromisoformat(start_time.replace(\"Z\", \"+00:00\"))\n",
    "#     seconds_diff = time_diff.total_seconds()\n",
    "#     return seconds_diff\n",
    "\n",
    "\n",
    "# print(cal_time(\"2025-01-15T03:31:56.150000+00:00\", \"2025-01-15T03:32:59.384Z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Print the complete structure of exported json file\"\"\"\n",
    "# def print_keys(d, parent_key=''):\n",
    "#     if isinstance(d, dict):\n",
    "#         for key, value in d.items():\n",
    "#             full_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "#             print(full_key)\n",
    "#             print_keys(value, full_key)\n",
    "#     elif isinstance(d, list):\n",
    "#         for i, item in enumerate(d):\n",
    "#             full_key = f\"{parent_key}[{i}]\"\n",
    "#             print_keys(item, full_key)\n",
    "\n",
    "# # Load JSON data from a file\n",
    "# with open('fetch_traces_response.json', 'r') as file:\n",
    "#     data = json.load(file)['data'][0]\n",
    "# # Print all keys\n",
    "# print_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747226053\n",
      "1747226053.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "timestamp_str = \"2025-05-14T12:34:13.100000+00:00\"\n",
    "dt = parser.isoparse(\n",
    "    timestamp_str\n",
    ")  # Or datetime.fromisoformat(timestamp_str) if no timezone offset\n",
    "unix_ts = int(dt.timestamp())\n",
    "\n",
    "print(unix_ts)  # This will print the integer Unix timestamp\n",
    "print(datetime.fromisoformat(timestamp_str).timestamp())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
