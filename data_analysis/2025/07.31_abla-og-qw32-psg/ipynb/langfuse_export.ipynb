{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"qwen2.5-coder:32b_5f8b_psg_batch\",\n",
    "    \"qwen2.5-coder:32b_5f8b_tpusg_batch\"\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session qwen2.5-coder:32b_5f8b_psg_batch...\n",
      "Fetching observation data for time-04-08-28-419064_chatcmpl-765a8dd8-f771-4352-aa10-412c438279ae...\n",
      "Fetching observation data for time-04-06-11-875321_chatcmpl-2423c674-d173-42e3-bfb9-797ee8dfc911...\n",
      "Fetching observation data for time-04-06-32-596895_chatcmpl-bfde5cfd-2045-46cf-8b3d-b7578bdf3757...\n",
      "Fetching observation data for time-04-06-56-265677_chatcmpl-58d989a3-60e0-49c1-b514-b3c658f460ca...\n",
      "Fetching observation data for time-04-07-22-760053_chatcmpl-8fe6fadd-fdbb-4722-9bcd-d2a4bb7bd595...\n",
      "Fetching observation data for time-04-07-52-631509_chatcmpl-4a80c900-2df6-4c52-8b4b-8153cabdebcb...\n",
      "Fetching observation data for 73694276-ae33-4168-82d7-b5035c310b5b...\n",
      "Fetching observation data for time-04-05-15-306706_chatcmpl-fe355305-9980-4a61-8b86-c6a95b035bb2...\n",
      "Fetching observation data for time-04-04-16-717815_chatcmpl-1e2fd0aa-4de5-480a-81fe-4c117bf92552...\n",
      "Fetching observation data for time-04-02-04-172119_chatcmpl-4dbb26c7-e463-4e31-925c-9cc8a7ac52be...\n",
      "Fetching observation data for time-04-02-23-653068_chatcmpl-c75b2df0-2f1a-4952-89e7-67c0c40e9060...\n",
      "Fetching observation data for time-04-02-46-116769_chatcmpl-4e25f91b-2550-438c-9293-a27aee052e7a...\n",
      "Fetching observation data for time-04-03-11-806946_chatcmpl-c5379aeb-e68e-46c3-aced-79f091140be8...\n",
      "Fetching observation data for time-04-03-43-350583_chatcmpl-43d70c2c-21b9-4286-ac39-036430f6097b...\n",
      "Fetching observation data for 3d069b08-5018-4cd1-bbae-319b2cbdd442...\n",
      "Fetching observation data for time-03-59-44-630278_chatcmpl-b40e5dca-52b8-4f4c-b369-b5e8013d13d1...\n",
      "Fetching observation data for time-04-00-04-040280_chatcmpl-d8cc9783-888b-4948-bc6b-0b85124bddb5...\n",
      "Fetching observation data for time-04-00-34-152096_chatcmpl-510cd95c-1755-4b05-9f2d-7e7dd024f4eb...\n",
      "Fetching observation data for time-04-01-02-734219_chatcmpl-0ae3067b-d6b7-499e-a163-215e86f45ac2...\n",
      "Fetching observation data for time-04-01-33-494104_chatcmpl-78fe0c4e-48c7-4f87-82fa-47740e1c76d6...\n",
      "Fetching observation data for 4ad3a21f-fd63-4672-8719-e1ec76c5dddc...\n",
      "Fetching observation data for time-03-57-39-988123_chatcmpl-023b41a6-8de7-4f3a-a07a-6c3b4e6e143f...\n",
      "Fetching observation data for time-03-57-59-604222_chatcmpl-2e67ef55-4ac9-4b2f-bd46-8c08a2a98dda...\n",
      "Fetching observation data for time-03-58-31-976236_chatcmpl-0a5337e3-62da-44ea-8484-a4412f824312...\n",
      "Fetching observation data for time-03-55-27-446236_chatcmpl-ee6e6d5b-c0bb-4201-b82d-79ac1dd9484d...\n",
      "Fetching observation data for time-03-55-47-731272_chatcmpl-9964df19-6fe7-4eb7-9c15-97b47c65046b...\n",
      "Fetching observation data for time-03-56-11-958875_chatcmpl-d0067575-2877-4477-9695-8dd8df5dfae1...\n",
      "Fetching observation data for time-03-56-36-546799_chatcmpl-c45ed18a-356c-4fbc-ab33-a624108ac387...\n",
      "Fetching observation data for time-03-57-06-097447_chatcmpl-2e51441d-1f27-4a3f-a8e8-838ad4c3bc86...\n",
      "Fetching observation data for 597ed5d4-1027-4da2-9f31-0c8f14f4ce51...\n",
      "Fetching observation data for time-03-54-27-926890_chatcmpl-10645286-420e-45db-b0c5-2722fa72f363...\n",
      "Fetching observation data for time-03-52-17-791606_chatcmpl-9986915f-066e-4db4-8f2f-079abe54e5b5...\n",
      "Fetching observation data for time-03-52-36-323888_chatcmpl-ef267f3b-1a2a-4664-b0e4-8f929ae3aa09...\n",
      "Fetching observation data for time-03-53-04-784955_chatcmpl-90ac86b3-15eb-40d2-8055-f45dba214bec...\n",
      "Fetching observation data for time-03-53-28-764940_chatcmpl-e27b6463-d1b2-4e4a-b3c7-5a00cd3ff4b5...\n",
      "Fetching observation data for time-03-53-53-360955_chatcmpl-76e404d6-d681-451b-a95e-83a93e7ef829...\n",
      "Fetching observation data for 3cae3acf-3879-4025-9d3c-6ce81ce30396...\n",
      "Fetching observation data for time-03-50-57-230255_chatcmpl-1fb343f2-9f33-4e12-8816-194f61db74d7...\n",
      "Fetching observation data for time-03-51-15-965905_chatcmpl-087aabcd-9759-41b9-bcca-e1ea08a7c18b...\n",
      "Fetching observation data for time-03-48-31-666445_chatcmpl-082615db-5ba6-4a03-a4d7-622ad4297e58...\n",
      "Fetching observation data for time-03-48-52-382088_chatcmpl-26ca3f4c-b5c9-4835-8635-13b74ad7ac55...\n",
      "Fetching observation data for time-03-49-18-333824_chatcmpl-627551f4-6e47-4f5f-80e0-9e9581c78525...\n",
      "Fetching observation data for time-03-49-49-380049_chatcmpl-f472d2d6-f783-4b3a-b519-3d7b9c445adc...\n",
      "Fetching observation data for time-03-46-31-054698_chatcmpl-0ec46a81-cf90-4486-8c73-0225c90174a8...\n",
      "Fetching observation data for time-03-46-53-496748_chatcmpl-0b6a3877-9834-4f6a-80a9-6383a2115617...\n",
      "Fetching observation data for time-03-47-23-999705_chatcmpl-28e8c093-078f-46fd-b7fa-78a48a9444d0...\n",
      "Fetching observation data for time-03-46-00-511296_chatcmpl-d801a5e9-512c-4747-86ae-371ff820e053...\n",
      "Fetching observation data for time-03-45-03-001763_chatcmpl-078e835c-8407-4e4d-b5a5-6c53e9d71e66...\n",
      "Fetching observation data for time-03-42-42-390047_chatcmpl-18220c45-d0aa-4b75-9ba8-2a65293d4028...\n",
      "Fetching observation data for time-03-43-01-271968_chatcmpl-e040339e-3c52-4848-9373-bc1cdf8d28d5...\n",
      "Fetching observation data for time-03-43-27-163253_chatcmpl-13b179c3-a9a2-4477-8da0-21f7f50b1e35...\n",
      "Fetching observation data for time-03-43-56-166747_chatcmpl-efbde308-4214-4993-b58a-7361d4ebd5bf...\n",
      "Fetching observation data for time-03-44-30-604899_chatcmpl-1673d18e-6302-495a-be41-ab33f9601ef0...\n",
      "Fetching observation data for b94ab1fc-d82d-43dc-b011-fb8ac4e7ce2c...\n",
      "Fetching observation data for time-03-40-32-769587_chatcmpl-72df119b-d128-4d6b-9714-ccbca6f4d476...\n",
      "Fetching observation data for time-03-40-53-280762_chatcmpl-a0799988-2797-49e1-bb21-2e77aff74be9...\n",
      "Fetching observation data for time-03-41-22-079637_chatcmpl-2d05987d-d018-41e3-8575-7ab890df1b34...\n",
      "Fetching observation data for time-03-41-47-648455_chatcmpl-f135e6e2-b3e1-4bea-833e-8c99cd400545...\n",
      "Fetching observation data for time-03-42-13-163348_chatcmpl-b2ad5276-5c23-4541-a959-f745012b6cc0...\n",
      "Fetching observation data for 4982c472-6731-4c6d-9692-ea3070c5671c...\n",
      "Fetching observation data for time-03-38-29-245944_chatcmpl-ffaabba5-d950-4916-b12d-37507ebb7c89...\n",
      "Fetching observation data for time-03-38-53-909271_chatcmpl-263160d8-84f3-41d5-bec9-6eccbf11f00a...\n",
      "Fetching observation data for time-03-39-22-346657_chatcmpl-f4b5c11d-2c38-4f2e-b11e-d90a26eb0e68...\n",
      "Fetching observation data for time-03-37-26-736010_chatcmpl-3d000531-879f-404e-a892-3edf8ed907f5...\n",
      "Fetching observation data for time-03-34-40-125077_chatcmpl-6b25bf99-f98d-4771-9674-6d4a6eb3a650...\n",
      "Fetching observation data for time-03-35-01-095170_chatcmpl-9fcc8dd1-3c7c-47fb-b59b-888be9b02d75...\n",
      "Fetching observation data for time-03-35-24-975571_chatcmpl-f18f968b-0618-4fb3-8e0c-a6d7dbbcca38...\n",
      "Fetching observation data for time-03-35-49-252059_chatcmpl-7ce0d83e-7a2c-469a-98e3-10236fefeb55...\n",
      "Fetching observation data for time-03-36-14-498329_chatcmpl-d25c557e-bb8c-431a-9616-c94104a12a23...\n",
      "Fetching observation data for time-03-32-14-501833_chatcmpl-e8076b9a-d98c-4efa-b39d-ad38e6c2abdb...\n",
      "Fetching observation data for time-03-32-35-259360_chatcmpl-9d77adad-5139-4957-88e1-5e0f08c40324...\n",
      "Fetching observation data for time-03-33-03-491994_chatcmpl-46cfcece-7ed5-47d1-8f09-dbf85785abe1...\n",
      "Fetching observation data for time-03-33-31-904335_chatcmpl-d9f1b5b6-9b1c-4fd0-8b15-4654227833d3...\n",
      "Fetching observation data for time-03-29-53-483658_chatcmpl-a956ee6b-3652-4a89-b955-518b9e1d7ee8...\n",
      "Fetching observation data for time-03-30-12-501319_chatcmpl-4576edbd-4234-42b9-94f4-974d5b86a00c...\n",
      "Fetching observation data for time-03-30-38-697458_chatcmpl-8856f619-4de2-444a-93cd-4a82b0a9df5d...\n",
      "Fetching observation data for time-03-31-03-620081_chatcmpl-f7072e53-0ee9-41fa-908a-1b49203a8d07...\n",
      "Fetching observation data for time-03-31-30-474097_chatcmpl-f80c2329-15fa-4fcb-b3c6-4dde89316d0d...\n",
      "Fetching observation data for 8208b236-1dea-4758-8865-7f03f03e7568...\n",
      "Fetching observation data for time-03-28-54-838792_chatcmpl-274e2b0c-315c-4bcf-a7fc-7d064a886180...\n",
      "Fetching observation data for time-03-26-39-207127_chatcmpl-2c2efd78-7126-4f56-800d-3b779f8d019f...\n",
      "Fetching observation data for time-03-27-00-406130_chatcmpl-a3972d46-63be-4ed6-bbb1-de2d5ed437b5...\n",
      "Fetching observation data for time-03-27-25-563460_chatcmpl-3b806eca-3309-4bff-8b2e-11bb2ff195b4...\n",
      "Fetching observation data for time-03-27-51-430161_chatcmpl-58824e7c-1afd-4564-84ed-8a8c045257f4...\n",
      "Fetching observation data for time-03-28-25-041075_chatcmpl-2885b23f-cf61-4887-ba65-37149cc6fa09...\n",
      "Fetching observation data for 11b56402-683e-448f-aa94-fee923d9b5e0...\n",
      "Fetching observation data for time-03-24-19-610033_chatcmpl-82c9434d-243d-46e1-88ab-2a362ef8936b...\n",
      "Fetching observation data for time-03-24-38-058450_chatcmpl-64a9523c-75fe-46d1-9562-5548bb3e831b...\n",
      "Fetching observation data for time-03-25-05-002583_chatcmpl-b52fedad-5e49-40f5-8fc8-e209c37a6ee3...\n",
      "Fetching observation data for time-03-25-39-738125_chatcmpl-01f98d4b-2f0c-4a39-93d9-d85390a937da...\n",
      "Fetching observation data for time-03-26-04-054108_chatcmpl-334e5639-7daf-4b46-92bb-1a20ffbff6ab...\n",
      "Fetching observation data for c1f4adac-c53f-455a-9e38-37f94002b999...\n",
      "Fetching observation data for time-03-23-18-908115_chatcmpl-67576256-f69f-4dfa-a3a8-685e87a1d6d4...\n",
      "Fetching observation data for time-03-21-09-147705_chatcmpl-f7efbcdf-5022-4cb2-9b30-4ca0950a959c...\n",
      "Fetching observation data for time-03-21-27-766800_chatcmpl-d175ac9b-bfcc-4fae-9d91-1402dc1c46eb...\n",
      "Fetching observation data for time-03-21-52-166613_chatcmpl-33ffd7c1-15ef-438f-8123-aa15774257f9...\n",
      "Fetching observation data for time-03-22-16-540219_chatcmpl-c7746e89-f30f-4dfc-9f15-f74624b2c3b3...\n",
      "Fetching observation data for time-03-22-42-904809_chatcmpl-7f2297c0-47c5-40ca-b1a1-2e3224a1de01...\n",
      "Fetching observation data for 4e3e51b7-d500-4def-99a3-64ecd3291450...\n",
      "Fetching observation data for time-03-18-37-281497_chatcmpl-503a8f2d-b3ca-4617-b378-00d9eec28451...\n",
      "Fetching observation data for time-03-18-58-072187_chatcmpl-b56358ea-947c-450e-8255-513e1fe39cf4...\n",
      "Fetching observation data for time-03-19-27-816906_chatcmpl-4eb5f6b3-9a7b-4cf7-8dea-293c751135fb...\n",
      "Fetching observation data for time-03-20-04-493580_chatcmpl-688fcda7-3352-4b1e-b6a8-d54f841c082e...\n",
      "Fetching observation data for time-03-20-31-125267_chatcmpl-edfaa00f-fa60-4cd2-b603-553e488acd0a...\n",
      "Fetching observation data for 34e251e5-a1ab-475c-a82f-0c1cdfaff0d7...\n",
      "Fetching observation data for time-03-15-50-387338_chatcmpl-7b59ada2-9b79-41d2-b95f-bfe0394c3ef9...\n",
      "Fetching observation data for time-03-16-10-441068_chatcmpl-a68da615-f180-44e1-8bb3-6c81ac89b750...\n",
      "Fetching observation data for time-03-16-34-675214_chatcmpl-5d647356-a483-4901-99a7-b50f0ffc6e7f...\n",
      "Fetching observation data for time-03-17-01-491509_chatcmpl-8cc2a41d-e1f7-4050-afc3-944ba7b2dec4...\n",
      "Fetching observation data for time-03-17-27-313218_chatcmpl-64102d48-4627-4728-85fa-e80abc507c54...\n",
      "Fetching observation data for time-03-14-50-622298_chatcmpl-c6b6b447-e7c8-45b6-826c-f021413bb6c6...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/07.31/raw_export/raw_qwen2.5-coder:32b_5f8b_psg_batch.json\n",
      "Fetching traces for session qwen2.5-coder:32b_5f8b_tpusg_batch...\n",
      "Fetching observation data for time-03-13-24-477335_chatcmpl-410f7e79-f109-4a20-a702-d1a3767e523a...\n",
      "Fetching observation data for time-03-12-02-722820_chatcmpl-d253bc0c-cff1-4be0-bc95-610499fd21e8...\n",
      "Fetching observation data for time-03-10-04-870857_chatcmpl-7c6fbd95-7773-4522-a17e-8e90c766c148...\n",
      "Fetching observation data for time-03-10-36-046665_chatcmpl-d9cc7894-4a10-47a1-a281-e097e37d11c7...\n",
      "Fetching observation data for time-03-08-33-141518_chatcmpl-e5ed544e-fb21-402b-b541-90db512d2fdc...\n",
      "Fetching observation data for time-03-05-17-176991_chatcmpl-f895634e-95a7-46df-82c1-ce5ef9ba0b8e...\n",
      "Fetching observation data for time-03-05-48-428311_chatcmpl-a1233a7f-b5ba-4e29-9cd2-edf75d6262d3...\n",
      "Fetching observation data for time-03-06-28-172084_chatcmpl-700f4910-e271-4dc7-a50d-0c4782a5a48d...\n",
      "Fetching observation data for time-03-07-05-788331_chatcmpl-32057b9b-0373-4e49-8286-c8f9a9602cd1...\n",
      "Fetching observation data for time-03-03-53-044565_chatcmpl-4adc852c-a949-4197-9cd0-b937340cc404...\n",
      "Fetching observation data for time-03-02-31-026514_chatcmpl-39a7b4a4-2beb-4813-8886-c9b7ef442583...\n",
      "Fetching observation data for time-03-01-09-379685_chatcmpl-fd06ae81-15ce-4dff-9650-9534ab21dcea...\n",
      "Fetching observation data for time-02-59-48-649921_chatcmpl-4e8d9270-9ca2-42a9-9743-2d4d0818f291...\n",
      "Fetching observation data for time-02-57-46-844914_chatcmpl-f73bde55-6d5d-466f-88c3-c13cc7c72e58...\n",
      "Fetching observation data for time-02-58-19-854773_chatcmpl-64cb0618-6988-42ff-8184-b1e6e161866d...\n",
      "Fetching observation data for time-02-56-27-153283_chatcmpl-cca22144-6986-418b-9aa3-f6a60d50ab14...\n",
      "Fetching observation data for time-02-57-00-127723_chatcmpl-bd6f69ce-b6fd-4556-94a9-2c9dfba65818...\n",
      "Fetching observation data for time-02-54-29-499546_chatcmpl-a5471ca3-19bc-4af2-97d5-74b517fb5c4a...\n",
      "Fetching observation data for time-02-54-58-652946_chatcmpl-7d532f7f-16f7-423c-bf2b-92647c57873d...\n",
      "Fetching observation data for time-02-53-06-831494_chatcmpl-1df9a141-7e06-4dab-8605-258b2d4901ea...\n",
      "Fetching observation data for time-02-51-45-183463_chatcmpl-37bde245-900d-4f79-8227-6c086fb200d7...\n",
      "Fetching observation data for time-02-50-20-450063_chatcmpl-4dd1c280-4003-4f0e-b1be-0d7365b92ce0...\n",
      "Fetching observation data for time-02-48-18-765703_chatcmpl-b4b61353-fe5c-4463-8306-fb799abb3f3d...\n",
      "Fetching observation data for time-02-48-52-240913_chatcmpl-01889444-fd4b-43ff-8a13-0d9bc0eac801...\n",
      "Fetching observation data for time-02-46-53-044722_chatcmpl-d83b015a-8fba-4399-bb52-ccc195553055...\n",
      "Fetching observation data for time-02-44-49-277792_chatcmpl-03eb195d-05ca-4a32-8429-518bd68b9627...\n",
      "Fetching observation data for time-02-45-22-827692_chatcmpl-e9321648-9568-4b76-84f0-f174db3ec4ea...\n",
      "Fetching observation data for time-02-43-27-559775_chatcmpl-60ab77a3-9d3f-4c83-858b-9caef4b0baea...\n",
      "Fetching observation data for time-02-42-03-886972_chatcmpl-7de1ac27-a295-4fb9-ad34-535035056661...\n",
      "Fetching observation data for time-02-39-12-930623_chatcmpl-5811e63b-8228-471c-a7d2-cd4af176e4f8...\n",
      "Fetching observation data for time-02-39-44-957132_chatcmpl-4004ea26-baef-43c1-bb55-f47ca216e982...\n",
      "Fetching observation data for time-02-40-28-078356_chatcmpl-a449311e-2dec-4b2c-aa8d-85d08d6ac4c7...\n",
      "Fetching observation data for time-02-37-48-570517_chatcmpl-5c078a0e-d7fb-49fc-ae0a-7384fe7509ab...\n",
      "Fetching observation data for time-02-35-49-636833_chatcmpl-be850737-d3a1-4bdd-84c9-6d2edb0d19a7...\n",
      "Fetching observation data for time-02-36-21-044004_chatcmpl-ac443782-c195-4185-8d9a-0bdd228ea16d...\n",
      "Fetching observation data for time-02-34-25-762514_chatcmpl-d6258ad8-7c0b-42ce-8ab7-a4d0fa902a2b...\n",
      "Fetching observation data for time-02-32-21-244478_chatcmpl-c8971822-91f9-490f-9ee7-0dbf1386c13f...\n",
      "Fetching observation data for time-02-32-54-892336_chatcmpl-84d658bb-4855-4272-82dd-7a84a0768267...\n",
      "Fetching observation data for time-02-30-26-683156_chatcmpl-7f594d92-ddc3-40d9-85d8-54700155ca3c...\n",
      "Fetching observation data for time-02-30-54-455371_chatcmpl-0a063329-c145-4584-b375-8506be18fe5f...\n",
      "Fetching observation data for time-02-28-32-159023_chatcmpl-31849591-638e-4cc1-90d0-75f90da2e67a...\n",
      "Fetching observation data for time-02-29-02-424840_chatcmpl-96b19f3a-4992-41c5-ac60-6c35f0d2f9a4...\n",
      "Fetching observation data for time-02-27-11-607050_chatcmpl-12401739-13fe-4115-a3c2-e5aaa0957459...\n",
      "Fetching observation data for time-02-23-52-038364_chatcmpl-29373ee0-13a8-4267-b108-13f641098fe9...\n",
      "Fetching observation data for time-02-24-26-075466_chatcmpl-de064574-3500-45ce-bbb3-4d438683273c...\n",
      "Fetching observation data for time-02-25-05-347629_chatcmpl-186c42dc-598f-4818-84f4-e97861f48413...\n",
      "Fetching observation data for time-02-25-43-720048_chatcmpl-864c6202-5033-434b-ab86-ad1841caf4da...\n",
      "Fetching observation data for time-02-26-24-385556_chatcmpl-65779992-8a49-4446-a883-ba1bce9c7f8f...\n",
      "Fetching observation data for ffc449be-c42f-4e4a-8e58-12dd855a2130...\n",
      "Fetching observation data for time-02-21-51-180207_chatcmpl-4041f3a8-b691-434a-a957-948bb5a4635e...\n",
      "Fetching observation data for time-02-22-23-087687_chatcmpl-135041cf-f463-4185-88e9-0a8738c9ae71...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/07.31/raw_export/raw_qwen2.5-coder:32b_5f8b_tpusg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_ab_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804040821_psg_qwen2.5-coder:32b/tmp_20250804040821_psg_qwen2.5-coder:32b.py\", line 64, in <module>\n",
      "    label = labels[index]\n",
      "TypeError: only integer scalar arrays can be converted to a scalar index\n",
      "\n",
      "SPAN error_4f_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804040409_psg_qwen2.5-coder:32b/tmp_20250804040409_psg_qwen2.5-coder:32b.py\", line 70, in <module>\n",
      "    label_name = labels[label_index]\n",
      "TypeError: only integer scalar arrays can be converted to a scalar index\n",
      "\n",
      "SPAN error_6b_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804040157_psg_qwen2.5-coder:32b/tmp_20250804040157_psg_qwen2.5-coder:32b.py\", line 62, in <module>\n",
      "    predicted_label = labels[predicted_index]\n",
      "TypeError: only integer scalar arrays can be converted to a scalar index\n",
      "\n",
      "SPAN error_ce_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804035733_psg_qwen2.5-coder:32b/tmp_20250804035733_psg_qwen2.5-coder:32b.py\", line 21, in <module>\n",
      "    with open(label_path, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/path/to/labels.txt'\n",
      "\n",
      "SPAN error_2a_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804035420_psg_qwen2.5-coder:32b/tmp_20250804035420_psg_qwen2.5-coder:32b.py\", line 60, in <module>\n",
      "    bbox, score, class_id = detection[:4], detection[4], int(detection[5])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_76_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804034456_psg_qwen2.5-coder:32b/tmp_20250804034456_psg_qwen2.5-coder:32b.py\", line 22, in <module>\n",
      "    with open(label_path, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'path_to_label_map.txt'\n",
      "\n",
      "SPAN error_20_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804034235_psg_qwen2.5-coder:32b/tmp_20250804034235_psg_qwen2.5-coder:32b.py\", line 48, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_35_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804033207_psg_qwen2.5-coder:32b/tmp_20250804033207_psg_qwen2.5-coder:32b.py\", line 68, in <module>\n",
      "    confidence = output_data[0][class_index]\n",
      "IndexError: index 19 is out of bounds for axis 0 with size 10\n",
      "\n",
      "SPAN error_94_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804032848_psg_qwen2.5-coder:32b/tmp_20250804032848_psg_qwen2.5-coder:32b.py\", line 28, in <module>\n",
      "    raise ValueError(f\"Image not found at {INPUT_PATH}\")\n",
      "ValueError: Image not found at data/object_detection/sheeps.mp4\n",
      "\n",
      "SPAN error_94_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804032632_psg_qwen2.5-coder:32b/tmp_20250804032632_psg_qwen2.5-coder:32b.py\", line 44, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], img)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_e4_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804032311_psg_qwen2.5-coder:32b/tmp_20250804032311_psg_qwen2.5-coder:32b.py\", line 64, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_61_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804032102_psg_qwen2.5-coder:32b/tmp_20250804032102_psg_qwen2.5-coder:32b.py\", line 59, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:32b_5f8b_psg_batch\n",
      "SPAN error_b3_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_11a6b92d_1754263618.py\", line 61, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Shape: [1], should be a scalar\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:32b_5f8b_tpusg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session qwen2.5-coder:32b_5f8b_psg_batch, simple id qwen2.5-coder:32b_5f8b. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/07.31/raw_export/trimmed_qwen2.5-coder:32b_5f8b_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/07.31/processed_data/qwen2.5-coder:32b_5f8b/clean_qwen2.5-coder:32b_5f8b_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/07.31/processed_data/qwen2.5-coder:32b_5f8b/clean_qwen2.5-coder:32b_5f8b_psg_batch.csv\n",
      "Processing session qwen2.5-coder:32b_5f8b_tpusg_batch, simple id qwen2.5-coder:32b_5f8b. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/07.31/raw_export/trimmed_qwen2.5-coder:32b_5f8b_tpusg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/07.31/processed_data/qwen2.5-coder:32b_5f8b/clean_qwen2.5-coder:32b_5f8b_tpusg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/07.31/processed_data/qwen2.5-coder:32b_5f8b/clean_qwen2.5-coder:32b_5f8b_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below is archived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Simply calculate success rate\"\"\"\n",
    "\n",
    "\n",
    "# def cal_success_rate(session_id):\n",
    "\n",
    "#     end_signal_count = 0\n",
    "#     failure_signal_count = 0\n",
    "#     # Function to print the name of each observation\n",
    "#     with open(f\"{raw_export_dir}/trimmed_{session_id}.json\", \"r\") as file:\n",
    "#         data = json.load(file)[\"data\"]\n",
    "#     for i in data:\n",
    "\n",
    "#         observations = i[\"observations\"]\n",
    "\n",
    "#         for observation in observations:\n",
    "#             # print(type(observation))\n",
    "#             for key, value in observation.items():\n",
    "#                 # print(f\"{key}: {value}\")\n",
    "#                 for key, value in value.items():\n",
    "#                     # print(f\"{key}: {value}\")\n",
    "#                     if key == \"name\":\n",
    "#                         if \"end_\" in value:\n",
    "\n",
    "#                             end_signal_count += 1\n",
    "#                         if \"failure_signal\" in value:\n",
    "\n",
    "#                             failure_signal_count += 1\n",
    "\n",
    "#     print(f\"Session ID: {session_id}\")\n",
    "#     total_count = end_signal_count + failure_signal_count\n",
    "#     if total_count > 0:\n",
    "#         success_rate = end_signal_count / total_count\n",
    "#         print(f\"Success rate: {success_rate:.4f}\")\n",
    "#     else:\n",
    "#         print(\"Success rate: N/A (no signals found)\")\n",
    "#     print(f\"Passed:\\t{end_signal_count}\\nFailed:\\t{failure_signal_count}\")\n",
    "#     print(\n",
    "#         \"\"\n",
    "#         if total_count == 30\n",
    "#         else \"Number of ending signals does not match the expected number!\"\n",
    "#     )\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# for session_id in session_id_list:\n",
    "#     cal_success_rate(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_time(start_time, end_time):\n",
    "#     time_diff = datetime.fromisoformat(\n",
    "#         end_time.replace(\"Z\", \"+00:00\")\n",
    "#     ) - datetime.fromisoformat(start_time.replace(\"Z\", \"+00:00\"))\n",
    "#     seconds_diff = time_diff.total_seconds()\n",
    "#     return seconds_diff\n",
    "\n",
    "\n",
    "# print(cal_time(\"2025-01-15T03:31:56.150000+00:00\", \"2025-01-15T03:32:59.384Z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Print the complete structure of exported json file\"\"\"\n",
    "# def print_keys(d, parent_key=''):\n",
    "#     if isinstance(d, dict):\n",
    "#         for key, value in d.items():\n",
    "#             full_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "#             print(full_key)\n",
    "#             print_keys(value, full_key)\n",
    "#     elif isinstance(d, list):\n",
    "#         for i, item in enumerate(d):\n",
    "#             full_key = f\"{parent_key}[{i}]\"\n",
    "#             print_keys(item, full_key)\n",
    "\n",
    "# # Load JSON data from a file\n",
    "# with open('fetch_traces_response.json', 'r') as file:\n",
    "#     data = json.load(file)['data'][0]\n",
    "# # Print all keys\n",
    "# print_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747226053\n",
      "1747226053.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "timestamp_str = \"2025-05-14T12:34:13.100000+00:00\"\n",
    "dt = parser.isoparse(\n",
    "    timestamp_str\n",
    ")  # Or datetime.fromisoformat(timestamp_str) if no timezone offset\n",
    "unix_ts = int(dt.timestamp())\n",
    "\n",
    "print(unix_ts)  # This will print the integer Unix timestamp\n",
    "print(datetime.fromisoformat(timestamp_str).timestamp())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
