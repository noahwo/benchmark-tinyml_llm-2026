{
  "data": [
    {
      "id": "f468a8ff",
      "timestamp": "2026-02-07T02:33:20.661000+00:00",
      "name": "f468_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\ndef load_labels(label_file):\n    with open(label_file, 'r') as f:\n        return [line.strip() for line in f.readlines()]\n\ndef preprocess_frame(frame, input_size):\n    frame_resized = cv2.resize(frame, input_size)\n    frame_normalized = (frame_resized / 255.0).astype(np.float32)\n    frame_expanded = np.expand_dims(frame_normalized, axis=0)\n    return frame_expanded\n\ndef main():\n    # Load labels\n    labels = load_labels(label_path)\n\n    # Initialize TFLite interpreter\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n\n    # Get input and output details\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    input_size = (input_details[0]['shape'][2], input_details[0]['shape'][1])\n\n    # Open video files\n    cap = cv2.VideoCapture(input_path)\n    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n\n    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocess the frame\n        input_data = preprocess_frame(frame, input_size)\n\n        # Set input tensor\n        interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.uint8))\n\n        # Run inference\n        interpreter.invoke()\n\n        # Get output tensors\n        boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n        classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n        scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n        # Draw bounding boxes and labels on the frame\n        for i in range(len(scores)):\n            if scores[i] > confidence_threshold:\n                ymin, xmin, ymax, xmax = boxes[i]\n                (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                              ymin * frame_height, ymax * frame_height)\n                left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n\n                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n                label = f\"{labels[int(classes[i])]}: {int(scores[i] * 100)}%\"\n                cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n        # Write the frame with detections\n        out.write(frame)\n\n    # Release resources\n    cap.release()\n    out.release()\n\nif __name__ == \"__main__\":\n    main()"
      },
      "session_id": "phi4_5f04_psg_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 24.518,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-33-20-663671_chatcmpl-9ce48aab-f695-4f59-8097-f15ebc385906",
          "traceId": "f468a8ff",
          "type": "GENERATION",
          "name": "f468_psg_gen_attempt#1",
          "startTime": "2026-02-07T02:33:20.663000+00:00",
          "endTime": "2026-02-07T02:33:32.642000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11979.0,
          "completionTokens": 829,
          "totalTokens": 1246,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-33-32-840923_chatcmpl-60b0b860-0e15-4b27-b507-952c72c810e8",
          "traceId": "f468a8ff",
          "type": "GENERATION",
          "name": "f468_psg_gen_attempt#2",
          "startTime": "2026-02-07T02:33:32.840000+00:00",
          "endTime": "2026-02-07T02:33:45.181000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12341.0,
          "completionTokens": 893,
          "totalTokens": 1580,
          "promptTokens": 687,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-07T02:33:56.376Z",
      "createdAt": "2026-02-07T02:33:21.189Z",
      "environment": "default"
    },
    {
      "id": "c39aee0f",
      "timestamp": "2026-02-07T02:31:43.986000+00:00",
      "name": "c39a_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# CONFIGURATION PARAMETERS\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels from the label map\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\ndef load_labels(path):\n    with open(path, 'r') as f:\n        return {i: line.strip() for i, line in enumerate(f.readlines())}\n\n# Load TFLite model and allocate tensors\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ndef preprocess_image(frame):\n    # Resize the frame to match the input size of the model\n    _, height, width, _ = input_details[0]['shape']\n    image_resized = cv2.resize(frame, (width, height))\n    return np.expand_dims(image_resized, axis=0)\n\ndef postprocess(output_data, frame, threshold):\n    # Extract output data\n    boxes = output_data[0][0]  # Bounding box coordinates\n    classes = output_data[1][0]  # Class indices\n    scores = output_data[2][0]  # Confidence scores\n\n    height, width, _ = frame.shape\n\n    for i in range(len(scores)):\n        if scores[i] > threshold:\n            # Scale bounding boxes back to original image size\n            ymin, xmin, ymax, xmax = boxes[i]\n            left, right, top, bottom = (xmin * width, xmax * width,\n                                        ymin * height, ymax * height)\n\n            # Draw bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          (0, 255, 0), 2)\n            class_id = int(classes[i])\n            label = labels[class_id]\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\ndef main():\n    # Open input and output video files\n    cap = cv2.VideoCapture(input_path)\n    out = None\n\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocess the image\n        input_data = preprocess_image(frame)\n\n        # Run inference\n        interpreter.set_tensor(input_details[0]['index'], input_data)\n        interpreter.invoke()\n\n        # Get output data\n        boxes = interpreter.get_tensor(output_details[0]['index'])\n        classes = interpreter.get_tensor(output_details[1]['index'])\n        scores = interpreter.get_tensor(output_details[2]['index'])\n\n        # Process the results and draw on the frame\n        postprocess([boxes, classes, scores], frame, confidence_threshold)\n\n        # Write the processed frame to the output video file\n        if out is None:\n            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n            out = cv2.VideoWriter(output_path, fourcc, 30.0, (frame.shape[1], frame.shape[0]))\n        \n        out.write(frame)\n\n    # Release resources\n    cap.release()\n    if out is not None:\n        out.release()\n\nif __name__ == \"__main__\":\n    main()"
      },
      "session_id": "phi4_5f04_psg_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 37.936,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-31-43-986922_chatcmpl-aa0cb3d4-a9ae-4f32-9030-9989f41179a7",
          "traceId": "c39aee0f",
          "type": "GENERATION",
          "name": "c39a_psg_gen_attempt#1",
          "startTime": "2026-02-07T02:31:43.986000+00:00",
          "endTime": "2026-02-07T02:31:56.813000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12827.0,
          "completionTokens": 906,
          "totalTokens": 1323,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-31-56-958321_chatcmpl-8d06aecf-0b45-44ed-9956-8c1e3c2f7f3a",
          "traceId": "c39aee0f",
          "type": "GENERATION",
          "name": "c39a_psg_gen_attempt#2",
          "startTime": "2026-02-07T02:31:56.958000+00:00",
          "endTime": "2026-02-07T02:32:09.324000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12366.0,
          "completionTokens": 916,
          "totalTokens": 1458,
          "promptTokens": 542,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-32-09-465025_chatcmpl-183e0e83-ca18-4ac1-9c55-409e7fbf6394",
          "traceId": "c39aee0f",
          "type": "GENERATION",
          "name": "c39a_psg_gen_attempt#3",
          "startTime": "2026-02-07T02:32:09.465000+00:00",
          "endTime": "2026-02-07T02:32:21.922000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12457.0,
          "completionTokens": 935,
          "totalTokens": 1478,
          "promptTokens": 543,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-07T02:32:59.666Z",
      "createdAt": "2026-02-07T02:31:44.512Z",
      "environment": "default"
    },
    {
      "id": "3226524a",
      "timestamp": "2026-02-07T02:30:44.610000+00:00",
      "name": "3226_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport time\nimport cv2\nimport numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Video processing\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing\n    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    image_resized = cv2.resize(image_rgb, (input_shape[2], input_shape[1]))\n    input_data = np.expand_dims(image_resized, axis=0)\n\n    # Set the tensor to the interpreter\n    input_tensor_type = input_details[0]['dtype']\n    if input_tensor_type == np.uint8:\n        input_data = input_data.astype(np.uint8)\n    elif input_tensor_type == np.float32:\n        input_data = (input_data / 255.0).astype(np.float32)\n\n    interpreter.set_tensor(input_index, input_data)\n\n    # Inference\n    start_time = time.time()\n    interpreter.invoke()\n    inference_time = time.time() - start_time\n\n    # Output handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    height, width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n\n            # Draw bounding box and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            object_name = labels[int(classes[i])]\n            label = f'{object_name}: {scores[i]:.2f}'\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (int(left), int(top - label_size[1])), \n                          (int(left + label_size[0]), int(top + base_line)), \n                          (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (int(left), int(top)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    # Write the frame with detection boxes\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\n\nprint(\"Object detection complete.\")"
      },
      "session_id": "phi4_5f04_psg_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 24.533,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-30-44-611613_chatcmpl-823749bd-6a8d-4400-b528-af2c3b362ded",
          "traceId": "3226524a",
          "type": "GENERATION",
          "name": "3226_psg_gen_attempt#1",
          "startTime": "2026-02-07T02:30:44.611000+00:00",
          "endTime": "2026-02-07T02:30:57.234000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12623.0,
          "completionTokens": 859,
          "totalTokens": 1276,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-30-57-431311_chatcmpl-302dcf63-9fba-455a-8509-9dab0060105a",
          "traceId": "3226524a",
          "type": "GENERATION",
          "name": "3226_psg_gen_attempt#2",
          "startTime": "2026-02-07T02:30:57.431000+00:00",
          "endTime": "2026-02-07T02:31:09.144000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11713.0,
          "completionTokens": 860,
          "totalTokens": 1483,
          "promptTokens": 623,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-07T02:31:23.494Z",
      "createdAt": "2026-02-07T02:30:45.137Z",
      "environment": "default"
    },
    {
      "id": "5994822d",
      "timestamp": "2026-02-07T02:29:18.861000+00:00",
      "name": "5994_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nimport os\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\ndef preprocess_input(image, input_details):\n    # Resize and normalize the image\n    size = (input_details[0]['shape'][2], input_details[0]['shape'][1])\n    resized_image = cv2.resize(image, size)\n    normalized_image = np.expand_dims(resized_image / 255.0, axis=0).astype(np.float32)\n    \n    # Convert to UINT8 as required by the model\n    return (normalized_image * 255).astype(np.uint8)\n\ndef postprocess_output(interpreter, scores, boxes, classes, input_shape):\n    height, width = input_shape[:2]\n    num_detections = int(scores.shape[1])\n    detections = []\n    \n    for i in range(num_detections):\n        if scores[0][i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[0][i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            detections.append((int(left), int(top), int(right), int(bottom),\n                               scores[0][i], classes[0][i]))\n    return detections\n\ndef main():\n    # Load labels\n    labels = load_labels(label_path)\n\n    # Initialize the TFLite interpreter\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    # Open video files\n    cap = cv2.VideoCapture(input_path)\n    if not cap.isOpened():\n        print(f\"Error opening video file {input_path}\")\n        return\n\n    # Get video properties\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n\n    # Define the codec and create VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocess the input image\n        input_data = preprocess_input(frame, input_details)\n\n        # Set input tensor\n        interpreter.set_tensor(input_details[0]['index'], input_data)\n\n        # Run inference\n        interpreter.invoke()\n\n        # Get output tensors\n        boxes = interpreter.get_tensor(output_details[0]['index'])\n        classes = interpreter.get_tensor(output_details[1]['index'])\n        scores = interpreter.get_tensor(output_details[2]['index'])\n\n        # Postprocess the results\n        detections = postprocess_output(interpreter, scores, boxes, classes, frame.shape)\n\n        # Draw detection boxes and labels on the frame\n        for (left, top, right, bottom, score, class_id) in detections:\n            label = f\"{labels[int(class_id)]}: {score:.2f}\"\n            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n            cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n        # Write the frame into the file\n        out.write(frame)\n\n    # Release everything if job is finished\n    cap.release()\n    out.release()\n    cv2.destroyAllWindows()\n\nif __name__ == \"__main__\":\n    main()"
      },
      "session_id": "phi4_5f04_psg_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 26.77,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-29-18-862536_chatcmpl-16de399b-e351-4ce9-8932-7d810486c491",
          "traceId": "5994822d",
          "type": "GENERATION",
          "name": "5994_psg_gen_attempt#1",
          "startTime": "2026-02-07T02:29:18.862000+00:00",
          "endTime": "2026-02-07T02:29:30.778000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11916.0,
          "completionTokens": 867,
          "totalTokens": 1284,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-29-30-946961_chatcmpl-4cbc5c0f-ddf3-4aba-a247-cd37bfe4831f",
          "traceId": "5994822d",
          "type": "GENERATION",
          "name": "5994_psg_gen_attempt#2",
          "startTime": "2026-02-07T02:29:30.946000+00:00",
          "endTime": "2026-02-07T02:29:45.632000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14686.0,
          "completionTokens": 1078,
          "totalTokens": 1764,
          "promptTokens": 686,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-07T02:30:23.575Z",
      "createdAt": "2026-02-07T02:29:19.387Z",
      "environment": "default"
    },
    {
      "id": "d251296a",
      "timestamp": "2026-02-07T02:28:24.461000+00:00",
      "name": "d251_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\n# Setup TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_size = (input_shape[1], input_shape[2])\n\nlabels = load_labels(label_path)\n\n# Video capture and writer\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    print(f\"Error: Could not open video {input_path}\")\n    exit()\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the input image\n    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    resized_frame = cv2.resize(img_rgb, input_size)\n    input_data = np.expand_dims(resized_frame, axis=0).astype(np.uint8)\n\n    # Set tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    height, width, _ = frame.shape\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            object_name = labels[int(classes[i])]\n            label = f\"{object_name}: {int(scores[i] * 100)}%\"\n\n            # Draw bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            cv2.putText(frame, label, (int(left), int(top) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\n\nprint(\"Processing complete. Output saved to:\", output_path)"
      },
      "session_id": "phi4_5f04_psg_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 22.625,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-28-24-462911_chatcmpl-f997ce62-6a7d-45d9-a3e8-c1ec1f8a9c81",
          "traceId": "d251296a",
          "type": "GENERATION",
          "name": "d251_psg_gen_attempt#1",
          "startTime": "2026-02-07T02:28:24.462000+00:00",
          "endTime": "2026-02-07T02:28:36.895000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12433.0,
          "completionTokens": 909,
          "totalTokens": 1326,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-28-37-070150_chatcmpl-070e04e9-7abe-4a6b-ac88-d20a6166c718",
          "traceId": "d251296a",
          "type": "GENERATION",
          "name": "d251_psg_gen_attempt#2",
          "startTime": "2026-02-07T02:28:37.070000+00:00",
          "endTime": "2026-02-07T02:28:47.087000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10017.0,
          "completionTokens": 737,
          "totalTokens": 1424,
          "promptTokens": 687,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-07T02:28:58.166Z",
      "createdAt": "2026-02-07T02:28:24.987Z",
      "environment": "default"
    },
    {
      "id": "971e3aee",
      "timestamp": "2026-02-07T02:27:31.957000+00:00",
      "name": "971e_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\nlabels = load_labels(label_path)\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Preprocessing function\ndef preprocess_frame(frame):\n    input_shape = input_details[0]['shape']\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.uint8)\n    return input_data\n\n# Inference function\ndef run_inference(input_frame):\n    interpreter.set_tensor(input_details[0]['index'], input_frame)\n    interpreter.invoke()\n    \n    # Get output details\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    return boxes, classes, scores\n\n# Post-processing and drawing function\ndef draw_detections(frame, boxes, classes, scores):\n    height, width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            class_id = int(classes[i])\n            box = tuple(boxes[i].tolist())\n            \n            ymin, xmin, ymax, xmax = box\n            left, right, top, bottom = (xmin * width, xmax * width,\n                                        ymin * height, ymax * height)\n            \n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\n# Video processing\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_data = preprocess_frame(frame)\n    boxes, classes, scores = run_inference(input_data)\n    draw_detections(frame, boxes, classes, scores)\n\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\n# Note: Calculation of mAP is complex and requires additional implementation\n# based on the specific requirements and dataset annotations."
      },
      "session_id": "phi4_5f04_psg_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 20.714,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-27-31-958879_chatcmpl-02fce69b-b817-44ad-881e-52a646dd9d30",
          "traceId": "971e3aee",
          "type": "GENERATION",
          "name": "971e_psg_gen_attempt#1",
          "startTime": "2026-02-07T02:27:31.958000+00:00",
          "endTime": "2026-02-07T02:27:41.763000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9805.0,
          "completionTokens": 732,
          "totalTokens": 1149,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-27-41-979059_chatcmpl-62bd3bcf-9cd9-4a06-93dc-f22802b2c1e1",
          "traceId": "971e3aee",
          "type": "GENERATION",
          "name": "971e_psg_gen_attempt#2",
          "startTime": "2026-02-07T02:27:41.979000+00:00",
          "endTime": "2026-02-07T02:27:52.672000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10693.0,
          "completionTokens": 790,
          "totalTokens": 1417,
          "promptTokens": 627,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-07T02:28:03.657Z",
      "createdAt": "2026-02-07T02:27:32.483Z",
      "environment": "default"
    },
    {
      "id": "15654df8",
      "timestamp": "2026-02-07T02:26:36.949000+00:00",
      "name": "1565_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\n\n# Configuration Parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\ndef load_labels(path):\n    with open(path, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\nlabels = load_labels(label_path)\n\n# Initialize the interpreter and allocate tensors\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\n\n# Video capture and output setup\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file {}\".format(input_path))\n\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n\n# Preprocess the frame\ndef preprocess_frame(frame):\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = np.float32(input_data - 127.5) / 127.5\n    return input_data\n\n# Perform inference on the frame\ndef infer(interpreter, frame):\n    input_data = preprocess_frame(frame)\n\n    # Ensure the input data type matches what's expected by the model\n    if input_details[0]['dtype'] == np.uint8:\n        input_data = input_data.astype(np.uint8)\n    \n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Retrieve output tensors\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence score\n\n    return boxes, classes, scores\n\n# Process video frames and draw bounding boxes with labels\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    \n    if not ret:\n        break\n    \n    boxes, classes, scores = infer(interpreter, frame)\n    \n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            xmin = int(xmin * width)\n            xmax = int(xmax * width)\n            ymin = int(ymin * height)\n            ymax = int(ymax * height)\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 2)\n            \n            label = labels[int(classes[i])]\n            text = f\"{label}: {int(scores[i] * 100)}%\"\n            cv2.putText(frame, text, (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n    \n    out.write(frame)\n\ncap.release()\nout.release()\n\n# Note: Mean Average Precision (mAP) computation is a complex task and typically involves\n# comparing the predicted bounding boxes with ground truth data, which requires additional setup."
      },
      "session_id": "phi4_5f04_psg_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 22.989,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-26-36-951051_chatcmpl-d2f14199-8c94-4607-b6dd-7e1d3b29f70f",
          "traceId": "15654df8",
          "type": "GENERATION",
          "name": "1565_psg_gen_attempt#1",
          "startTime": "2026-02-07T02:26:36.951000+00:00",
          "endTime": "2026-02-07T02:26:48.205000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11254.0,
          "completionTokens": 829,
          "totalTokens": 1246,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-26-48-380835_chatcmpl-abde1613-1070-44d1-91a8-9b02a2dbc529",
          "traceId": "15654df8",
          "type": "GENERATION",
          "name": "1565_psg_gen_attempt#2",
          "startTime": "2026-02-07T02:26:48.380000+00:00",
          "endTime": "2026-02-07T02:26:59.940000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11560.0,
          "completionTokens": 853,
          "totalTokens": 1480,
          "promptTokens": 627,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-07T02:27:11.156Z",
      "createdAt": "2026-02-07T02:26:37.475Z",
      "environment": "default"
    },
    {
      "id": "d0c02e7e",
      "timestamp": "2026-02-07T02:25:55.513000+00:00",
      "name": "d0c0_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport time\nimport numpy as np\nimport cv2\nfrom ai_edge_litert.interpreter import Interpreter\n\n# Configuration Parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels from label map\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\nlabels = load_labels(label_path)\n\n# Initialize TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\nheight, width = input_shape[1], input_shape[2]\n\n# Preprocessing function\ndef preprocess_frame(frame):\n    frame_resized = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# Inference function\ndef detect_objects(input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    \n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]   # Confidence of detected objects\n    \n    return boxes, classes, scores\n\n# Video processing\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    input_data = preprocess_frame(frame)\n    \n    start_time = time.time()\n    boxes, classes, scores = detect_objects(input_data)\n    elapsed_ms = (time.time() - start_time) * 1000\n    print(f\"Inference time: {elapsed_ms:.2f} ms\")\n    \n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            left, right, top, bottom = int(xmin * cap.get(3)), int(xmax * cap.get(3)), int(ymin * cap.get(4)), int(ymax * cap.get(4))\n            \n            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {int(scores[i]*100)}%'\n            cv2.putText(frame, label, (left, top-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    out.write(frame)\n\ncap.release()\nout.release()\n\nprint(\"Video processing complete.\")"
      },
      "session_id": "phi4_5f04_psg_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 10.146,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-25-55-515042_chatcmpl-ea412917-93c5-4f6d-9b96-4224df288e43",
          "traceId": "d0c02e7e",
          "type": "GENERATION",
          "name": "d0c0_psg_gen_attempt#1",
          "startTime": "2026-02-07T02:25:55.515000+00:00",
          "endTime": "2026-02-07T02:26:05.661000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10146.0,
          "completionTokens": 764,
          "totalTokens": 1181,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-07T02:26:16.782Z",
      "createdAt": "2026-02-07T02:25:56.042Z",
      "environment": "default"
    },
    {
      "id": "4b73710f",
      "timestamp": "2026-02-07T02:25:11.983000+00:00",
      "name": "4b73_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport time\nimport numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\nimport cv2\n\n# Configuration Parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\n\ndef preprocess_frame(frame):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_shape[1], input_shape[2]))\n    return np.expand_dims(frame_resized, axis=0)\n\ndef postprocess_output(output_data, image_height, image_width):\n    boxes = output_data[0][0]\n    classes = output_data[1][0].astype(np.int32)\n    scores = output_data[2][0]\n\n    results = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * image_width, xmax * image_width,\n                                          ymin * image_height, ymax * image_height)\n\n            results.append((int(left), int(top), int(right), int(bottom),\n                            scores[i], classes[i]))\n\n    return results\n\ndef draw_boxes(frame, boxes):\n    for box in boxes:\n        left, top, right, bottom, score, class_id = box\n        label = f\"{labels[class_id]}: {score:.2f}\"\n        \n        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n        cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX,\n                    0.5, (0, 255, 0), 1)\n\n# Video processing\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise ValueError(\"Error opening video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps,\n                      (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_data = preprocess_frame(frame)\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    start_time = time.time()\n    interpreter.invoke()\n    inference_time = (time.time() - start_time) * 1000\n\n    output_data = [interpreter.get_tensor(output['index']) for output in output_details]\n    detections = postprocess_output(output_data, frame_height, frame_width)\n    \n    draw_boxes(frame, detections)\n\n    out.write(frame)\n    print(f\"Inference Time: {inference_time:.2f} ms\")\n\ncap.release()\nout.release()"
      },
      "session_id": "phi4_5f04_psg_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 11.317,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-25-11-984178_chatcmpl-9538dcd8-8e73-4b0f-a10d-1ea8ed60c955",
          "traceId": "4b73710f",
          "type": "GENERATION",
          "name": "4b73_psg_gen_attempt#1",
          "startTime": "2026-02-07T02:25:11.984000+00:00",
          "endTime": "2026-02-07T02:25:23.301000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11317.0,
          "completionTokens": 825,
          "totalTokens": 1242,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-07T02:25:34.591Z",
      "createdAt": "2026-02-07T02:25:12.508Z",
      "environment": "default"
    },
    {
      "id": "9506473b",
      "timestamp": "2026-02-07T02:23:30.115000+00:00",
      "name": "9506_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport os\nfrom tflite_runtime.interpreter import Interpreter\n\ndef load_labels(path):\n    with open(path, 'r') as f:\n        return [line.strip() for line in f.readlines()]\n\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_shape = interpreter.get_input_details()[0]['shape']\n\n    # Resize the image to fit the model expected size and convert to UINT8\n    image = cv2.resize(image, (input_shape[1], input_shape[2]))\n    image = np.expand_dims(image, axis=0)\n    \n    input_tensor = np.asarray(image, dtype=np.uint8)\n\n    interpreter.set_tensor(tensor_index, input_tensor)\n\ndef get_output(interpreter, score_threshold):\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0] # Confidence of detected objects\n    \n    # Filter out boxes with low confidence\n    n = len(scores)\n    for i in range(n):\n        if scores[i] >= score_threshold:\n            yield scores[i], classes[i], boxes[i]\n\ndef draw_box_on_image(num, class_id, box, im_width, im_height, image, label):\n    ymin, xmin, ymax, xmax = box\n    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n                                  ymin * im_height, ymax * im_height)\n    \n    cv2.rectangle(image, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), thickness=4)\n\n    # Label\n    label = '{}: {}%'.format(label, int(100 * num))\n    label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n    top = max(top, label_size[1])\n    cv2.putText(image, label, (int(left), int(top-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), thickness=2)\n\ndef main():\n    model_path = \"models/ssd-mobilenet_v1/detect.tflite\"\n    label_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\n    input_path = \"data/object_detection/sheeps.mp4\"\n    output_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\n    confidence_threshold = 0.5\n\n    labels = load_labels(label_path)\n\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n\n    _, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']\n    output_height = interpreter.get_output_details()[0]['shape'][1]\n    output_width = interpreter.get_output_details()[0]['shape'][2]\n\n    cap = cv2.VideoCapture(input_path)\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n    out = cv2.VideoWriter(output_path, \n                          cv2.VideoWriter_fourcc(*'mp4v'), \n                          fps, (width, height))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        set_input_tensor(interpreter, frame)\n        interpreter.invoke()\n\n        for num, class_id, box in get_output(interpreter, confidence_threshold):\n            draw_box_on_image(num, int(class_id), box, width, height, frame, labels[int(class_id)])\n\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()"
      },
      "session_id": "phi4_5f04_psg_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 42.43,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-23-30-116673_chatcmpl-c0d26d18-fe9c-486b-807c-b3c7847be267",
          "traceId": "9506473b",
          "type": "GENERATION",
          "name": "9506_psg_gen_attempt#1",
          "startTime": "2026-02-07T02:23:30.116000+00:00",
          "endTime": "2026-02-07T02:23:45.214000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15098.0,
          "completionTokens": 1115,
          "totalTokens": 1532,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-23-45-370117_chatcmpl-9ce6edb1-cf1b-4bde-a6f5-11f146606c8a",
          "traceId": "9506473b",
          "type": "GENERATION",
          "name": "9506_psg_gen_attempt#2",
          "startTime": "2026-02-07T02:23:45.370000+00:00",
          "endTime": "2026-02-07T02:23:58.257000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12887.0,
          "completionTokens": 949,
          "totalTokens": 1651,
          "promptTokens": 702,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-23-58-423018_chatcmpl-6ac66b96-dd4a-4cf7-8b09-fac9b06f7809",
          "traceId": "9506473b",
          "type": "GENERATION",
          "name": "9506_psg_gen_attempt#3",
          "startTime": "2026-02-07T02:23:58.423000+00:00",
          "endTime": "2026-02-07T02:24:12.546000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14123.0,
          "completionTokens": 1041,
          "totalTokens": 1790,
          "promptTokens": 749,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-07T02:24:50.834Z",
      "createdAt": "2026-02-07T02:23:30.640Z",
      "environment": "default"
    },
    {
      "id": "9e89f7c3",
      "timestamp": "2026-02-07T02:22:03.699000+00:00",
      "name": "9e89_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration Parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the interpreter and allocate tensors\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Get input shape\n_, height, width, _ = input_details[0]['shape']\n\n# Video capture and writer setup\ncap = cv2.VideoCapture(input_path)\nfps = cap.get(cv2.CAP_PROP_FPS)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n# Helper function to preprocess the input image\ndef preprocess_image(image):\n    image_resized = cv2.resize(image, (width, height))\n    image_np = np.expand_dims(image_resized, axis=0)\n    return image_np.astype(np.uint8)\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the input image\n    preprocessed_frame = preprocess_image(frame)\n\n    # Set the tensor to the interpreter\n    interpreter.set_tensor(input_details[0]['index'], preprocessed_frame)\n\n    # Run inference\n    interpreter.invoke()\n\n    # Retrieve output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]   # Confidence of detected objects\n\n    # Draw detection boxes with labels\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n\n            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {int(scores[i]*100)}%'\n            cv2.putText(frame, label, (left, top-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260207042302_psg_phi4:latest/tmp_20260207042302_psg_phi4:latest.py\", line 51, in <module>\n    interpreter.set_tensor(input_details[0]['index'], preprocessed_frame)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Dimension mismatch. Got 640 but expected 300 for dimension 1 of input 175.\n"
      },
      "session_id": "phi4_5f04_psg_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 59.167,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-22-03-701118_chatcmpl-599ffb47-b5f5-4fee-802a-3e02a497563e",
          "traceId": "9e89f7c3",
          "type": "GENERATION",
          "name": "9e89_psg_gen_attempt#1",
          "startTime": "2026-02-07T02:22:03.701000+00:00",
          "endTime": "2026-02-07T02:22:15.573000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11872.0,
          "completionTokens": 860,
          "totalTokens": 1277,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-22-15-761241_chatcmpl-2b0a0e2b-15d4-4bb7-b140-351d263e8ec6",
          "traceId": "9e89f7c3",
          "type": "GENERATION",
          "name": "9e89_psg_gen_attempt#2",
          "startTime": "2026-02-07T02:22:15.761000+00:00",
          "endTime": "2026-02-07T02:22:27.208000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11447.0,
          "completionTokens": 842,
          "totalTokens": 1530,
          "promptTokens": 688,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-22-27-377391_chatcmpl-36e7a119-31a6-4c7a-b952-6ef23476565f",
          "traceId": "9e89f7c3",
          "type": "GENERATION",
          "name": "9e89_psg_gen_attempt#3",
          "startTime": "2026-02-07T02:22:27.377000+00:00",
          "endTime": "2026-02-07T02:22:40.406000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13029.0,
          "completionTokens": 963,
          "totalTokens": 1642,
          "promptTokens": 679,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-22-40-535173_chatcmpl-7f344016-6fce-4fb8-959c-456eb764280c",
          "traceId": "9e89f7c3",
          "type": "GENERATION",
          "name": "9e89_psg_gen_attempt#4",
          "startTime": "2026-02-07T02:22:40.535000+00:00",
          "endTime": "2026-02-07T02:22:52.354000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11819.0,
          "completionTokens": 875,
          "totalTokens": 1549,
          "promptTokens": 674,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-22-52-545267_chatcmpl-52c166b4-2fbd-4bca-bd91-37030312e81b",
          "traceId": "9e89f7c3",
          "type": "GENERATION",
          "name": "9e89_psg_gen_attempt#5",
          "startTime": "2026-02-07T02:22:52.545000+00:00",
          "endTime": "2026-02-07T02:23:02.704000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10159.0,
          "completionTokens": 741,
          "totalTokens": 1368,
          "promptTokens": 627,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "9e3f806e-7efc-4791-947c-0d68dd9f8bc3",
          "traceId": "9e89f7c3",
          "type": "SPAN",
          "name": "error_9e_psg_failure_signal_py_sketch_generator",
          "startTime": "2026-02-07T02:23:02.868000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20260207042302_psg_phi4:latest/tmp_20260207042302_psg_phi4:latest.py\", line 51, in <module>\n    interpreter.set_tensor(input_details[0]['index'], preprocessed_frame)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Dimension mismatch. Got 640 but expected 300 for dimension 1 of input 175.\n",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2026-02-07T02:23:08.353Z",
      "createdAt": "2026-02-07T02:22:04.225Z",
      "environment": "default"
    },
    {
      "id": "a4cb2617",
      "timestamp": "2026-02-07T02:20:56.372000+00:00",
      "name": "a4cb_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\n\n# Configuration Parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load Labels\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\nlabels = load_labels(label_path)\n\n# Setup TFLite Interpreter\ninterpreter = Interpreter(model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\noutput_indices = [detail['index'] for detail in output_details]\n\n# Video Processing\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing\n    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    img_resized = cv2.resize(img_rgb, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(img_resized, axis=0).astype(np.uint8)\n\n    # Inference\n    interpreter.set_tensor(input_index, input_data)\n    interpreter.invoke()\n\n    # Extract output data\n    boxes = interpreter.get_tensor(output_indices[0])\n    classes = interpreter.get_tensor(output_indices[1])\n    scores = interpreter.get_tensor(output_indices[2])\n\n    height, width, _ = frame.shape\n\n    for i in range(len(scores[0])):\n        if scores[0][i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[0][i]\n            left, right, top, bottom = int(xmin * width), int(xmax * width), int(ymin * height), int(ymax * height)\n            class_id = classes[0][i]\n\n            # Draw bounding box and label\n            cv2.rectangle(frame, (left, top), (right, bottom), (255, 0, 0), 2)\n            label_text = f\"{labels[int(class_id)]}: {scores[0][i]:.2f}\"\n            cv2.putText(frame, label_text, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n\n    # Output handling\n    out.write(frame)\n\ncap.release()\nout.release()"
      },
      "session_id": "phi4_5f04_psg_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 34.553,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-20-56-373407_chatcmpl-59828b23-d101-4476-8e36-36e7daa0df9d",
          "traceId": "a4cb2617",
          "type": "GENERATION",
          "name": "a4cb_psg_gen_attempt#1",
          "startTime": "2026-02-07T02:20:56.373000+00:00",
          "endTime": "2026-02-07T02:21:06.960000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10587.0,
          "completionTokens": 769,
          "totalTokens": 1186,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-21-07-244135_chatcmpl-dee6c456-8df5-4612-a639-9e601edbad96",
          "traceId": "a4cb2617",
          "type": "GENERATION",
          "name": "a4cb_psg_gen_attempt#2",
          "startTime": "2026-02-07T02:21:07.244000+00:00",
          "endTime": "2026-02-07T02:21:20.954000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13710.0,
          "completionTokens": 1014,
          "totalTokens": 1637,
          "promptTokens": 623,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-21-21-188162_chatcmpl-3c963bab-8fb9-40e1-b449-c476956594bb",
          "traceId": "a4cb2617",
          "type": "GENERATION",
          "name": "a4cb_psg_gen_attempt#3",
          "startTime": "2026-02-07T02:21:21.188000+00:00",
          "endTime": "2026-02-07T02:21:30.926000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9738.0,
          "completionTokens": 727,
          "totalTokens": 1350,
          "promptTokens": 623,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-07T02:21:42.019Z",
      "createdAt": "2026-02-07T02:20:56.897Z",
      "environment": "default"
    },
    {
      "id": "a832dc2a",
      "timestamp": "2026-02-07T02:20:00.921000+00:00",
      "name": "a832_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport os\nfrom ai_edge_litert.interpreter import Interpreter\n\n# Configuration Parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Open video file\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\noutput_video = cv2.VideoWriter(output_path, \n                               cv2.VideoWriter_fourcc(*'mp4v'), \n                               fps, \n                               (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the input image\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.uint8)\n\n    # Set the tensor and run inference\n    interpreter.set_tensor(input_index, input_data)\n    interpreter.invoke()\n\n    # Extract output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]   # Confidence of detected objects\n\n    # Post-process the output and draw bounding boxes\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n            left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n\n            # Draw rectangle and label\n            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n            object_name = labels[int(classes[i])]\n            label = f'{object_name}: {int(scores[i]*100)}%'\n            cv2.putText(frame, label, (left, top - 5), cv2.FONT_HERSHEY_SIMPLEX,\n                        0.7, (0, 255, 0), 2)\n\n    # Write the frame with detection to output video\n    output_video.write(frame)\n\n# Release resources\ncap.release()\noutput_video.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "phi4_5f04_psg_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 24.063,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-20-00-922942_chatcmpl-b90b52e4-367f-437d-8ca2-0a7d161d4b8d",
          "traceId": "a832dc2a",
          "type": "GENERATION",
          "name": "a832_psg_gen_attempt#1",
          "startTime": "2026-02-07T02:20:00.922000+00:00",
          "endTime": "2026-02-07T02:20:11.528000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10606.0,
          "completionTokens": 808,
          "totalTokens": 1225,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-20-11-707953_chatcmpl-546f32d1-4593-4191-9ae6-3b9d7ecd313f",
          "traceId": "a832dc2a",
          "type": "GENERATION",
          "name": "a832_psg_gen_attempt#2",
          "startTime": "2026-02-07T02:20:11.707000+00:00",
          "endTime": "2026-02-07T02:20:24.985000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13278.0,
          "completionTokens": 975,
          "totalTokens": 1598,
          "promptTokens": 623,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-07T02:20:36.069Z",
      "createdAt": "2026-02-07T02:20:01.445Z",
      "environment": "default"
    },
    {
      "id": "80a7f363",
      "timestamp": "2026-02-07T02:19:16.499000+00:00",
      "name": "80a7_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels from label map file\ndef load_labels(label_path):\n    with open(label_path, 'r') as f:\n        return {i: line.strip() for i, line in enumerate(f.readlines())}\n\n# Initialize TFLite interpreter and allocate tensors\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input details and output details from the model\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n_, height, width, _ = input_details[0]['shape']\n\n# Load labels\nlabels = load_labels(label_path)\n\n# Open video capture and writer\ncap = cv2.VideoCapture(input_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\n# Function to preprocess the input image\ndef preprocess_frame(frame):\n    frame_resized = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# Inference and postprocessing\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    # Preprocess the frame\n    input_data = preprocess_frame(frame)\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    # Draw detection boxes and labels on the frame\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            \n            object_name = labels[int(classes[i])]\n            label = f'{object_name}: {int(scores[i]*100)}%'\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (int(left), int(top - round(1.5*label_size[1]))),\n                          (int(left + round(1.5*label_size[0])), int(top + base_line)), \n                          (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (int(left), int(top + base_line)), \n                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    # Write the frame with detections to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(\"Processing complete. Output saved at:\", output_path)"
      },
      "session_id": "phi4_5f04_psg_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 12.402,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-19-16-500605_chatcmpl-56dff474-1180-40e9-b7d1-37173b08f50b",
          "traceId": "80a7f363",
          "type": "GENERATION",
          "name": "80a7_psg_gen_attempt#1",
          "startTime": "2026-02-07T02:19:16.500000+00:00",
          "endTime": "2026-02-07T02:19:28.902000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12402.0,
          "completionTokens": 889,
          "totalTokens": 1306,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-07T02:19:40.159Z",
      "createdAt": "2026-02-07T02:19:17.023Z",
      "environment": "default"
    },
    {
      "id": "864547e1",
      "timestamp": "2026-02-07T02:17:25.752000+00:00",
      "name": "8645_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\ndef load_labels(label_path):\n    with open(label_path, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_tensor = interpreter.tensor(tensor_index)()[0]\n    input_tensor[:, :] = np.expand_dims(image, 0)\n\ndef get_output_tensor(interpreter, index):\n    output_details = interpreter.get_output_details()[index]\n    tensor = np.squeeze(interpreter.get_tensor(output_details['index']))\n    return tensor\n\ndef draw_box_on_image(num, box, class_name, score, frame_width, frame_height):\n    ymin, xmin, ymax, xmax = box\n    left, right, top, bottom = int(xmin * frame_width), int(xmax * frame_width), int(ymin * frame_height), int(ymax * frame_height)\n    \n    cv2.rectangle(frame, (left, top), (right, bottom), color=(0, 255, 0), thickness=3)\n    label = f'{class_name}: {score:.2f}'\n    cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\ndef main():\n    global frame\n\n    labels = load_labels(label_path)\n    \n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n\n    _, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']\n\n    cap = cv2.VideoCapture(input_path)\n    if not cap.isOpened():\n        print(\"Error: Could not open video.\")\n        return\n\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        image = cv2.resize(frame, (input_width, input_height))\n        set_input_tensor(interpreter, image)\n\n        interpreter.invoke()\n\n        boxes = get_output_tensor(interpreter, 0)\n        classes = get_output_tensor(interpreter, 1)\n        scores = get_output_tensor(interpreter, 2)\n\n        count = int(get_output_tensor(interpreter, 3))\n\n        for i in range(count):\n            if scores[i] >= confidence_threshold:\n                draw_box_on_image(i, boxes[i], labels[int(classes[i])], scores[i], width, height)\n\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == \"__main__\":\n    main()"
      },
      "session_id": "phi4_5f04_psg_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 51.48,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-17-25-754253_chatcmpl-2183f43c-30a6-4a74-84a6-b8ba8fdf0b68",
          "traceId": "864547e1",
          "type": "GENERATION",
          "name": "8645_psg_gen_attempt#1",
          "startTime": "2026-02-07T02:17:25.754000+00:00",
          "endTime": "2026-02-07T02:17:36.276000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10522.0,
          "completionTokens": 774,
          "totalTokens": 1191,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-17-36-416870_chatcmpl-34602676-9c61-482e-ace1-6d4e50e5aadc",
          "traceId": "864547e1",
          "type": "GENERATION",
          "name": "8645_psg_gen_attempt#2",
          "startTime": "2026-02-07T02:17:36.416000+00:00",
          "endTime": "2026-02-07T02:17:51.539000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15123.0,
          "completionTokens": 1120,
          "totalTokens": 1666,
          "promptTokens": 546,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-17-51-903632_chatcmpl-af5be2bc-1a71-4a51-b649-709485e28afe",
          "traceId": "864547e1",
          "type": "GENERATION",
          "name": "8645_psg_gen_attempt#3",
          "startTime": "2026-02-07T02:17:51.903000+00:00",
          "endTime": "2026-02-07T02:18:03.339000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11436.0,
          "completionTokens": 842,
          "totalTokens": 1560,
          "promptTokens": 718,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-18-03-809789_chatcmpl-8374046b-fff8-42e9-9f4c-4f838738bfce",
          "traceId": "864547e1",
          "type": "GENERATION",
          "name": "8645_psg_gen_attempt#4",
          "startTime": "2026-02-07T02:18:03.809000+00:00",
          "endTime": "2026-02-07T02:18:17.234000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13425.0,
          "completionTokens": 984,
          "totalTokens": 1701,
          "promptTokens": 717,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-07T02:18:55.494Z",
      "createdAt": "2026-02-07T02:17:26.276Z",
      "environment": "default"
    },
    {
      "id": "3c583ccf",
      "timestamp": "2026-02-07T02:16:30.348000+00:00",
      "name": "3c58_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\n\n# Configuration Parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels from the label map\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\nlabels = load_labels(label_path)\n\n# Initialize TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\n\ndef preprocess_frame(frame):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.uint8)  # Corrected type to UINT8\n    return input_data\n\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        score = float(detection[2])\n        if score > confidence_threshold:\n            ymin, xmin, ymax, xmax = detection[0:4]\n            left, right, top, bottom = int(xmin * frame.shape[1]), int(xmax * frame.shape[1]), int(ymin * frame.shape[0]), int(ymax * frame.shape[0])\n            \n            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n            label = f\"{labels[int(detection[1])]}: {score:.2f}\"\n            cv2.putText(frame, label, (left, top - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n\ndef main():\n    cap = cv2.VideoCapture(input_path)\n    if not cap.isOpened():\n        print(f\"Error: Cannot open video file {input_path}\")\n        return\n\n    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        input_data = preprocess_frame(frame)\n        interpreter.set_tensor(input_details[0]['index'], input_data)\n\n        interpreter.invoke()\n\n        # Get output details\n        boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n        classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n        scores = interpreter.get_tensor(output_details[2]['index'])[0]   # Confidence of detected objects\n\n        detections = np.column_stack((boxes, classes, scores))\n        draw_boxes(frame, detections)\n\n        out.write(frame)\n    \n    cap.release()\n    out.release()\n\nif __name__ == \"__main__\":\n    main()"
      },
      "session_id": "phi4_5f04_psg_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 23.5,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-16-30-349768_chatcmpl-4883af17-bcb7-4b02-bfd8-796f78c2a9df",
          "traceId": "3c583ccf",
          "type": "GENERATION",
          "name": "3c58_psg_gen_attempt#1",
          "startTime": "2026-02-07T02:16:30.349000+00:00",
          "endTime": "2026-02-07T02:16:42.209000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11860.0,
          "completionTokens": 881,
          "totalTokens": 1298,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-16-42-385645_chatcmpl-2d3c880a-c9ce-4797-bb29-b87909dc571a",
          "traceId": "3c583ccf",
          "type": "GENERATION",
          "name": "3c58_psg_gen_attempt#2",
          "startTime": "2026-02-07T02:16:42.385000+00:00",
          "endTime": "2026-02-07T02:16:53.849000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11464.0,
          "completionTokens": 829,
          "totalTokens": 1516,
          "promptTokens": 687,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-07T02:17:04.979Z",
      "createdAt": "2026-02-07T02:16:30.873Z",
      "environment": "default"
    },
    {
      "id": "5a3aff4b",
      "timestamp": "2026-02-07T02:15:12.826000+00:00",
      "name": "5a3a_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\n\n# Configuration Parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\nlabels = load_labels(label_path)\n\n# Initialize TFLite interpreter and allocate tensors\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Get input image size\n_, input_height, input_width, _ = input_details[0]['shape']\n\n# Open video files\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing\n    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    resized_image = cv2.resize(image_rgb, (input_width, input_height))\n    input_data = np.expand_dims(resized_image, axis=0)\n\n    # Set the tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], np.uint8(input_data))\n\n    interpreter.invoke()\n\n    # Get output details\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]   # Confidence of detected objects\n\n    # Draw boxes and labels on the image\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n\n            # Draw rectangle and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {int(scores[i] * 100)}%\"\n            cv2.putText(frame, label, (int(left), int(top) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\n    # Write the frame with boxes\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "phi4_5f04_psg_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 45.322,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-15-12-829642_chatcmpl-d6690b5c-eeb7-4e49-9b0a-0220314379a6",
          "traceId": "5a3aff4b",
          "type": "GENERATION",
          "name": "5a3a_psg_gen_attempt#1",
          "startTime": "2026-02-07T02:15:12.829000+00:00",
          "endTime": "2026-02-07T02:15:26.340000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13511.0,
          "completionTokens": 1004,
          "totalTokens": 1421,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-15-26-589194_chatcmpl-f966b4df-dd74-40e1-b8fa-721ce072ee84",
          "traceId": "5a3aff4b",
          "type": "GENERATION",
          "name": "5a3a_psg_gen_attempt#2",
          "startTime": "2026-02-07T02:15:26.589000+00:00",
          "endTime": "2026-02-07T02:15:38.226000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11637.0,
          "completionTokens": 855,
          "totalTokens": 1483,
          "promptTokens": 628,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-15-38-407961_chatcmpl-c3aee600-7be0-427c-aa6d-8efde90ce18e",
          "traceId": "5a3aff4b",
          "type": "GENERATION",
          "name": "5a3a_psg_gen_attempt#3",
          "startTime": "2026-02-07T02:15:38.407000+00:00",
          "endTime": "2026-02-07T02:15:48.190000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9783.0,
          "completionTokens": 722,
          "totalTokens": 1353,
          "promptTokens": 631,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-15-48-363945_chatcmpl-899d6199-3b3e-4d3b-8ef5-eb6a410b8e0f",
          "traceId": "5a3aff4b",
          "type": "GENERATION",
          "name": "5a3a_psg_gen_attempt#4",
          "startTime": "2026-02-07T02:15:48.363000+00:00",
          "endTime": "2026-02-07T02:15:58.151000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9788.0,
          "completionTokens": 723,
          "totalTokens": 1350,
          "promptTokens": 627,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-07T02:16:09.470Z",
      "createdAt": "2026-02-07T02:15:13.352Z",
      "environment": "default"
    },
    {
      "id": "783f2cd4",
      "timestamp": "2026-02-07T02:13:36.750000+00:00",
      "name": "783f_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path = \"data/object_detection/sheeps.mp4\"\noutput_path = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as file:\n    labels = [line.strip() for line in file.readlines()]\n\n# Initialize the TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Open input video\ncap = cv2.VideoCapture(input_path)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the input image\n    height, width, _ = frame.shape\n    input_frame = cv2.resize(frame, (300, 300))\n    input_frame = np.expand_dims(input_frame, axis=0)\n\n    # Convert to UINT8 as expected by the model\n    input_frame = np.uint8(255 * (input_frame / 255.0))\n\n    # Set tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_frame)\n    interpreter.invoke()\n\n    # Get detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence score\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame with detections\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\n# Note: mAP calculation is not implemented here as it requires ground truth annotations and additional logic."
      },
      "session_id": "phi4_5f04_psg_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 62.219,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-13-36-751265_chatcmpl-2d3b69bb-82e6-4ebf-8c0f-8174fd5f97a4",
          "traceId": "783f2cd4",
          "type": "GENERATION",
          "name": "783f_psg_gen_attempt#1",
          "startTime": "2026-02-07T02:13:36.751000+00:00",
          "endTime": "2026-02-07T02:14:29.624000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 52873.0,
          "completionTokens": 745,
          "totalTokens": 1162,
          "promptTokens": 417,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-14-29-964734_chatcmpl-b2aea4a4-ca72-4e98-9b5e-6a6d8c6896d0",
          "traceId": "783f2cd4",
          "type": "GENERATION",
          "name": "783f_psg_gen_attempt#2",
          "startTime": "2026-02-07T02:14:29.964000+00:00",
          "endTime": "2026-02-07T02:14:38.970000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9006.0,
          "completionTokens": 631,
          "totalTokens": 1258,
          "promptTokens": 627,
          "costDetails": {},
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2026-02-07T02:14:50.475Z",
      "createdAt": "2026-02-07T02:13:37.275Z",
      "environment": "default"
    }
  ],
  "meta": {
    "total_items": 30
  }
}