{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "session_id_list = [\n",
    "    # \"gpt-5-2025-08-07_7aac_psg_batch\",\n",
    "    # \"gpt-5-2025-08-07_7aac_tpusg_batch\",\n",
    "    # \"gpt-5-2025-08-07_f7c7_sg_batch\",\n",
    "    # \"gpt-5-2025-08-07_92de_sg_batch\",\n",
    "    \"gpt-5-2025-08-07_6b01_sg_batch\",\n",
    "    \"gpt-5-2025-08-07_6b01_psg_batch\",\n",
    "    \"gpt-5-2025-08-07_6b01_tpusg_batch\",\n",
    "    # \"gpt-5-2025-08-07_88d1_sg_batch\"\n",
    " \n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session gpt-5-2025-08-07_6b01_sg_batch...\n",
      "Fetching observation data for time-18-52-36-777229_chatcmpl-D6JMLQF1G56vJQbsBzPcOU63yf9X8...\n",
      "Fetching observation data for time-18-53-30-681668_chatcmpl-D6JNCAya5wAhLPgklM8V89IKdaVU4...\n",
      "Fetching observation data for time-18-54-38-370150_chatcmpl-D6JOIq96X1zeKxpyG02T8GkS87qEb...\n",
      "Fetching observation data for time-18-56-25-550030_chatcmpl-D6JQ1FCQxUOcRXEWZbKBgDby00EPN...\n",
      "Fetching observation data for time-18-58-10-772649_chatcmpl-D6JRjqhZHDntIuUsdQcgxXtd7d6c0...\n",
      "Fetching observation data for time-18-59-48-508700_chatcmpl-D6JTIZSZrHQoyAf65mfnILatMKgnU...\n",
      "Fetching observation data for time-19-02-45-361395_chatcmpl-D6JW9TuQN60Wj9Y613Xfm7H3qEBvA...\n",
      "Fetching observation data for d97431a6-3593-4d6f-9c90-679a5cf43c39...\n",
      "Fetching observation data for time-18-46-43-906111_chatcmpl-D6JGe6kBgIuxkmzJQRbHJXdZnPP3q...\n",
      "Fetching observation data for time-18-47-44-697631_chatcmpl-D6JHcf6bMwGrzrw9P7wZ3NAVD2IZt...\n",
      "Fetching observation data for time-18-48-34-604676_chatcmpl-D6JIQtRpcdiAyXeC5u97pNInoTev4...\n",
      "Fetching observation data for time-18-50-17-231418_chatcmpl-D6JK50JRMxfJrqcmUa1y9bVTNiSr5...\n",
      "Fetching observation data for time-18-35-28-063716_chatcmpl-D6J5k0DWRkmghGrgkvHZrP3iUHLC8...\n",
      "Fetching observation data for time-18-36-19-681165_chatcmpl-D6J6Z7OYARCLKodEu1pnq9tvzO1f8...\n",
      "Fetching observation data for time-18-37-11-366355_chatcmpl-D6J7Po0q7LX3w1dXuLTuxmkKMx1wQ...\n",
      "Fetching observation data for time-18-39-07-282714_chatcmpl-D6J9HCCY1mDtWIPWJXuKBSTaVw5sQ...\n",
      "Fetching observation data for time-18-40-43-526449_chatcmpl-D6JAp9fJ2fTiWo0ceQmfPLHJVl7Jj...\n",
      "Fetching observation data for time-18-42-30-376248_chatcmpl-D6JCYGJ56jLCelXu6qU1aUPXC47Rs...\n",
      "Fetching observation data for time-18-44-19-675705_chatcmpl-D6JEJJsEwlkx4SaCHWdSPeBHlrNsR...\n",
      "Fetching observation data for 1a8dc262-09ab-4281-9d0d-c3ed14f2d599...\n",
      "Fetching observation data for time-18-29-52-190792_chatcmpl-D6J0KcGd8G4LIs9YTo6rYgjrkNWgn...\n",
      "Fetching observation data for time-18-30-47-853366_chatcmpl-D6J1E3wCJruNOo0vGajaZFlLA78HG...\n",
      "Fetching observation data for time-18-32-31-426521_chatcmpl-D6J2tCJw0V7DigAU3HM0Eye0EGHax...\n",
      "Fetching observation data for time-18-23-47-317400_chatcmpl-D6IuRpX4DGJFvOnEKrQ8rTcMeKa8t...\n",
      "Fetching observation data for time-18-24-46-435575_chatcmpl-D6IvO3GMf5hFs8APePvEsV6AGUGTl...\n",
      "Fetching observation data for time-18-26-52-506970_chatcmpl-D6IxQnzDZqkwrWJ22qbW96zlOGZnK...\n",
      "Fetching observation data for time-18-11-45-262268_chatcmpl-D6Iin8qXw0yBHH8IQZSmnBDXYCd6W...\n",
      "Fetching observation data for time-18-12-32-842234_chatcmpl-D6IjZ3HjgnkRDyX7pPg6e3APuo5k2...\n",
      "Fetching observation data for time-18-14-19-940622_chatcmpl-D6IlIDlZ7per78W9acAXjDVbXkQfD...\n",
      "Fetching observation data for time-18-17-27-472814_chatcmpl-D6IoJfrYuxRrZRUwfzcepNNwjMCG4...\n",
      "Fetching observation data for time-18-19-27-496376_chatcmpl-D6IqFqAPdz5mCz3i1XqnYtSkDDBkZ...\n",
      "Fetching observation data for time-18-21-21-527241_chatcmpl-D6Is5WnTcrvlFy8pbW1j1sCN6uDU9...\n",
      "Fetching observation data for 1696c8b6-0954-4760-9b20-81bc45ec65c1...\n",
      "Fetching observation data for time-17-58-55-811781_chatcmpl-D6IWOCCHmyNoTEeYlVB5EfAHJdPEe...\n",
      "Fetching observation data for time-17-59-34-998949_chatcmpl-D6IX1CI5EUqQ0dvIfF1Kixwd0Oxic...\n",
      "Fetching observation data for time-18-01-27-428792_chatcmpl-D6IYpRHE91XjyH6y9Cb9YqCMGrIF2...\n",
      "Fetching observation data for time-18-03-19-286062_chatcmpl-D6IadT5CSDNKISGcb8FN06Ww3UU4f...\n",
      "Fetching observation data for time-18-05-37-274607_chatcmpl-D6IeD1FUBvejzcj1ZuDzCaS1Pw3dH...\n",
      "Fetching observation data for time-18-08-47-898333_chatcmpl-D6Ifw5EUo4tBZLi9wiUzhwVhHQPtx...\n",
      "Fetching observation data for 5f84bb18-2fe9-4bdb-af38-a3d9ade82370...\n",
      "Fetching observation data for time-17-48-47-798355_chatcmpl-D6IMa7GERbJA7ghaasbkHMO46zd0h...\n",
      "Fetching observation data for time-17-49-35-661621_chatcmpl-D6INLxhCtZ7ylpEaS9dz2bunfGVtp...\n",
      "Fetching observation data for time-17-51-26-244445_chatcmpl-D6IP8S5b40c9TRz3G5vMufkEh97m5...\n",
      "Fetching observation data for time-17-53-18-405615_chatcmpl-D6IQw2MWfWWe3yIUDl9gMV6AcOamG...\n",
      "Fetching observation data for time-17-55-07-617565_chatcmpl-D6ISh3bPt3ojQ3Ukv0e8HSwPDkHia...\n",
      "Fetching observation data for time-17-56-45-456075_chatcmpl-D6IUHxnHhGmzlGUiWPMnG8D3ZPO8O...\n",
      "Fetching observation data for f32cc607-a63b-41c4-bd28-3e64e0e55793...\n",
      "Fetching observation data for time-17-41-56-271193_chatcmpl-D6IFwoaLCQBf8UUR5JAWyv72DVZKk...\n",
      "Fetching observation data for time-17-42-56-308730_chatcmpl-D6IGuHgbEF5sdsRaN9T3JypoyFOQ3...\n",
      "Fetching observation data for time-17-45-37-231732_chatcmpl-D6IJV0PBcrnlnUIWbthnqSDfVHD5H...\n",
      "Fetching observation data for time-17-37-11-386283_chatcmpl-D6IBLIKfCuFZRcPVglHHNX2efUwIq...\n",
      "Fetching observation data for time-17-37-53-141122_chatcmpl-D6IC1hnIXxu2k1Ov5h8JttxiUTsLg...\n",
      "Fetching observation data for time-17-39-22-504328_chatcmpl-D6IDSsB3zIYdD8OsDZ0QZarTgL7m9...\n",
      "Fetching observation data for time-17-31-44-269676_chatcmpl-D6I64uCX4xJBbxqb7XbmQ2bAimdMY...\n",
      "Fetching observation data for time-17-32-45-367940_chatcmpl-D6I73pC6TAVp70OCEE8j67pinHJDc...\n",
      "Fetching observation data for time-17-34-12-903957_chatcmpl-D6I8Tdq2OXzzEk9Ds1NzgpSg5Et1V...\n",
      "Fetching observation data for time-17-20-55-286594_chatcmpl-D6HvbgbJkPVaMeJ6FoSHxfn4rg7mN...\n",
      "Fetching observation data for time-17-21-42-704947_chatcmpl-D6HwNxUSU659c1wSiVU36Hefip7Sf...\n",
      "Fetching observation data for time-17-23-33-046677_chatcmpl-D6Hy93aaeGQWbqa8YYqWshBGWHK59...\n",
      "Fetching observation data for time-17-25-27-914556_chatcmpl-D6I00UtQCzFf42hL78U3Y4zT46ugV...\n",
      "Fetching observation data for time-17-27-22-666244_chatcmpl-D6I1qOhmHEIXuUD0IhNNDa4YckUgx...\n",
      "Fetching observation data for time-17-28-57-235599_chatcmpl-D6I3N3bGrqnx97UdMDrJ8bDw3n91M...\n",
      "Fetching observation data for time-17-15-18-340724_chatcmpl-D6HqAwQQs0BLaj1B1ZjoG3bksG8Zh...\n",
      "Fetching observation data for time-17-16-09-647525_chatcmpl-D6Hqz2jHrJvWnzYer2tzV1q29Bj5u...\n",
      "Fetching observation data for time-17-16-54-460615_chatcmpl-D6HriBzgBMmXU2DPWXkL6Bwkzm4lL...\n",
      "Fetching observation data for time-17-18-14-847792_chatcmpl-D6Ht178HFBHayjPA4rw42lAga358l...\n",
      "Fetching observation data for time-17-08-48-042555_chatcmpl-D6HjtJ0WdfmmSRJBi0Vb2l9bw62rs...\n",
      "Fetching observation data for time-17-09-35-838192_chatcmpl-D6Hkems7gVqmzVhRHHccxvElNUtjk...\n",
      "Fetching observation data for time-17-10-20-102702_chatcmpl-D6HlMLDJLGuHC04nkearXsuPTEuDC...\n",
      "Fetching observation data for time-17-11-34-530873_chatcmpl-D6HmYWGBdV3fVy2P4vTKLVzKBCie5...\n",
      "Fetching observation data for time-17-13-03-504158_chatcmpl-D6HnzGV75N3FSRoYMhY5achaFjSp8...\n",
      "Fetching observation data for time-16-57-42-056333_chatcmpl-D6HZ8aAi4yKgJHFCKTavkBkurgXtZ...\n",
      "Fetching observation data for time-16-58-24-231544_chatcmpl-D6HZoJqnCyp66OdjXVJx4IIvizjMq...\n",
      "Fetching observation data for time-16-59-59-347931_chatcmpl-D6HbLlzAWiFXduNwb5XmwLj3eXcgj...\n",
      "Fetching observation data for time-17-01-33-143409_chatcmpl-D6Hcr7zPsVJyvJGlcZdPt1osBAb7e...\n",
      "Fetching observation data for time-17-04-01-262791_chatcmpl-D6HfFjtprSWPu1HFvJHPzyEvYmBD1...\n",
      "Fetching observation data for time-17-05-54-202707_chatcmpl-D6Hh53ZSL8UUMy0KXf4Az0RLwGq7K...\n",
      "Fetching observation data for time-16-52-35-138954_chatcmpl-D6HUBApQe5T1jMpB5ercdqE7m7Bnv...\n",
      "Fetching observation data for time-16-53-19-240111_chatcmpl-D6HUtAMW9u3F7GBuYudDFMJ4QgfPq...\n",
      "Fetching observation data for time-16-54-52-575571_chatcmpl-D6HWOXi0nR2z0hFhirkkVcVKm1Ii3...\n",
      "Fetching observation data for time-16-42-02-333632_chatcmpl-D6HJyXifhpCAXKTF5FrCAQFR6vKL8...\n",
      "Fetching observation data for time-16-42-44-319470_chatcmpl-D6HKe0lCIb8nkeH5hhfotaa43D1Vl...\n",
      "Fetching observation data for time-16-44-04-143595_chatcmpl-D6HLw6VS5f5cwaf5LO2RcFg4SFzVS...\n",
      "Fetching observation data for time-16-45-35-392932_chatcmpl-D6HNPreCmB9xHcOE9GymBtCfbPPPs...\n",
      "Fetching observation data for time-16-47-46-759372_chatcmpl-D6HPX1sMGAk7S1JyuAQpP1kZf7thA...\n",
      "Fetching observation data for time-16-49-54-632085_chatcmpl-D6HRbSt1GbT6WUuJ58YLB0SN1IeFI...\n",
      "Fetching observation data for time-16-37-24-326304_chatcmpl-D6HFanYs4kOMCTNCG5TLv5TE1Jqng...\n",
      "Fetching observation data for time-16-38-18-055787_chatcmpl-D6HGMLWIscp9hBYvjSNrcQ7tjzpmj...\n",
      "Fetching observation data for time-16-39-32-634561_chatcmpl-D6HHYFAhzYYkEKb99fCvCif08GY1x...\n",
      "Fetching observation data for time-16-32-14-386529_chatcmpl-D6HAUvawWWckqd8ErjwMGI6sKTayM...\n",
      "Fetching observation data for time-16-33-07-606376_chatcmpl-D6HBL1VToABl7Q3BrjW5wc6y2ZBUG...\n",
      "Fetching observation data for time-16-34-46-311812_chatcmpl-D6HCwrvLGoMT95Rlgf5w78kEGV3xL...\n",
      "Fetching observation data for time-16-27-10-398879_chatcmpl-D6H5anDXEwOOSRNCS7mNWyEHEDCX6...\n",
      "Fetching observation data for time-16-27-51-611086_chatcmpl-D6H6GFTxwTMUcSruKCYhix5TtNGkx...\n",
      "Fetching observation data for time-16-28-40-163412_chatcmpl-D6H72LUkeiawevUahcZUcHWuHC0OB...\n",
      "Fetching observation data for time-16-29-56-794306_chatcmpl-D6H8HmjNhNvyujTNqrbDb7a9Pe0Bu...\n",
      "Fetching observation data for time-16-22-13-326846_chatcmpl-D6H0nMH7dyGMZwDlkz9qaOlsqfFiZ...\n",
      "Fetching observation data for time-16-22-53-337157_chatcmpl-D6H1RCpD6SeYJwFKUbEtf8JSPDDbR...\n",
      "Fetching observation data for time-16-24-24-641368_chatcmpl-D6H2uX8pT7GvLmHQq4VX5KrLdXVOM...\n",
      "Fetching observation data for time-16-17-31-276834_chatcmpl-D6GwF39fZy85tdyiU2hift8BY9Wa9...\n",
      "Fetching observation data for time-16-18-11-634353_chatcmpl-D6GwubzalvM5Dk7MIYVw1ZUwakjNt...\n",
      "Fetching observation data for time-16-19-38-542103_chatcmpl-D6GyIC1eLkUZPefMZ6lyz8otxSQTk...\n",
      "Fetching observation data for time-16-10-12-211487_chatcmpl-D6GpB5yyFR9SX9Vnw3a0s9zPXHoke...\n",
      "Fetching observation data for time-16-10-54-703796_chatcmpl-D6GpqGEkYpAkKwwOzNSJfKFTixiEV...\n",
      "Fetching observation data for time-16-12-26-105605_chatcmpl-D6GrKqpbZd7tpKozhZDJrbZ0Z6yFh...\n",
      "Fetching observation data for time-16-13-51-975610_chatcmpl-D6Gsiph9GUG4rYMAenAcZE4Ldkfow...\n",
      "Fetching observation data for time-16-15-20-179675_chatcmpl-D6Gu86MRWfH9hhHRX4Glit9LWhTuW...\n",
      "Fetching observation data for time-16-01-29-426700_chatcmpl-D6GgjGHvNMyMNC5Ktfk1B3SOAHwsR...\n",
      "Fetching observation data for time-16-02-36-038549_chatcmpl-D6GhoHkBDhbCdA3t8vBVpwppK090U...\n",
      "Fetching observation data for time-16-04-05-965405_chatcmpl-D6GjGY8pracFj0cxJhmij3aXNpAIT...\n",
      "Fetching observation data for time-16-05-30-483402_chatcmpl-D6Gkd80kjL3c4cLI2AJjDDgREXbzc...\n",
      "Fetching observation data for time-16-07-05-634106_chatcmpl-D6Gm9V3SNlkeRpxDD27tWzQMLPwCK...\n",
      "Fetching observation data for time-16-08-28-388097_chatcmpl-D6GnUIb8xDpq5i91BqZvmMsygQgFD...\n",
      "Fetching observation data for c505dffd-9ee6-4380-bd72-df9fc1069784...\n",
      "Fetching observation data for time-15-50-07-407543_chatcmpl-D6GVjimD8uyh88gtvYuoOiOgvxmZw...\n",
      "Fetching observation data for time-15-50-58-809658_chatcmpl-D6GWZUsFyfmBvennSyCf5fPEZdHwE...\n",
      "Fetching observation data for time-15-51-40-072393_chatcmpl-D6GXE8zuZNjeDeKdcPM7lus1U53jE...\n",
      "Fetching observation data for time-15-53-20-919306_chatcmpl-D6GYrTSLi8jvfZCZSC5UhYthX1VFS...\n",
      "Fetching observation data for time-15-55-08-240307_chatcmpl-D6GaaeknBhmduwqGjGgTfxqtCLnD4...\n",
      "Fetching observation data for time-15-57-06-134365_chatcmpl-D6GcUT1kGFPtfftJVDEz2GL2hkFgP...\n",
      "Fetching observation data for time-15-58-48-283106_chatcmpl-D6Ge8ZzM2Hor54rZ881kbaTv50GI6...\n",
      "Fetching observation data for time-15-41-08-255855_chatcmpl-D6GN2KvZk0Pj2kWeYHFehps5mFLSW...\n",
      "Fetching observation data for time-15-41-55-236750_chatcmpl-D6GNn7vKcOnzr5cEqbffG0xixy5Vw...\n",
      "Fetching observation data for time-15-43-36-971595_chatcmpl-D6GPRIQmNPsPwsh3MheKM71xJyPAn...\n",
      "Fetching observation data for time-15-45-36-829773_chatcmpl-D6GRNpYpPlLpRP3P99QMGNs8hHD6S...\n",
      "Fetching observation data for time-15-47-15-067147_chatcmpl-D6GSxeEzi0F9RsUEZcsqByTCREGya...\n",
      "Fetching observation data for time-15-29-58-515874_chatcmpl-D6GCFxK1AUBWHDPCxEa63LYSduRQn...\n",
      "Fetching observation data for time-15-30-59-274751_chatcmpl-D6GDDmNDGYPb527f8VBCXvXBsySSS...\n",
      "Fetching observation data for time-15-31-47-303427_chatcmpl-D6GDzN6pdwSvtekKnA0JsjoAxRrF4...\n",
      "Fetching observation data for time-15-33-11-303685_chatcmpl-D6GFLlcD4F539zi92hdBoOG9JpygM...\n",
      "Fetching observation data for time-15-34-48-587972_chatcmpl-D6GGvjI1z7g1cUGsf1tVaHh8AU6s9...\n",
      "Fetching observation data for time-15-36-35-788211_chatcmpl-D6GId6r3VdPQNTy5QI9dZWCkFWVWZ...\n",
      "Fetching observation data for time-15-38-38-072287_chatcmpl-D6GKcnQO0ewiTXVRyGDZ0Obh0dWGG...\n",
      "Fetching observation data for 7b3b2c8c-500d-4b7e-9d76-8210a91dac43...\n",
      "Fetching observation data for time-15-20-28-567871_chatcmpl-D6G32OD94WmKGELxspwly42DSsHqU...\n",
      "Fetching observation data for time-15-21-17-550680_chatcmpl-D6G3pE61U4BgpyfqYO4RdUWt90Lh5...\n",
      "Fetching observation data for time-15-22-49-122362_chatcmpl-D6G5JMCh19HiezXo5nVvsGZT68FTx...\n",
      "Fetching observation data for time-15-24-36-851332_chatcmpl-D6G73RZDboEE8LLHVbP6ieLmfoeN5...\n",
      "Fetching observation data for time-15-26-09-970826_chatcmpl-D6G8YMOzzUSleM8NjlwMt6D8A2SnE...\n",
      "Fetching observation data for time-15-27-39-749135_chatcmpl-D6GA0YN9JjF85h6SCfDV9SXBkGHPh...\n",
      "Fetching observation data for 10065cd1-b0a5-4ad8-aedf-e18e157e80f5...\n",
      "Fetching observation data for time-15-09-30-576951_chatcmpl-D6FsQc3JIijsH2gojmCj7jIbe6miY...\n",
      "Fetching observation data for time-15-10-39-722748_chatcmpl-D6FtXaALjl9vXWNJGqU89o5Bf6sRm...\n",
      "Fetching observation data for time-15-12-47-719867_chatcmpl-D6FvcIRxQwxgChhqTY4L7t5NmpsUD...\n",
      "Fetching observation data for time-15-14-19-771260_chatcmpl-D6Fx6o4IbRBeu74VSdJhouqwSwJJs...\n",
      "Fetching observation data for time-15-16-27-375242_chatcmpl-D6Fz9APD8i04wmnHy2mZARkRlNQH5...\n",
      "Fetching observation data for time-15-18-18-333550_chatcmpl-D6G0w8bJd5lCW2pNlR3w4BGbiUX77...\n",
      "Fetching observation data for 472e7d6b-5b44-4f1f-b003-7a4b6186f610...\n",
      "Fetching observation data for time-15-03-12-613321_chatcmpl-D6FmLHXyGJYr6AfBInXRU06SGj0JE...\n",
      "Fetching observation data for time-15-03-52-592539_chatcmpl-D6FmyKrVktpM74OOUN5IPguxb7Ch0...\n",
      "Fetching observation data for time-15-04-55-791603_chatcmpl-D6Fo0W41Og1kILlgMqxw9DauFs9eF...\n",
      "Fetching observation data for time-15-06-38-339276_chatcmpl-D6FpfxffVdwINCMY3OmJHii0GN1LW...\n",
      "Raw JSON saved to: /home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/raw_export/raw_gpt-5-2025-08-07_6b01_sg_batch.json\n",
      "Fetching traces for session gpt-5-2025-08-07_6b01_psg_batch...\n",
      "Fetching observation data for time-13-25-14-540840_chatcmpl-D6EFX4AMo3eHulDOHz96a7s2IxLGB...\n",
      "Fetching observation data for time-13-22-52-207948_chatcmpl-D6EDE9B1NdA6d4xqvby19zwFvYr8J...\n",
      "Fetching observation data for time-13-20-44-203079_chatcmpl-D6EBAvExfvh1IZ2Cl74R2sqDgOHHe...\n",
      "Fetching observation data for time-13-17-32-259566_chatcmpl-D6E85oNeZdkDC9rKx9cLg5YKKqK9O...\n",
      "Fetching observation data for time-13-15-31-955173_chatcmpl-D6E681rX83BCBZaTW7maolF8w17nA...\n",
      "Fetching observation data for time-13-12-30-427818_chatcmpl-D6E3CUOyNyzaUS2bpwCIFfYk3zLGm...\n",
      "Fetching observation data for time-13-09-16-484148_chatcmpl-D6E04GijYBgqlyI7c0Q40OkSrwa8I...\n",
      "Fetching observation data for time-13-05-48-434063_chatcmpl-D6Dwkh62VhcZgswXdODMz7toZ3sWi...\n",
      "Fetching observation data for time-13-07-14-321116_chatcmpl-D6Dy6FiTmuNKZxmMi7HYVTtvCVbjw...\n",
      "Fetching observation data for time-13-03-14-665208_chatcmpl-D6DuFxAc6HxxiqC4UoK06ZJZeyfDX...\n",
      "Fetching observation data for time-13-01-03-916845_chatcmpl-D6Ds85m7cREH8jJVSwrirznZv2k5R...\n",
      "Fetching observation data for time-12-59-06-944148_chatcmpl-D6DqFA4lOvchd6e5kt6iImzxyzjLE...\n",
      "Fetching observation data for time-12-56-45-147328_chatcmpl-D6Dnyq6d5g5X220lSR1NhEqGgSoQ5...\n",
      "Fetching observation data for time-12-54-14-413632_chatcmpl-D6DlW9I4W8vWvjpcFFllQAvs11kcl...\n",
      "Fetching observation data for time-12-51-41-472149_chatcmpl-D6Dj3FkHJlJlYmj5QdeAYu6Dyx1pf...\n",
      "Fetching observation data for time-12-49-42-596401_chatcmpl-D6Dh8nHpknaMS8qYgscn0WE1XqK2D...\n",
      "Fetching observation data for time-12-46-18-553484_chatcmpl-D6DdrxhTEtNAOLzkcFoexaHV1gObX...\n",
      "Fetching observation data for time-12-43-43-898947_chatcmpl-D6DbMAeH7rJJBb7UEMcXyXxljzpnF...\n",
      "Fetching observation data for time-12-41-20-153937_chatcmpl-D6DZ2sjJwVx8W8kp5vNatfeLHcdge...\n",
      "Fetching observation data for time-12-37-51-425346_chatcmpl-D6DVfhWmttKrn3W5wUW85Zb7t6aBb...\n",
      "Fetching observation data for time-12-34-49-160172_chatcmpl-D6DSjQDbsnWTlUca3CoEUTkLVtwgu...\n",
      "Fetching observation data for time-12-31-48-730682_chatcmpl-D6DPpCHnFk53CcuMfxS3SVudynS4L...\n",
      "Fetching observation data for time-12-29-59-684130_chatcmpl-D6DO3SiVMYdwGbJSVrbVxTFnrFipQ...\n",
      "Fetching observation data for time-12-26-35-973237_chatcmpl-D6DKmK57BPgdfPEVor2UPLWRzpSlg...\n",
      "Fetching observation data for time-12-28-00-195590_chatcmpl-D6DM8G4lYkoc8TrUrSoAcVPjm7Vq0...\n",
      "Fetching observation data for time-12-24-08-065750_chatcmpl-D6DIOCjqy3CKTy2A24zQCJOIZRSm1...\n",
      "Fetching observation data for time-12-22-29-440873_chatcmpl-D6DGnGFqXJqScRw9rA28b6sqEVqKe...\n",
      "Fetching observation data for time-12-20-45-589084_chatcmpl-D6DF7bxUaPmMYsIeP0HiDKRbL9Wew...\n",
      "Fetching observation data for time-12-19-11-983856_chatcmpl-D6DDcTlFmnpDkpBhM9vyTkAMB7t2i...\n",
      "Fetching observation data for time-12-16-34-005545_chatcmpl-D6DB4J5M5yC56U1xtm0QmhUuDWOzj...\n",
      "Fetching observation data for time-12-14-50-175842_chatcmpl-D6D9OQQ512qA3cGCPapBLv5h2xBHv...\n",
      "Fetching observation data for time-12-13-11-396741_chatcmpl-D6D7nvePjrFLTubullYmBfIr8sOVY...\n",
      "Raw JSON saved to: /home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/raw_export/raw_gpt-5-2025-08-07_6b01_psg_batch.json\n",
      "Fetching traces for session gpt-5-2025-08-07_6b01_tpusg_batch...\n",
      "Fetching observation data for time-15-00-59-464107_chatcmpl-D6FkBxcJpbKIyPY9ju1pawq32zLiu...\n",
      "Fetching observation data for time-14-58-13-718268_chatcmpl-D6FhV9MJhPiLxvWPj8cfnu7tCwUNq...\n",
      "Fetching observation data for time-14-55-44-700550_chatcmpl-D6Ff7JdRLFVaNyMFayMe8jSqTh7Hz...\n",
      "Fetching observation data for time-14-53-19-897866_chatcmpl-D6FcmF2CKmSbGvEplZYKaXguCZcJi...\n",
      "Fetching observation data for time-14-50-28-899921_chatcmpl-D6Fa1gtR3rSDxB5gSdFAJfY7XBy0K...\n",
      "Fetching observation data for time-14-47-25-042361_chatcmpl-D6FX3FVx2irgEffqBFYD9YuqatRzT...\n",
      "Fetching observation data for time-14-45-17-155707_chatcmpl-D6FUzAjtB4z3cxcoz83RbCBZXaYoJ...\n",
      "Fetching observation data for time-14-42-16-327726_chatcmpl-D6FS4MpnHT94yPOpivQWoURUI3DBv...\n",
      "Fetching observation data for time-14-39-29-258522_chatcmpl-D6FPNYOqPQiZX9yYpMDOb5QhClvpT...\n",
      "Fetching observation data for time-14-36-55-364214_chatcmpl-D6FMtWDGTJ2K9zdpUxolOuqAKYCoM...\n",
      "Fetching observation data for time-14-34-28-818446_chatcmpl-D6FKXO6G8VOc3nwKKX2oHwjSOYS2g...\n",
      "Fetching observation data for time-14-31-28-990257_chatcmpl-D6FHd3pFebOVhtqb55fl9WUy4YNup...\n",
      "Fetching observation data for time-14-29-11-072389_chatcmpl-D6FFPm3Q01kFztMFm9E2HpChvPYfq...\n",
      "Fetching observation data for time-14-25-58-201720_chatcmpl-D6FCIYPN5iCX5cV8eFSaTlfJFdFaN...\n",
      "Fetching observation data for time-14-20-18-164949_chatcmpl-D6F6pJ2ZN4DGxeO21rarASAtED5F0...\n",
      "Fetching observation data for time-14-22-58-841051_chatcmpl-D6F9P1wnh6d8mGBP4nEoVridhyAKH...\n",
      "Fetching observation data for time-14-16-58-402545_chatcmpl-D6F3aiGQlTSW9l3idWAzjoJ9e2yIG...\n",
      "Fetching observation data for time-14-14-12-492019_chatcmpl-D6F0u743NUVf5cIKPsqKwNKdsrKon...\n",
      "Fetching observation data for time-14-10-04-565771_chatcmpl-D6EwufwFIjRqIoqkLUt55exPFlXvo...\n",
      "Fetching observation data for time-14-11-21-556583_chatcmpl-D6Ey9qqlAE4WhFciqQ6Qh3bzIyhUp...\n",
      "Fetching observation data for time-14-04-21-469213_chatcmpl-D6ErNkbaTTT5uj5Vs1dc0Te7Mh169...\n",
      "Fetching observation data for time-14-07-19-237101_chatcmpl-D6EuFKslHMmVw59GIYZvndJkeZ48u...\n",
      "Fetching observation data for time-14-01-34-651276_chatcmpl-D6EohwQ3Vd3yprDbOKnG7g02OL4iA...\n",
      "Fetching observation data for time-13-58-59-816039_chatcmpl-D6EmC7zXUzY1st4I0wsUSWlNlW1bR...\n",
      "Fetching observation data for time-13-56-22-195029_chatcmpl-D6EjfxQqtmiq5wZ4pn0b4FTEoHLbf...\n",
      "Fetching observation data for time-13-53-30-207280_chatcmpl-D6EgsLH5vPA2ilsYC4h6RKxWdDJc8...\n",
      "Fetching observation data for time-13-46-20-192077_chatcmpl-D6EZw46RakggPfCn44nYVMbDCP7I8...\n",
      "Fetching observation data for time-13-48-11-958181_chatcmpl-D6Ebk7ofmn5hHutMGavqsuS61uf0O...\n",
      "Fetching observation data for time-13-50-12-367537_chatcmpl-D6EdgIgornSKeS7LUkyw72pKIwDny...\n",
      "Fetching observation data for time-13-43-16-443038_chatcmpl-D6EWyQmpAradpaloex6bxb6cNDwIg...\n",
      "Fetching observation data for time-13-39-40-345631_chatcmpl-D6ETUWByEHN0wAOJzFuwdoIMCoFfp...\n",
      "Fetching observation data for time-13-37-03-416807_chatcmpl-D6EQx95y4xpvDeKPMQf3h3YNigUwv...\n",
      "Fetching observation data for time-13-34-00-891727_chatcmpl-D6EO1PvcPK9aKhXjHLK8wEbkFolwE...\n",
      "Fetching observation data for time-13-31-21-786454_chatcmpl-D6ELSkY5d5cYPqHf8Yd7O13DNF8NZ...\n",
      "Fetching observation data for time-13-28-00-501416_chatcmpl-D6EIDHjDFruN1EfuGy95SUr24kJGd...\n",
      "Raw JSON saved to: /home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/raw_export/raw_gpt-5-2025-08-07_6b01_tpusg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_66_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206190438_gpt-5-2025-08-07/compiling_20260206190438_gpt-5-2025-08-07.ino:40:15: error: 'T' does not name a type\n",
      " static inline T clamp_int32(int32_t v, int32_t lo, int32_t hi) {\n",
      "               ^\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_25_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino: In function 'void setup()':\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino:126:3: error: reference to 'model' is ambiguous\n",
      "   model = tflite::GetModel(g_model);\n",
      "   ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino:9:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/model.h:1:21: note: candidates are: const unsigned char model [2528]\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino:41:22: note:                 const tflite::Model* {anonymous}::model\n",
      " const tflite::Model* model = nullptr;\n",
      "                      ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino:126:28: error: 'g_model' was not declared in this scope\n",
      "   model = tflite::GetModel(g_model);\n",
      "                            ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino:126:28: note: suggested alternative: 'model'\n",
      "   model = tflite::GetModel(g_model);\n",
      "                            ^~~~~~~\n",
      "                            model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino:127:7: error: reference to 'model' is ambiguous\n",
      "   if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      "       ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino:9:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/model.h:1:21: note: candidates are: const unsigned char model [2528]\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino:41:22: note:                 const tflite::Model* {anonymous}::model\n",
      " const tflite::Model* model = nullptr;\n",
      "                      ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino:129:18: error: reference to 'model' is ambiguous\n",
      "     Serial.print(model->version());\n",
      "                  ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino:9:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/model.h:1:21: note: candidates are: const unsigned char model [2528]\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino:41:22: note:                 const tflite::Model* {anonymous}::model\n",
      " const tflite::Model* model = nullptr;\n",
      "                      ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino:132:71: error: no matching function for call to 'digitalWrite(unsigned int)'\n",
      "     while (true) { digitalWrite(LED_BUILTIN, !digitalWrite(LED_BUILTIN)); delay(100); }\n",
      "                                                                       ^\n",
      "In file included from /home/wuguangh/.arduino15/packages/arduino/hardware/mbed/3.3.0/variants/ARDUINO_NANO33BLE/pinmode_arduino.h:23:0,\n",
      "                 from /home/wuguangh/.arduino15/packages/arduino/hardware/mbed/3.3.0/cores/arduino/Arduino.h:26,\n",
      "                 from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino:1:\n",
      "/home/wuguangh/.arduino15/packages/arduino/hardware/mbed/3.3.0/cores/arduino/api/Common.h:97:6: note: candidate: void digitalWrite(pin_size_t, PinStatus)\n",
      " void digitalWrite(pin_size_t pinNumber, PinStatus status);\n",
      "      ^~~~~~~~~~~~\n",
      "/home/wuguangh/.arduino15/packages/arduino/hardware/mbed/3.3.0/cores/arduino/api/Common.h:97:6: note:   candidate expects 2 arguments, 1 provided\n",
      "In file included from /home/wuguangh/.arduino15/packages/arduino/hardware/mbed/3.3.0/cores/arduino/Arduino.h:126:0,\n",
      "                 from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino:1:\n",
      "/home/wuguangh/.arduino15/packages/arduino/hardware/mbed/3.3.0/cores/arduino/overloads.h:24:6: note: candidate: void digitalWrite(PinName, PinStatus)\n",
      " void digitalWrite(PinName pinNumber, PinStatus status);\n",
      "      ^~~~~~~~~~~~\n",
      "/home/wuguangh/.arduino15/packages/arduino/hardware/mbed/3.3.0/cores/arduino/overloads.h:24:6: note:   candidate expects 2 arguments, 1 provided\n",
      "In file included from /home/wuguangh/.arduino15/packages/arduino/hardware/mbed/3.3.0/cores/arduino/api/ArduinoAPI.h:54:0,\n",
      "                 from /home/wuguangh/.arduino15/packages/arduino/hardware/mbed/3.3.0/cores/arduino/Arduino.h:27,\n",
      "                 from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino:1:\n",
      "/home/wuguangh/.arduino15/packages/arduino/hardware/mbed/3.3.0/cores/arduino/api/Compat.h:10:13: note: candidate: void arduino::digitalWrite(pin_size_t, int)\n",
      " inline void digitalWrite(pin_size_t pinNumber, int status) {\n",
      "             ^~~~~~~~~~~~\n",
      "/home/wuguangh/.arduino15/packages/arduino/hardware/mbed/3.3.0/cores/arduino/api/Compat.h:10:13: note:   candidate expects 2 arguments, 1 provided\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino:136:5: error: reference to 'model' is ambiguous\n",
      "     model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "     ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino:9:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/model.h:1:21: note: candidates are: const unsigned char model [2528]\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206184546_gpt-5-2025-08-07/compiling_20260206184546_gpt-5-2025-08-07.ino:41:22: note:                 const tflite::Model* {anonymous}::model\n",
      " const tflite::Model* model = nullptr;\n",
      "                      ^~~~~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_0a_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206182253_gpt-5-2025-08-07/compiling_20260206182253_gpt-5-2025-08-07.ino:35:31: error: conflicting declaration 'const tflite::Model* model'\n",
      " static const tflite::Model*   model          = nullptr;\n",
      "                               ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206182253_gpt-5-2025-08-07/compiling_20260206182253_gpt-5-2025-08-07.ino:18:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206182253_gpt-5-2025-08-07/model.h:1:21: note: previous declaration as 'const unsigned char model [2528]'\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206182253_gpt-5-2025-08-07/compiling_20260206182253_gpt-5-2025-08-07.ino: In function 'void setup()':\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206182253_gpt-5-2025-08-07/compiling_20260206182253_gpt-5-2025-08-07.ino:111:28: error: 'g_model' was not declared in this scope\n",
      "   model = tflite::GetModel(g_model);\n",
      "                            ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206182253_gpt-5-2025-08-07/compiling_20260206182253_gpt-5-2025-08-07.ino:111:28: note: suggested alternative: 'model'\n",
      "   model = tflite::GetModel(g_model);\n",
      "                            ^~~~~~~\n",
      "                            model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206182253_gpt-5-2025-08-07/compiling_20260206182253_gpt-5-2025-08-07.ino:112:14: error: request for member 'version' in '*(const unsigned char*)(& model)', which is of non-class type 'const unsigned char'\n",
      "   if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      "              ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206182253_gpt-5-2025-08-07/compiling_20260206182253_gpt-5-2025-08-07.ino:114:35: error: request for member 'version' in '*(const unsigned char*)(& model)', which is of non-class type 'const unsigned char'\n",
      "                            model->version(), TFLITE_SCHEMA_VERSION);\n",
      "                                   ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206182253_gpt-5-2025-08-07/compiling_20260206182253_gpt-5-2025-08-07.ino:123:68: error: no matching function for call to 'tflite::MicroInterpreter::MicroInterpreter(const unsigned char [2528], tflite::AllOpsResolver&, uint8_t [16384], const int&, tflite::ErrorReporter*&)'\n",
      "     model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                                                    ^\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206182253_gpt-5-2025-08-07/compiling_20260206182253_gpt-5-2025-08-07.ino:17:0:\n",
      "/home/wuguangh/Arduino/libraries/Harvard_TinyMLx/src/tensorflow/lite/micro/micro_interpreter.h:92:3: note: candidate: tflite::MicroInterpreter::MicroInterpreter(const tflite::Model*, const tflite::MicroOpResolver&, tflite::MicroAllocator*, tflite::ErrorReporter*, tflite::Profiler*)\n",
      "   MicroInterpreter(const Model* model, const MicroOpResolver& op_resolver,\n",
      "   ^~~~~~~~~~~~~~~~\n",
      "/home/wuguangh/Arduino/libraries/Harvard_TinyMLx/src/tensorflow/lite/micro/micro_interpreter.h:92:3: note:   no known conversion for argument 1 from 'const unsigned char [2528]' to 'const tflite::Model*'\n",
      "/home/wuguangh/Arduino/libraries/Harvard_TinyMLx/src/tensorflow/lite/micro/micro_interpreter.h:82:3: note: candidate: tflite::MicroInterpreter::MicroInterpreter(const tflite::Model*, const tflite::MicroOpResolver&, uint8_t*, size_t, tflite::ErrorReporter*, tflite::Profiler*)\n",
      "   MicroInterpreter(const Model* model, const MicroOpResolver& op_resolver,\n",
      "   ^~~~~~~~~~~~~~~~\n",
      "/home/wuguangh/Arduino/libraries/Harvard_TinyMLx/src/tensorflow/lite/micro/micro_interpreter.h:82:3: note:   no known conversion for argument 1 from 'const unsigned char [2528]' to 'const tflite::Model*'\n",
      "/home/wuguangh/Arduino/libraries/Harvard_TinyMLx/src/tensorflow/lite/micro/micro_interpreter.h:73:7: note: candidate: constexpr tflite::MicroInterpreter::MicroInterpreter(const tflite::MicroInterpreter&)\n",
      " class MicroInterpreter {\n",
      "       ^~~~~~~~~~~~~~~~\n",
      "/home/wuguangh/Arduino/libraries/Harvard_TinyMLx/src/tensorflow/lite/micro/micro_interpreter.h:73:7: note:   candidate expects 1 argument, 5 provided\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_14_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: sketch/compiling_20260206181015_gpt-5-2025-08-07.ino.cpp.o: In function `setup':\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206181015_gpt-5-2025-08-07/compiling_20260206181015_gpt-5-2025-08-07.ino:108: undefined reference to `g_model'\n",
      "collect2: error: ld returned 1 exit status\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_17_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206175802_gpt-5-2025-08-07/compiling_20260206175802_gpt-5-2025-08-07.ino: In function 'bool setupTFLM()':\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206175802_gpt-5-2025-08-07/compiling_20260206175802_gpt-5-2025-08-07.ino:58:37: error: 'g_model' was not declared in this scope\n",
      "   g_model_struct = tflite::GetModel(g_model);\n",
      "                                     ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206175802_gpt-5-2025-08-07/compiling_20260206175802_gpt-5-2025-08-07.ino:58:37: note: suggested alternative: 'model'\n",
      "   g_model_struct = tflite::GetModel(g_model);\n",
      "                                     ^~~~~~~\n",
      "                                     model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206175802_gpt-5-2025-08-07/compiling_20260206175802_gpt-5-2025-08-07.ino:59:36: error: 'TFLITE_SCHEMA_VERSION' was not declared in this scope\n",
      "   if (g_model_struct->version() != TFLITE_SCHEMA_VERSION) {\n",
      "                                    ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206175802_gpt-5-2025-08-07/compiling_20260206175802_gpt-5-2025-08-07.ino:59:36: note: suggested alternative: 'TFLITE_CHECK_LE'\n",
      "   if (g_model_struct->version() != TFLITE_SCHEMA_VERSION) {\n",
      "                                    ^~~~~~~~~~~~~~~~~~~~~\n",
      "                                    TFLITE_CHECK_LE\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_55_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206160917_gpt-5-2025-08-07/compiling_20260206160917_gpt-5-2025-08-07.ino: In function 'void setup()':\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206160917_gpt-5-2025-08-07/compiling_20260206160917_gpt-5-2025-08-07.ino:175:34: error: 'g_model' was not declared in this scope\n",
      "   g_model_ptr = tflite::GetModel(g_model);\n",
      "                                  ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206160917_gpt-5-2025-08-07/compiling_20260206160917_gpt-5-2025-08-07.ino:175:34: note: suggested alternative: 'model'\n",
      "   g_model_ptr = tflite::GetModel(g_model);\n",
      "                                  ^~~~~~~\n",
      "                                  model\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_34_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/compiling_20260206154014_gpt-5-2025-08-07.ino: In function 'void setup()':\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/compiling_20260206154014_gpt-5-2025-08-07.ino:102:3: error: reference to 'model' is ambiguous\n",
      "   model = tflite::GetModel(g_model);\n",
      "   ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/compiling_20260206154014_gpt-5-2025-08-07.ino:9:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/model.h:1:21: note: candidates are: const unsigned char model [2528]\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/compiling_20260206154014_gpt-5-2025-08-07.ino:33:24: note:                 const tflite::Model* {anonymous}::model\n",
      "   const tflite::Model* model = nullptr;\n",
      "                        ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/compiling_20260206154014_gpt-5-2025-08-07.ino:102:28: error: 'g_model' was not declared in this scope\n",
      "   model = tflite::GetModel(g_model);\n",
      "                            ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/compiling_20260206154014_gpt-5-2025-08-07.ino:102:28: note: suggested alternative: 'model'\n",
      "   model = tflite::GetModel(g_model);\n",
      "                            ^~~~~~~\n",
      "                            model\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/compiling_20260206154014_gpt-5-2025-08-07.ino:103:7: error: reference to 'model' is ambiguous\n",
      "   if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
      "       ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/compiling_20260206154014_gpt-5-2025-08-07.ino:9:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/model.h:1:21: note: candidates are: const unsigned char model [2528]\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/compiling_20260206154014_gpt-5-2025-08-07.ino:33:24: note:                 const tflite::Model* {anonymous}::model\n",
      "   const tflite::Model* model = nullptr;\n",
      "                        ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/compiling_20260206154014_gpt-5-2025-08-07.ino:105:18: error: reference to 'model' is ambiguous\n",
      "     Serial.print(model->version());\n",
      "                  ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/compiling_20260206154014_gpt-5-2025-08-07.ino:9:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/model.h:1:21: note: candidates are: const unsigned char model [2528]\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/compiling_20260206154014_gpt-5-2025-08-07.ino:33:24: note:                 const tflite::Model* {anonymous}::model\n",
      "   const tflite::Model* model = nullptr;\n",
      "                        ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/compiling_20260206154014_gpt-5-2025-08-07.ino:112:46: error: reference to 'model' is ambiguous\n",
      "   interpreter = new tflite::MicroInterpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter);\n",
      "                                              ^~~~~\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/compiling_20260206154014_gpt-5-2025-08-07.ino:9:0:\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/model.h:1:21: note: candidates are: const unsigned char model [2528]\n",
      " const unsigned char model[] = {\n",
      "                     ^~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206154014_gpt-5-2025-08-07/compiling_20260206154014_gpt-5-2025-08-07.ino:33:24: note:                 const tflite::Model* {anonymous}::model\n",
      "   const tflite::Model* model = nullptr;\n",
      "                        ^~~~~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_6c_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206152903_gpt-5-2025-08-07/compiling_20260206152903_gpt-5-2025-08-07.ino: In function 'bool readNormalizedRGB(float&, float&, float&)':\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206152903_gpt-5-2025-08-07/compiling_20260206152903_gpt-5-2025-08-07.ino:103:37: error: cannot bind non-const lvalue reference of type 'int&' to an rvalue of type 'int'\n",
      "   if (!APDS.readColor(rr, gg, bb, cc)) return false;\n",
      "                                     ^\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206152903_gpt-5-2025-08-07/compiling_20260206152903_gpt-5-2025-08-07.ino:18:0:\n",
      "/home/wuguangh/Arduino/libraries/Arduino_APDS9960/src/Arduino_APDS9960.h:47:8: note:   initializing argument 1 of 'bool APDS9960::readColor(int&, int&, int&, int&)'\n",
      "   bool readColor(int& r, int& g, int& b, int& c);\n",
      "        ^~~~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206152903_gpt-5-2025-08-07/compiling_20260206152903_gpt-5-2025-08-07.ino: In function 'void setup()':\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206152903_gpt-5-2025-08-07/compiling_20260206152903_gpt-5-2025-08-07.ino:168:37: error: 'g_model' was not declared in this scope\n",
      "   g_model_handle = tflite::GetModel(g_model);\n",
      "                                     ^~~~~~~\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206152903_gpt-5-2025-08-07/compiling_20260206152903_gpt-5-2025-08-07.ino:168:37: note: suggested alternative: 'model'\n",
      "   g_model_handle = tflite::GetModel(g_model);\n",
      "                                     ^~~~~~~\n",
      "                                     model\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "SPAN error_6f_sg_failure_signal_sketch_generator: Failed. Last error: Max 5 attempts exceeded. Last error from code execution: /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206151934_gpt-5-2025-08-07/compiling_20260206151934_gpt-5-2025-08-07.ino: In function 'bool readAveragedRGB(uint32_t&, uint32_t&, uint32_t&)':\n",
      "/home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206151934_gpt-5-2025-08-07/compiling_20260206151934_gpt-5-2025-08-07.ino:85:35: error: cannot bind non-const lvalue reference of type 'int&' to an rvalue of type 'int'\n",
      "     if (!APDS.readColor(r, g, b, c)) {\n",
      "                                   ^\n",
      "In file included from /home/wuguangh/Projects/tinyml-autopilot/compiling/compiling_20260206151934_gpt-5-2025-08-07/compiling_20260206151934_gpt-5-2025-08-07.ino:16:0:\n",
      "/home/wuguangh/Arduino/libraries/Arduino_APDS9960/src/Arduino_APDS9960.h:47:8: note:   initializing argument 1 of 'bool APDS9960::readColor(int&, int&, int&, int&)'\n",
      "   bool readColor(int& r, int& g, int& b, int& c);\n",
      "        ^~~~~~~~~\n",
      "\n",
      "Error during build: exit status 1\n",
      "\n",
      "Successfully processed and saved trimmed data for session gpt-5-2025-08-07_6b01_sg_batch\n",
      "Successfully processed and saved trimmed data for session gpt-5-2025-08-07_6b01_psg_batch\n",
      "Successfully processed and saved trimmed data for session gpt-5-2025-08-07_6b01_tpusg_batch\n",
      "======================================================================================================================================================\n",
      "TOTAL 0 TRACES SKIPPED. THEY ARE []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "skipped_trace_details = []  # Keep reason + observation that triggered the skip\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            error_markers = [\n",
    "             \n",
    "                \"litellm.apiconnectionerror\",\n",
    "                \"ollamaexception\",\n",
    "                \"llama runner process has terminated: cuda error\",\n",
    "            ]\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict):\n",
    "                    ob_name = obs.get(\"name\", \"\")\n",
    "                    status_message = obs.get(\"statusMessage\") or \"\"\n",
    "                    if not status_message and \"output\" in obs:\n",
    "                        output_field = obs.get(\"output\")\n",
    "                        if isinstance(output_field, dict):\n",
    "                            status_message = output_field.get(\"message\", \"\")\n",
    "                        elif isinstance(output_field, str):\n",
    "                            status_message = output_field\n",
    "                    lower_message = status_message.lower() if status_message else \"\"\n",
    "                    if ob_name.startswith(\"error\") and status_message:\n",
    "                        print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if any(marker in lower_message for marker in error_markers):\n",
    "                        trace_name = data.get(\"name\", \"<unknown trace>\")\n",
    "                        matched_marker = next(\n",
    "                            (marker for marker in error_markers if marker in lower_message),\n",
    "                            \"unknown error\",\n",
    "                        )\n",
    "                        reason = status_message or matched_marker\n",
    "                        condition = f\"error_marker:{matched_marker}\"\n",
    "                        print(\n",
    "                            f\"Found error marker in observation {ob_name} -> skipping trace {trace_name} ({reason})\"\n",
    "                        )\n",
    "                        skip_trace = True\n",
    "                        if trace_name not in skipped_traces:\n",
    "                            skipped_traces.append(trace_name)\n",
    "                        skipped_trace_details.append(\n",
    "                            {\n",
    "                                \"trace\": trace_name,\n",
    "                                \"observation\": ob_name,\n",
    "                                \"reason\": reason,\n",
    "                                \"condition\": condition,\n",
    "                            }\n",
    "                        )\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(\"=\"*150)\n",
    "print(f\"TOTAL {len(skipped_traces)} TRACES SKIPPED. THEY ARE {skipped_traces}\")\n",
    "if skipped_trace_details:\n",
    "    print(\"SKIP REASONS:\\n```\")\n",
    "    for detail in skipped_trace_details:\n",
    "        print(\n",
    "            f\"- {detail['trace']} (observation: {detail['observation']} | condition: {detail['condition']}): {detail['reason']}\"\n",
    "        )\n",
    "    print(\"```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session gpt-5-2025-08-07_6b01_sg_batch, simple id gpt-5-2025-08-07_6b01. Look for /home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/raw_export/trimmed_gpt-5-2025-08-07_6b01_sg_batch.json\n",
      "/home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/processed_data/gpt-5-2025-08-07_6b01/clean_gpt-5-2025-08-07_6b01_sg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/processed_data/gpt-5-2025-08-07_6b01/clean_gpt-5-2025-08-07_6b01_sg_batch.csv\n",
      "Processing session gpt-5-2025-08-07_6b01_psg_batch, simple id gpt-5-2025-08-07_6b01. Look for /home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/raw_export/trimmed_gpt-5-2025-08-07_6b01_psg_batch.json\n",
      "/home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/processed_data/gpt-5-2025-08-07_6b01/clean_gpt-5-2025-08-07_6b01_psg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/processed_data/gpt-5-2025-08-07_6b01/clean_gpt-5-2025-08-07_6b01_psg_batch.csv\n",
      "Processing session gpt-5-2025-08-07_6b01_tpusg_batch, simple id gpt-5-2025-08-07_6b01. Look for /home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/raw_export/trimmed_gpt-5-2025-08-07_6b01_tpusg_batch.json\n",
      "/home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/processed_data/gpt-5-2025-08-07_6b01/clean_gpt-5-2025-08-07_6b01_tpusg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/processed_data/gpt-5-2025-08-07_6b01/clean_gpt-5-2025-08-07_6b01_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Generation with Generation Counts\n",
    "\n",
    "This section creates CSV files similar to the langfuse_export section 3, but adds a column for the number of generation attempts used for each trace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sessions: ['gpt-5-2025-08-07_6b01_tpusg_batch', 'gpt-5-2025-08-07_6b01_sg_batch', 'gpt-5-2025-08-07_6b01_psg_batch']\n",
      "Looking for raw files in: /home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/raw_export\n",
      "Will save CSV files to: /home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/processed_data\n",
      "Processing session gpt-5-2025-08-07_6b01_tpusg_batch, simple id gpt-5-2025-08-07_6b01. Look for /home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/raw_export/trimmed_gpt-5-2025-08-07_6b01_tpusg_batch.json\n",
      "/home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/processed_data/gpt-5-2025-08-07_6b01/clean_gpt-5-2025-08-07_6b01_tpusg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/processed_data/gpt-5-2025-08-07_6b01/clean_gpt-5-2025-08-07_6b01_tpusg_batch.csv\n",
      "Processing session gpt-5-2025-08-07_6b01_sg_batch, simple id gpt-5-2025-08-07_6b01. Look for /home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/raw_export/trimmed_gpt-5-2025-08-07_6b01_sg_batch.json\n",
      "/home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/processed_data/gpt-5-2025-08-07_6b01/clean_gpt-5-2025-08-07_6b01_sg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/processed_data/gpt-5-2025-08-07_6b01/clean_gpt-5-2025-08-07_6b01_sg_batch.csv\n",
      "Processing session gpt-5-2025-08-07_6b01_psg_batch, simple id gpt-5-2025-08-07_6b01. Look for /home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/raw_export/trimmed_gpt-5-2025-08-07_6b01_psg_batch.json\n",
      "/home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/processed_data/gpt-5-2025-08-07_6b01/clean_gpt-5-2025-08-07_6b01_psg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/benchmark-tinyml_llm-2026/data_analysis/2026/02.09_abla-l2-gpt5/processed_data/gpt-5-2025-08-07_6b01/clean_gpt-5-2025-08-07_6b01_psg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "# Setup paths - same as langfuse_export\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "\n",
    "\n",
    "# Get session id list from data directory\n",
    "session_id_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(raw_export_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if \"trimmed_\" in file_path:\n",
    "            session_id = file_path.split('trimmed_')[1].rstrip('.json')\n",
    "            session_id_list.append(session_id)\n",
    "\n",
    "print(f\"Processing sessions: {session_id_list}\")\n",
    "print(f\"Looking for raw files in: {raw_export_dir}\")\n",
    "print(f\"Will save CSV files to: {processed_data_dir}\")\n",
    "\n",
    "\n",
    "def json_to_csv_weighted(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "    Upgraded version that includes generation_count column.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "            \"generation_count\": 0,  # New field for generation count\n",
    "        }\n",
    "\n",
    "        # Count generations and process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"generation_count\"] += 1\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "                    \n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "            \n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        \n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv_weighted(session_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
